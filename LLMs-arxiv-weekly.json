{"STPA - Vehicles": {"2304.00408": "|**2023-04-01**|**Hazard Analysis for Self-Adaptive Systems Using System-Theoretic Process Analysis**|Simon Diemert et.al.|[2304.00408v1](http://arxiv.org/abs/2304.00408v1)|null|\n", "2205.12075": "|**2022-05-24**|**Failure Mechanism Traceability and Application in Human System Interface of Nuclear Power Plants using RESHA**|Edward Chen et.al.|[2205.12075v1](http://arxiv.org/abs/2205.12075v1)|null|\n", "2006.09108": "|**2020-06-16**|**An STPA-based Approach for Systematic Security Analysis of In-vehicle Diagnostic and Software Update Systems**|Jinghua Yu et.al.|[2006.09108v1](http://arxiv.org/abs/2006.09108v1)|null|\n", "2006.02930": "|**2020-06-04**|**Data-Flow-Based Extension of the System-Theoretic Process Analysis for Security (STPA-Sec)**|Jinghua Yu et.al.|[2006.02930v1](http://arxiv.org/abs/2006.02930v1)|null|\n", "1912.02019": "|**2019-12-04**|**Applying systems-theoretic process analysis in the context of cooperative driving**|Joakim Oscarsson et.al.|[1912.02019v1](http://arxiv.org/abs/1912.02019v1)|null|\n", "1807.06172": "|**2018-09-30**|**Experimental Resilience Assessment of An Open-Source Driving Agent**|Abu Hasnat Mohammad Rubaiyat et.al.|[1807.06172v2](http://arxiv.org/abs/1807.06172v2)|null|\n", "1703.03657": "|**2017-03-10**|**Using STPA in Compliance with ISO 26262 for Developing a Safe Architecture for Fully Automated Vehicles**|Asim Abdulkhaleq et.al.|[1703.03657v1](http://arxiv.org/abs/1703.03657v1)|null|\n"}, "STPA - Robots": {"1912.02019": "|**2019-12-04**|**Applying systems-theoretic process analysis in the context of cooperative driving**|Joakim Oscarsson et.al.|[1912.02019v1](http://arxiv.org/abs/1912.02019v1)|null|\n", "1807.06172": "|**2018-09-30**|**Experimental Resilience Assessment of An Open-Source Driving Agent**|Abu Hasnat Mohammad Rubaiyat et.al.|[1807.06172v2](http://arxiv.org/abs/1807.06172v2)|null|\n", "1612.03103": "|**2016-12-09**|**A Systematic and Semi-Automatic Safety-Based Test Case Generation Approach Based on Systems-Theoretic Process Analysis**|Asim Abdulkhaleq et.al.|[1612.03103v1](http://arxiv.org/abs/1612.03103v1)|null|\n"}, "STPA - Ships": {"2212.10830": "|**2022-12-21**|**A Comparative Risk Analysis on CyberShip System with STPA-Sec, STRIDE and CORAS**|Rishikesh Sahay et.al.|[2212.10830v1](http://arxiv.org/abs/2212.10830v1)|null|\n"}, "STPA - Drones": {}, "STPA - ML": {"2302.10588": "|**2023-07-17**|**STPA for Learning-Enabled Systems: A Survey and A New Practice**|Yi Qi et.al.|[2302.10588v2](http://arxiv.org/abs/2302.10588v2)|null|\n", "2211.04602": "|**2022-11-08**|**System Safety Engineering for Social and Ethical ML Risks: A Case Study**|Edgar W. Jatho III et.al.|[2211.04602v1](http://arxiv.org/abs/2211.04602v1)|null|\n", "2210.03535": "|**2022-10-06**|**From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML**|Shalaleh Rismani et.al.|[2210.03535v1](http://arxiv.org/abs/2210.03535v1)|null|\n"}, "STPA - Security": {"2212.10830": "|**2022-12-21**|**A Comparative Risk Analysis on CyberShip System with STPA-Sec, STRIDE and CORAS**|Rishikesh Sahay et.al.|[2212.10830v1](http://arxiv.org/abs/2212.10830v1)|null|\n", "2204.08999": "|**2022-06-22**|**STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection**|Smitha Gautham et.al.|[2204.08999v3](http://arxiv.org/abs/2204.08999v3)|null|\n", "2006.09108": "|**2020-06-16**|**An STPA-based Approach for Systematic Security Analysis of In-vehicle Diagnostic and Software Update Systems**|Jinghua Yu et.al.|[2006.09108v1](http://arxiv.org/abs/2006.09108v1)|null|\n", "2006.02930": "|**2020-06-04**|**Data-Flow-Based Extension of the System-Theoretic Process Analysis for Security (STPA-Sec)**|Jinghua Yu et.al.|[2006.02930v1](http://arxiv.org/abs/2006.02930v1)|null|\n", "1706.00497": "|**2017-05-29**|**A Hazard Analysis Technique for Additive Manufacturing**|Gregory Pope et.al.|[1706.00497v1](http://arxiv.org/abs/1706.00497v1)|null|\n", "1703.03657": "|**2017-03-10**|**Using STPA in Compliance with ISO 26262 for Developing a Safe Architecture for Fully Automated Vehicles**|Asim Abdulkhaleq et.al.|[1703.03657v1](http://arxiv.org/abs/1703.03657v1)|null|\n"}, "STPA - Privacy": {"1710.11571": "|**2017-10-24**|**Exploratory Study of the Privacy Extension for System Theoretic Process Analysis (STPA-Priv) to elicit Privacy Risks in eHealth**|Kai Mindermann et.al.|[1710.11571v1](http://arxiv.org/abs/1710.11571v1)|null|\n"}, "STPA - Systems": {}, "STPA - Evaluation": {"2307.08823": "|**2023-07-17**|**Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries**|Leonie Koessler et.al.|[2307.08823v1](http://arxiv.org/abs/2307.08823v1)|null|\n", "2212.10830": "|**2022-12-21**|**A Comparative Risk Analysis on CyberShip System with STPA-Sec, STRIDE and CORAS**|Rishikesh Sahay et.al.|[2212.10830v1](http://arxiv.org/abs/2212.10830v1)|null|\n", "2204.08999": "|**2022-06-22**|**STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection**|Smitha Gautham et.al.|[2204.08999v3](http://arxiv.org/abs/2204.08999v3)|null|\n", "2108.04621": "|**2021-08-10**|**Refactoring the Whitby Intelligent Tutoring System for Clean Architecture**|Paul S. Brown et.al.|[2108.04621v1](http://arxiv.org/abs/2108.04621v1)|**[link](https://github.com/paulbrownmagic/bedsit)**|\n", "1804.01715": "|**2018-04-05**|**Combining STPA and BDD for Safety Analysis and Verification in Agile Development: A Controlled Experiment**|Yang Wang et.al.|[1804.01715v1](http://arxiv.org/abs/1804.01715v1)|null|\n", "1706.00497": "|**2017-05-29**|**A Hazard Analysis Technique for Additive Manufacturing**|Gregory Pope et.al.|[1706.00497v1](http://arxiv.org/abs/1706.00497v1)|null|\n", "1703.05375": "|**2018-04-05**|**An Exploratory Study of Applying a Scrum Development Process for Safety-Critical Systems**|Yang Wang et.al.|[1703.05375v3](http://arxiv.org/abs/1703.05375v3)|null|\n", "1703.03657": "|**2017-03-10**|**Using STPA in Compliance with ISO 26262 for Developing a Safe Architecture for Fully Automated Vehicles**|Asim Abdulkhaleq et.al.|[1703.03657v1](http://arxiv.org/abs/1703.03657v1)|null|\n"}, "STPA - SC": {}, "STPA - SA": {"2304.01246": "|**2023-11-05**|**Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT**|Yi Qi et.al.|[2304.01246v2](http://arxiv.org/abs/2304.01246v2)|**[link](https://github.com/yiqi0318/chatgpt-stpa)**|\n", "2211.04602": "|**2022-11-08**|**System Safety Engineering for Social and Ethical ML Risks: A Case Study**|Edgar W. Jatho III et.al.|[2211.04602v1](http://arxiv.org/abs/2211.04602v1)|null|\n", "1912.02019": "|**2019-12-04**|**Applying systems-theoretic process analysis in the context of cooperative driving**|Joakim Oscarsson et.al.|[1912.02019v1](http://arxiv.org/abs/1912.02019v1)|null|\n", "1804.01715": "|**2018-04-05**|**Combining STPA and BDD for Safety Analysis and Verification in Agile Development: A Controlled Experiment**|Yang Wang et.al.|[1804.01715v1](http://arxiv.org/abs/1804.01715v1)|null|\n", "1703.05375": "|**2018-04-05**|**An Exploratory Study of Applying a Scrum Development Process for Safety-Critical Systems**|Yang Wang et.al.|[1703.05375v3](http://arxiv.org/abs/1703.05375v3)|null|\n", "1703.03657": "|**2017-03-10**|**Using STPA in Compliance with ISO 26262 for Developing a Safe Architecture for Fully Automated Vehicles**|Asim Abdulkhaleq et.al.|[1703.03657v1](http://arxiv.org/abs/1703.03657v1)|null|\n", "1612.03109": "|**2016-12-09**|**A comprehensive safety engineering approach for software-intensive systems based on STPA**|Asim Abdulkhaleq et.al.|[1612.03109v1](http://arxiv.org/abs/1612.03109v1)|null|\n", "1612.03103": "|**2016-12-09**|**A Systematic and Semi-Automatic Safety-Based Test Case Generation Approach Based on Systems-Theoretic Process Analysis**|Asim Abdulkhaleq et.al.|[1612.03103v1](http://arxiv.org/abs/1612.03103v1)|null|\n"}, "STPA - Model": {"2306.04499": "|**2023-06-07**|**Anticipating Accidents through Reasoned Simulation**|Craig Innes et.al.|[2306.04499v1](http://arxiv.org/abs/2306.04499v1)|null|\n", "2304.01246": "|**2023-11-05**|**Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT**|Yi Qi et.al.|[2304.01246v2](http://arxiv.org/abs/2304.01246v2)|**[link](https://github.com/yiqi0318/chatgpt-stpa)**|\n", "2304.00408": "|**2023-04-01**|**Hazard Analysis for Self-Adaptive Systems Using System-Theoretic Process Analysis**|Simon Diemert et.al.|[2304.00408v1](http://arxiv.org/abs/2304.00408v1)|null|\n", "2302.10588": "|**2023-07-17**|**STPA for Learning-Enabled Systems: A Survey and A New Practice**|Yi Qi et.al.|[2302.10588v2](http://arxiv.org/abs/2302.10588v2)|null|\n", "2209.00552": "|**2022-11-09**|**Systems Theoretic Process Analysis of a Run Time Assured Neural Network Control System**|Kerianne L. Hobbs et.al.|[2209.00552v2](http://arxiv.org/abs/2209.00552v2)|null|\n", "2204.08999": "|**2022-06-22**|**STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection**|Smitha Gautham et.al.|[2204.08999v3](http://arxiv.org/abs/2204.08999v3)|null|\n", "2108.04621": "|**2021-08-10**|**Refactoring the Whitby Intelligent Tutoring System for Clean Architecture**|Paul S. Brown et.al.|[2108.04621v1](http://arxiv.org/abs/2108.04621v1)|**[link](https://github.com/paulbrownmagic/bedsit)**|\n", "2006.09108": "|**2020-06-16**|**An STPA-based Approach for Systematic Security Analysis of In-vehicle Diagnostic and Software Update Systems**|Jinghua Yu et.al.|[2006.09108v1](http://arxiv.org/abs/2006.09108v1)|null|\n", "1612.03109": "|**2016-12-09**|**A comprehensive safety engineering approach for software-intensive systems based on STPA**|Asim Abdulkhaleq et.al.|[1612.03109v1](http://arxiv.org/abs/1612.03109v1)|null|\n"}, "STPA - LES": {"2108.04621": "|**2021-08-10**|**Refactoring the Whitby Intelligent Tutoring System for Clean Architecture**|Paul S. Brown et.al.|[2108.04621v1](http://arxiv.org/abs/2108.04621v1)|**[link](https://github.com/paulbrownmagic/bedsit)**|\n", "2302.10588": "|**2023-07-17**|**STPA for Learning-Enabled Systems: A Survey and A New Practice**|Yi Qi et.al.|[2302.10588v2](http://arxiv.org/abs/2302.10588v2)|null|\n"}, "STPA - CyberSystem": {"2212.10830": "|**2022-12-21**|**A Comparative Risk Analysis on CyberShip System with STPA-Sec, STRIDE and CORAS**|Rishikesh Sahay et.al.|[2212.10830v1](http://arxiv.org/abs/2212.10830v1)|null|\n"}, "STPA - SafetyAnalysis": {"2304.01246": "|**2023-11-05**|**Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT**|Yi Qi et.al.|[2304.01246v2](http://arxiv.org/abs/2304.01246v2)|**[link](https://github.com/yiqi0318/chatgpt-stpa)**|\n", "2211.04602": "|**2022-11-08**|**System Safety Engineering for Social and Ethical ML Risks: A Case Study**|Edgar W. Jatho III et.al.|[2211.04602v1](http://arxiv.org/abs/2211.04602v1)|null|\n", "1912.02019": "|**2019-12-04**|**Applying systems-theoretic process analysis in the context of cooperative driving**|Joakim Oscarsson et.al.|[1912.02019v1](http://arxiv.org/abs/1912.02019v1)|null|\n", "1804.01715": "|**2018-04-05**|**Combining STPA and BDD for Safety Analysis and Verification in Agile Development: A Controlled Experiment**|Yang Wang et.al.|[1804.01715v1](http://arxiv.org/abs/1804.01715v1)|null|\n", "1703.05375": "|**2018-04-05**|**An Exploratory Study of Applying a Scrum Development Process for Safety-Critical Systems**|Yang Wang et.al.|[1703.05375v3](http://arxiv.org/abs/1703.05375v3)|null|\n", "1703.03657": "|**2017-03-10**|**Using STPA in Compliance with ISO 26262 for Developing a Safe Architecture for Fully Automated Vehicles**|Asim Abdulkhaleq et.al.|[1703.03657v1](http://arxiv.org/abs/1703.03657v1)|null|\n", "1612.03109": "|**2016-12-09**|**A comprehensive safety engineering approach for software-intensive systems based on STPA**|Asim Abdulkhaleq et.al.|[1612.03109v1](http://arxiv.org/abs/1612.03109v1)|null|\n", "1612.03103": "|**2016-12-09**|**A Systematic and Semi-Automatic Safety-Based Test Case Generation Approach Based on Systems-Theoretic Process Analysis**|Asim Abdulkhaleq et.al.|[1612.03103v1](http://arxiv.org/abs/1612.03103v1)|null|\n"}, "LLM - Vehicles": {"2311.14786": "|**2023-11-24**|**GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian Behavior Prediction**|Jia Huang et.al.|[2311.14786v1](http://arxiv.org/abs/2311.14786v1)|null|\n", "2311.13095": "|**2023-11-22**|**Enhancing Logical Reasoning in Large Language Models to Facilitate Legal Applications**|Ha-Thanh Nguyen et.al.|[2311.13095v1](http://arxiv.org/abs/2311.13095v1)|null|\n", "2311.11796": "|**2023-11-20**|**Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems**|Guangjing Wang et.al.|[2311.11796v1](http://arxiv.org/abs/2311.11796v1)|null|\n", "2311.07759": "|**2023-11-13**|**Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems**|Alessandro Oltramari et.al.|[2311.07759v1](http://arxiv.org/abs/2311.07759v1)|null|\n", "2311.07377": "|**2023-11-13**|**Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach**|Xi Zheng et.al.|[2311.07377v1](http://arxiv.org/abs/2311.07377v1)|null|\n", "2311.02807": "|**2023-11-06**|**QualEval: Qualitative Evaluation for Model Improvement**|Vishvak Murahari et.al.|[2311.02807v1](http://arxiv.org/abs/2311.02807v1)|**[link](https://github.com/vmurahari3/qualeval)**|\n", "2310.19080": "|**2023-11-05**|**Reward Finetuning for Faster and More Accurate Unsupervised Object Discovery**|Katie Z Luo et.al.|[2310.19080v2](http://arxiv.org/abs/2310.19080v2)|null|\n", "2310.14414": "|**2023-10-22**|**Vision Language Models in Autonomous Driving and Intelligent Transportation Systems**|Xingcheng Zhou et.al.|[2310.14414v1](http://arxiv.org/abs/2310.14414v1)|**[link](https://github.com/ge25nab/Awesome-VLM-AD-ITS)**|\n", "2310.08034": "|**2023-10-12**|**Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2310.08034v1](http://arxiv.org/abs/2310.08034v1)|null|\n", "2310.07944": "|**2023-10-11**|**AutoRepo: A general framework for multi-modal LLM-based automated construction reporting**|Hongxu Pu et.al.|[2310.07944v1](http://arxiv.org/abs/2310.07944v1)|null|\n", "2310.04304": "|**2023-10-06**|**Coding by Design: GPT-4 empowers Agile Model Driven Development**|Ahmed R. Sadik et.al.|[2310.04304v1](http://arxiv.org/abs/2310.04304v1)|null|\n", "2310.03026": "|**2023-10-13**|**LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving**|Hao Sha et.al.|[2310.03026v2](http://arxiv.org/abs/2310.03026v2)|null|\n", "2310.01415": "|**2023-10-16**|**GPT-Driver: Learning to Drive with GPT**|Jiageng Mao et.al.|[2310.01415v2](http://arxiv.org/abs/2310.01415v2)|**[link](https://github.com/pointscoder/gpt-driver)**|\n", "2310.01412": "|**2023-10-08**|**DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model**|Zhenhua Xu et.al.|[2310.01412v2](http://arxiv.org/abs/2310.01412v2)|null|\n", "2309.16052": "|**2023-09-27**|**OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language**|Ruochu Yang et.al.|[2309.16052v1](http://arxiv.org/abs/2309.16052v1)|null|\n", "2309.15289": "|**2023-10-18**|**SEPT: Towards Efficient Scene Representation Learning for Motion Prediction**|Zhiqian Lan et.al.|[2309.15289v3](http://arxiv.org/abs/2309.15289v3)|null|\n", "2309.10228": "|**2023-09-19**|**Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2309.10228v1](http://arxiv.org/abs/2309.10228v1)|null|\n", "2309.07864": "|**2023-09-19**|**The Rise and Potential of Large Language Model Based Agents: A Survey**|Zhiheng Xi et.al.|[2309.07864v3](http://arxiv.org/abs/2309.07864v3)|**[link](https://github.com/woooodyy/llm-agent-paper-list)**|\n", "2309.06424": "|**2023-09-12**|**Unveiling the potential of large language models in generating semantic and cross-language clones**|Palash R. Roy et.al.|[2309.06424v1](http://arxiv.org/abs/2309.06424v1)|null|\n", "2309.05186": "|**2023-09-11**|**HiLM-D: Towards High-Resolution Understanding in Multimodal Large Language Models for Autonomous Driving**|Xinpeng Ding et.al.|[2309.05186v1](http://arxiv.org/abs/2309.05186v1)|null|\n", "2308.10380": "|**2023-08-23**|**A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability**|Ming Jin et.al.|[2308.10380v2](http://arxiv.org/abs/2308.10380v2)|null|\n", "2307.07947": "|**2023-07-16**|**Language Conditioned Traffic Generation**|Shuhan Tan et.al.|[2307.07947v1](http://arxiv.org/abs/2307.07947v1)|**[link](https://github.com/Ariostgx/lctgen)**|\n", "2306.06344": "|**2023-10-18**|**Language-Guided Traffic Simulation via Scene-Level Diffusion**|Ziyuan Zhong et.al.|[2306.06344v2](http://arxiv.org/abs/2306.06344v2)|null|\n", "2305.06018": "|**2023-10-08**|**TARGET: Automated Scenario Generation from Traffic Rules for Testing Autonomous Vehicles**|Yao Deng et.al.|[2305.06018v2](http://arxiv.org/abs/2305.06018v2)|null|\n", "2303.00973": "|**2023-09-06**|**Image Labels Are All You Need for Coarse Seagrass Segmentation**|Scarlett Raine et.al.|[2303.00973v2](http://arxiv.org/abs/2303.00973v2)|**[link](https://github.com/sgraine/bag-of-seagrass)**|\n", "2302.02231": "|**2023-05-19**|**PubGraph: A Large-Scale Scientific Knowledge Graph**|Kian Ahrabian et.al.|[2302.02231v2](http://arxiv.org/abs/2302.02231v2)|null|\n", "2212.08681": "|**2022-12-16**|**Plansformer: Generating Symbolic Plans using Transformers**|Vishal Pallagani et.al.|[2212.08681v1](http://arxiv.org/abs/2212.08681v1)|null|\n", "2210.13669": "|**2022-10-25**|**Help me write a poem: Instruction Tuning as a Vehicle for Collaborative Poetry Writing**|Tuhin Chakrabarty et.al.|[2210.13669v1](http://arxiv.org/abs/2210.13669v1)|**[link](https://github.com/vishakhpk/creative-instructions)**|\n"}, "LLM - Robots": {"2311.15649": "|**2023-11-27**|**RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**|Yaran Chen et.al.|[2311.15649v1](http://arxiv.org/abs/2311.15649v1)|null|\n", "2311.14786": "|**2023-11-24**|**GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian Behavior Prediction**|Jia Huang et.al.|[2311.14786v1](http://arxiv.org/abs/2311.14786v1)|null|\n", "2311.14379": "|**2023-11-24**|**Robot Learning in the Era of Foundation Models: A Survey**|Xuan Xiao et.al.|[2311.14379v1](http://arxiv.org/abs/2311.14379v1)|null|\n", "2311.13884": "|**2023-11-23**|**Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**|Bin Zhang et.al.|[2311.13884v1](http://arxiv.org/abs/2311.13884v1)|null|\n", "2311.13549": "|**2023-11-22**|**ADriver-I: A General World Model for Autonomous Driving**|Fan Jia et.al.|[2311.13549v1](http://arxiv.org/abs/2311.13549v1)|null|\n", "2311.12893": "|**2023-11-21**|**A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs**|Jiageng Zhong et.al.|[2311.12893v1](http://arxiv.org/abs/2311.12893v1)|null|\n", "2311.11183": "|**2023-11-18**|**Deploying and Evaluating LLMs to Program Service Mobile Robots**|Zichao Hu et.al.|[2311.11183v1](http://arxiv.org/abs/2311.11183v1)|null|\n", "2311.12871": "|**2023-11-18**|**An Embodied Generalist Agent in 3D World**|Jiangyong Huang et.al.|[2311.12871v1](http://arxiv.org/abs/2311.12871v1)|**[link](https://github.com/embodied-generalist/embodied-generalist)**|\n", "2311.10813": "|**2023-11-21**|**A Language Agent for Autonomous Driving**|Jiageng Mao et.al.|[2311.10813v2](http://arxiv.org/abs/2311.10813v2)|**[link](https://github.com/usc-gvl/agent-driver)**|\n", "2311.10678": "|**2023-11-17**|**Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections**|Lihan Zha et.al.|[2311.10678v1](http://arxiv.org/abs/2311.10678v1)|**[link](https://github.com/Stanford-ILIAD/droc)**|\n", "2311.08957": "|**2023-11-15**|**I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots**|Giulio Antonio Abbo et.al.|[2311.08957v1](http://arxiv.org/abs/2311.08957v1)|null|\n", "2311.10763": "|**2023-11-15**|**Comparing Generalization in Learning with Limited Numbers of Exemplars: Transformer vs. RNN in Attractor Dynamics**|Rui Fukushima et.al.|[2311.10763v1](http://arxiv.org/abs/2311.10763v1)|null|\n", "2311.08206": "|**2023-11-14**|**Human-Centric Autonomous Systems With LLMs for User Command Reasoning**|Yi Yang et.al.|[2311.08206v1](http://arxiv.org/abs/2311.08206v1)|**[link](https://github.com/kth-rpl/drivecmd_llm)**|\n", "2311.07377": "|**2023-11-13**|**Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach**|Xi Zheng et.al.|[2311.07377v1](http://arxiv.org/abs/2311.07377v1)|null|\n", "2311.07226": "|**2023-11-13**|**Large Language Models for Robotics: A Survey**|Fanlong Zeng et.al.|[2311.07226v1](http://arxiv.org/abs/2311.07226v1)|null|\n", "2311.06640": "|**2023-11-11**|**NewsGPT: ChatGPT Integration for Robot-Reporter**|Abdelhadi Hireche et.al.|[2311.06640v1](http://arxiv.org/abs/2311.06640v1)|**[link](https://github.com/aeh1707/NewsGPT_Pepper)**|\n", "2311.03783": "|**2023-11-07**|**Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI**|Song Yaoxian et.al.|[2311.03783v1](http://arxiv.org/abs/2311.03783v1)|null|\n", "2311.02847": "|**2023-11-08**|**Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs**|Wenke Xia et.al.|[2311.02847v2](http://arxiv.org/abs/2311.02847v2)|**[link](https://github.com/gewu-lab/llm_articulated_object_manipulation)**|\n", "2311.02787": "|**2023-11-05**|**Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation**|Yang You et.al.|[2311.02787v1](http://arxiv.org/abs/2311.02787v1)|null|\n", "2311.02379": "|**2023-11-04**|**Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models**|Kun Chu et.al.|[2311.02379v1](http://arxiv.org/abs/2311.02379v1)|null|\n", "2311.04926": "|**2023-11-03**|**More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems**|Irene Hou et.al.|[2311.04926v1](http://arxiv.org/abs/2311.04926v1)|null|\n", "2311.01403": "|**2023-11-02**|**REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots**|Andrea Tagliabue et.al.|[2311.01403v1](http://arxiv.org/abs/2311.01403v1)|null|\n", "2311.10751": "|**2023-11-23**|**ProAgent: From Robotic Process Automation to Agentic Process Automation**|Yining Ye et.al.|[2311.10751v2](http://arxiv.org/abs/2311.10751v2)|**[link](https://github.com/openbmb/proagent)**|\n", "2311.00967": "|**2023-11-02**|**Vision-Language Interpreter for Robot Task Planning**|Keisuke Shirai et.al.|[2311.00967v1](http://arxiv.org/abs/2311.00967v1)|**[link](https://github.com/omron-sinicx/vilain)**|\n", "2311.00926": "|**2023-11-02**|**M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place**|Wentao Yuan et.al.|[2311.00926v1](http://arxiv.org/abs/2311.00926v1)|null|\n", "2311.00153": "|**2023-11-09**|**Towards A Natural Language Interface for Flexible Multi-Agent Task Assignment**|Jake Brawer et.al.|[2311.00153v2](http://arxiv.org/abs/2311.00153v2)|null|\n", "2310.20357": "|**2023-11-01**|**Enhancing the Spatial Awareness Capability of Multi-Modal Large Language Model**|Yongqiang Zhao et.al.|[2310.20357v2](http://arxiv.org/abs/2310.20357v2)|null|\n", "2310.20151": "|**2023-10-31**|**Multi-Agent Consensus Seeking via Large Language Models**|Huaben Chen et.al.|[2310.20151v1](http://arxiv.org/abs/2310.20151v1)|null|\n", "2310.20034": "|**2023-10-30**|**GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning**|Moritz A. Graule et.al.|[2310.20034v1](http://arxiv.org/abs/2310.20034v1)|null|\n", "2311.01468": "|**2023-10-30**|**Remember what you did so you know what to do next**|Manuel R. Ciosici et.al.|[2311.01468v1](http://arxiv.org/abs/2311.01468v1)|null|\n", "2310.19620": "|**2023-10-30**|**Large Trajectory Models are Scalable Motion Predictors and Planners**|Qiao Sun et.al.|[2310.19620v1](http://arxiv.org/abs/2310.19620v1)|**[link](https://github.com/tsinghua-mars-lab/statetransformer)**|\n", "2310.17787": "|**2023-10-26**|**Evaluation of large language models using an Indian language LGBTI+ lexicon**|Aditya Joshi et.al.|[2310.17787v1](http://arxiv.org/abs/2310.17787v1)|null|\n", "2310.17555": "|**2023-10-26**|**Interactive Robot Learning from Verbal Correction**|Huihan Liu et.al.|[2310.17555v1](http://arxiv.org/abs/2310.17555v1)|null|\n", "2310.17372": "|**2023-10-26**|**Dialogue-based generation of self-driving simulation scenarios using Large Language Models**|Antonio Valerio Miceli-Barone et.al.|[2310.17372v1](http://arxiv.org/abs/2310.17372v1)|**[link](https://github.com/avmb/dialogllmscenic)**|\n", "2310.17019": "|**2023-10-25**|**Conditionally Combining Robot Skills using Large Language Models**|K. R. Zentner et.al.|[2310.17019v1](http://arxiv.org/abs/2310.17019v1)|**[link](https://github.com/krzentner/language-world)**|\n", "2310.16035": "|**2023-10-24**|**What's Left? Concept Grounding with Logic-Enhanced Foundation Models**|Joy Hsu et.al.|[2310.16035v1](http://arxiv.org/abs/2310.16035v1)|**[link](https://github.com/joyhsu0504/left)**|\n", "2310.15127": "|**2023-11-20**|**Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models**|Gabriel Sarch et.al.|[2310.15127v2](http://arxiv.org/abs/2310.15127v2)|null|\n", "2310.14092": "|**2023-10-21**|**Learning Reward for Physical Skills using Large Language Model**|Yuwei Zeng et.al.|[2310.14092v1](http://arxiv.org/abs/2310.14092v1)|null|\n", "2310.13639": "|**2023-10-24**|**Contrastive Preference Learning: Learning from Human Feedback without RL**|Joey Hejna et.al.|[2310.13639v2](http://arxiv.org/abs/2310.13639v2)|**[link](https://github.com/jhejna/cpl)**|\n", "2310.13255": "|**2023-10-20**|**Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds**|Sipeng Zheng et.al.|[2310.13255v1](http://arxiv.org/abs/2310.13255v1)|null|\n", "2310.13065": "|**2023-10-19**|**Creative Robot Tool Use with Large Language Models**|Mengdi Xu et.al.|[2310.13065v1](http://arxiv.org/abs/2310.13065v1)|null|\n", "2310.12931": "|**2023-10-19**|**Eureka: Human-Level Reward Design via Coding Large Language Models**|Yecheng Jason Ma et.al.|[2310.12931v1](http://arxiv.org/abs/2310.12931v1)|**[link](https://github.com/eureka-research/Eureka)**|\n", "2311.08412": "|**2023-10-19**|**Exploring Large Language Models as a Source of Common-Sense Knowledge for Robots**|Felix Ocker et.al.|[2311.08412v1](http://arxiv.org/abs/2311.08412v1)|**[link](https://github.com/hri-eu/common_sense_for_robots)**|\n", "2310.12020": "|**2023-10-23**|**LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation**|Shengqiang Zhang et.al.|[2310.12020v2](http://arxiv.org/abs/2310.12020v2)|null|\n", "2310.11604": "|**2023-10-17**|**Language Models as Zero-Shot Trajectory Generators**|Teyun Kwon et.al.|[2310.11604v1](http://arxiv.org/abs/2310.11604v1)|null|\n", "2310.10645": "|**2023-10-16**|**Interactive Task Planning with Language Models**|Boyi Li et.al.|[2310.10645v1](http://arxiv.org/abs/2310.10645v1)|null|\n", "2310.10632": "|**2023-10-16**|**BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology**|Odhran O'Donoghue et.al.|[2310.10632v1](http://arxiv.org/abs/2310.10632v1)|**[link](https://github.com/bioplanner/bioplanner)**|\n", "2310.10221": "|**2023-10-16**|**RoboLLM: Robotic Vision Tasks Grounded on Multimodal Large Language Models**|Zijun Long et.al.|[2310.10221v1](http://arxiv.org/abs/2310.10221v1)|**[link](https://github.com/longkukuhi/armbench)**|\n", "2310.10103": "|**2023-10-16**|**Navigation with Large Language Models: Semantic Guesswork as a Heuristic for Planning**|Dhruv Shah et.al.|[2310.10103v1](http://arxiv.org/abs/2310.10103v1)|null|\n", "2310.10021": "|**2023-10-17**|**Bootstrap Your Own Skills: Learning to Solve New Tasks with Large Language Model Guidance**|Jesse Zhang et.al.|[2310.10021v2](http://arxiv.org/abs/2310.10021v2)|null|\n", "2310.09676": "|**2023-10-14**|**Mastering Robot Manipulation with Multimodal Prompts through Pretraining and Multi-task Fine-tuning**|Jiachen Li et.al.|[2310.09676v1](http://arxiv.org/abs/2310.09676v1)|null|\n", "2310.09503": "|**2023-10-20**|**JM3D & JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues**|Jiayi Ji et.al.|[2310.09503v2](http://arxiv.org/abs/2310.09503v2)|**[link](https://github.com/mr-neko/jm3d)**|\n", "2310.09454": "|**2023-10-14**|**LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents**|Yash Shukla et.al.|[2310.09454v1](http://arxiv.org/abs/2310.09454v1)|null|\n", "2310.08873": "|**2023-10-13**|**Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models**|Zhen Zhang et.al.|[2310.08873v1](http://arxiv.org/abs/2310.08873v1)|null|\n", "2310.08669": "|**2023-11-06**|**Multimodal Large Language Model for Visual Navigation**|Yao-Hung Hubert Tsai et.al.|[2310.08669v2](http://arxiv.org/abs/2310.08669v2)|null|\n", "2310.08582": "|**2023-10-12**|**Tree-Planner: Efficient Close-loop Task Planning with Large Language Models**|Mengkang Hu et.al.|[2310.08582v1](http://arxiv.org/abs/2310.08582v1)|null|\n", "2310.08034": "|**2023-10-12**|**Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2310.08034v1](http://arxiv.org/abs/2310.08034v1)|null|\n", "2310.07968": "|**2023-10-12**|**Think, Act, and Ask: Open-World Interactive Personalized Robot Navigation**|Yinpei Dai et.al.|[2310.07968v1](http://arxiv.org/abs/2310.07968v1)|null|\n", "2310.07937": "|**2023-10-11**|**Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models**|Bangguo Yu et.al.|[2310.07937v1](http://arxiv.org/abs/2310.07937v1)|null|\n", "2310.07889": "|**2023-10-11**|**LangNav: Language as a Perceptual Representation for Navigation**|Bowen Pan et.al.|[2310.07889v1](http://arxiv.org/abs/2310.07889v1)|null|\n", "2310.07263": "|**2023-10-11**|**CoPAL: Corrective Planning of Robot Actions with Large Language Models**|Frank Joublin et.al.|[2310.07263v1](http://arxiv.org/abs/2310.07263v1)|null|\n", "2310.07018": "|**2023-10-10**|**NEWTON: Are Large Language Models Capable of Physical Reasoning?**|Yi Ru Wang et.al.|[2310.07018v1](http://arxiv.org/abs/2310.07018v1)|null|\n", "2310.06646": "|**2023-10-10**|**Forgetful Large Language Models: Lessons Learned from Using LLMs in Robot Programming**|Juo-Tung Chen et.al.|[2310.06646v1](http://arxiv.org/abs/2310.06646v1)|null|\n", "2310.06303": "|**2023-10-10**|**Dobby: A Conversational Service Robot Driven by GPT-4**|Carson Stark et.al.|[2310.06303v1](http://arxiv.org/abs/2310.06303v1)|null|\n", "2310.06226": "|**2023-10-10**|**Words into Action: Learning Diverse Humanoid Robot Behaviors using Language Guided Iterative Motion Refinement**|K. Niranjan Kumar et.al.|[2310.06226v1](http://arxiv.org/abs/2310.06226v1)|null|\n", "2310.10673": "|**2023-10-09**|**Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate Emotion Probability Vectors**|David Sinclair et.al.|[2310.10673v1](http://arxiv.org/abs/2310.10673v1)|null|\n", "2310.05239": "|**2023-10-08**|**LAN-grasp: Using Large Language Models for Semantic Object Grasping**|Reihaneh Mirjalili et.al.|[2310.05239v1](http://arxiv.org/abs/2310.05239v1)|null|\n", "2310.04981": "|**2023-10-08**|**Compositional Semantics for Open Vocabulary Spatio-semantic Representations**|Robin Karlsson et.al.|[2310.04981v1](http://arxiv.org/abs/2310.04981v1)|null|\n", "2310.03026": "|**2023-10-13**|**LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving**|Hao Sha et.al.|[2310.03026v2](http://arxiv.org/abs/2310.03026v2)|null|\n", "2310.02264": "|**2023-10-03**|**Generalizable Long-Horizon Manipulations with Large Language Models**|Haoyu Zhou et.al.|[2310.02264v1](http://arxiv.org/abs/2310.02264v1)|null|\n", "2310.02071": "|**2023-10-16**|**Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond**|Liang Chen et.al.|[2310.02071v3](http://arxiv.org/abs/2310.02071v3)|**[link](https://github.com/pkunlp-icler/pca-eval)**|\n", "2310.02031": "|**2023-10-25**|**OceanGPT: A Large Language Model for Ocean Science Tasks**|Zhen Bi et.al.|[2310.02031v4](http://arxiv.org/abs/2310.02031v4)|**[link](https://github.com/zjunlp/knowlm)**|\n", "2310.01957": "|**2023-10-13**|**Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving**|Long Chen et.al.|[2310.01957v2](http://arxiv.org/abs/2310.01957v2)|**[link](https://github.com/wayveai/driving-with-llms)**|\n", "2310.01415": "|**2023-10-16**|**GPT-Driver: Learning to Drive with GPT**|Jiageng Mao et.al.|[2310.01415v2](http://arxiv.org/abs/2310.01415v2)|**[link](https://github.com/pointscoder/gpt-driver)**|\n", "2310.01412": "|**2023-10-08**|**DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model**|Zhenhua Xu et.al.|[2310.01412v2](http://arxiv.org/abs/2310.01412v2)|null|\n", "2310.01361": "|**2023-10-02**|**GenSim: Generating Robotic Simulation Tasks via Large Language Models**|Lirui Wang et.al.|[2310.01361v1](http://arxiv.org/abs/2310.01361v1)|**[link](https://github.com/liruiw/gensim)**|\n", "2310.00658": "|**2023-10-01**|**The Robots are Here: Navigating the Generative AI Revolution in Computing Education**|James Prather et.al.|[2310.00658v1](http://arxiv.org/abs/2310.00658v1)|null|\n", "2310.00481": "|**2023-09-30**|**LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments**|Chak Lam Shek et.al.|[2310.00481v1](http://arxiv.org/abs/2310.00481v1)|null|\n", "2310.00163": "|**2023-09-29**|**Cook2LTL: Translating Cooking Recipes to LTL Formulae using Large Language Models**|Angelos Mavrogiannis et.al.|[2310.00163v1](http://arxiv.org/abs/2310.00163v1)|**[link](https://github.com/angmavrogiannis/cook2ltl-translating-cooking-recipes-to-primitive-ltl-action-formulae)**|\n", "2309.16898": "|**2023-09-28**|**A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM**|JongYoon Lim et.al.|[2309.16898v1](http://arxiv.org/abs/2309.16898v1)|null|\n", "2309.16347": "|**2023-09-28**|**Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks**|Eleftherios Triantafyllidis et.al.|[2309.16347v1](http://arxiv.org/abs/2309.16347v1)|null|\n", "2309.16292": "|**2023-10-12**|**DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models**|Licheng Wen et.al.|[2309.16292v2](http://arxiv.org/abs/2309.16292v2)|null|\n", "2309.16739": "|**2023-09-28**|**Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities**|Zheng Lin et.al.|[2309.16739v1](http://arxiv.org/abs/2309.16739v1)|null|\n", "2309.16052": "|**2023-09-27**|**OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language**|Ruochu Yang et.al.|[2309.16052v1](http://arxiv.org/abs/2309.16052v1)|null|\n", "2309.16031": "|**2023-09-27**|**DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs**|Gyeongmin Kim et.al.|[2309.16031v1](http://arxiv.org/abs/2309.16031v1)|null|\n", "2309.15943": "|**2023-09-27**|**Scalable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems?**|Yongchao Chen et.al.|[2309.15943v1](http://arxiv.org/abs/2309.15943v1)|null|\n", "2309.15577": "|**2023-09-27**|**An Evaluation of ChatGPT-4's Qualitative Spatial Reasoning Capabilities in RCC-8**|Anthony G Cohn et.al.|[2309.15577v1](http://arxiv.org/abs/2309.15577v1)|null|\n", "2309.15065": "|**2023-09-26**|**Language-EXtended Indoor SLAM (LEXIS): A Versatile System for Real-time Visual Scene Understanding**|Christina Kassab et.al.|[2309.15065v1](http://arxiv.org/abs/2309.15065v1)|null|\n", "2309.15049": "|**2023-09-26**|**When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications**|Enrico Saccon et.al.|[2309.15049v1](http://arxiv.org/abs/2309.15049v1)|null|\n", "2309.14945": "|**2023-09-26**|**Integration of Large Language Models within Cognitive Architectures for Autonomous Robots**|Miguel \u00c1. Gonz\u00e1lez-Santamarta et.al.|[2309.14945v1](http://arxiv.org/abs/2309.14945v1)|null|\n", "2309.14321": "|**2023-10-24**|**Lifelong Robot Learning with Human Assisted Language Planners**|Meenal Parakh et.al.|[2309.14321v2](http://arxiv.org/abs/2309.14321v2)|null|\n", "2309.13937": "|**2023-09-25**|**SPOTS: Stable Placement of Objects with Reasoning in Semi-Autonomous Teleoperation Systems**|Joonhyung Lee et.al.|[2309.13937v1](http://arxiv.org/abs/2309.13937v1)|null|\n", "2309.12311": "|**2023-09-21**|**LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent**|Jianing Yang et.al.|[2309.12311v1](http://arxiv.org/abs/2309.12311v1)|null|\n", "2309.12089": "|**2023-09-21**|**HiCRISP: A Hierarchical Closed-Loop Robotic Intelligent Self-Correction Planner**|Chenlin Ming et.al.|[2309.12089v1](http://arxiv.org/abs/2309.12089v1)|**[link](https://github.com/ming-bot/HiCRISP)**|\n", "2309.11489": "|**2023-09-21**|**Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning**|Tianbao Xie et.al.|[2309.11489v2](http://arxiv.org/abs/2309.11489v2)|**[link](https://github.com/xlang-ai/text2reward)**|\n", "2309.11382": "|**2023-09-20**|**Discuss Before Moving: Visual Language Navigation via Multi-expert Discussions**|Yuxing Long et.al.|[2309.11382v1](http://arxiv.org/abs/2309.11382v1)|null|\n", "2309.11359": "|**2023-09-20**|**Prompt, Plan, Perform: LLM-based Humanoid Control via Quantized Imitation Learning**|Jingkai Sun et.al.|[2309.11359v1](http://arxiv.org/abs/2309.11359v1)|null|\n", "2309.10346": "|**2023-09-19**|**Explaining Agent Behavior with Large Language Models**|Xijia Zhang et.al.|[2309.10346v1](http://arxiv.org/abs/2309.10346v1)|null|\n", "2309.10103": "|**2023-09-18**|**Reasoning about the Unseen for Efficient Outdoor Object Navigation**|Quanting Xie et.al.|[2309.10103v1](http://arxiv.org/abs/2309.10103v1)|**[link](https://github.com/quantingxie/reasonedexplorer)**|\n", "2309.10092": "|**2023-09-18**|**Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help**|Jun Wang et.al.|[2309.10092v1](http://arxiv.org/abs/2309.10092v1)|null|\n", "2309.10062": "|**2023-09-18**|**SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models**|Shyam Sundar Kannan et.al.|[2309.10062v1](http://arxiv.org/abs/2309.10062v1)|null|\n", "2309.09969": "|**2023-11-17**|**Prompt a Robot to Walk with Large Language Models**|Yen-Jen Wang et.al.|[2309.09969v2](http://arxiv.org/abs/2309.09969v2)|**[link](https://github.com/HybridRobotics/prompt2walk)**|\n", "2309.09919": "|**2023-10-14**|**Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents**|Ziyi Yang et.al.|[2309.09919v2](http://arxiv.org/abs/2309.09919v2)|null|\n", "2309.09182": "|**2023-09-17**|**Optimal Scene Graph Planning with Large Language Model Guidance**|Zhirui Dai et.al.|[2309.09182v1](http://arxiv.org/abs/2309.09182v1)|null|\n", "2309.09181": "|**2023-09-17**|**From Cooking Recipes to Robot Task Trees -- Improving Planning Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network**|Md Sadman Sakib et.al.|[2309.09181v1](http://arxiv.org/abs/2309.09181v1)|null|\n", "2309.08587": "|**2023-09-21**|**Compositional Foundation Models for Hierarchical Planning**|Anurag Ajay et.al.|[2309.08587v2](http://arxiv.org/abs/2309.08587v2)|null|\n", "2309.08138": "|**2023-11-06**|**Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation**|Hongcheng Wang et.al.|[2309.08138v3](http://arxiv.org/abs/2309.08138v3)|**[link](https://github.com/whcpumpkin/demand-driven-navigation)**|\n", "2309.07726": "|**2023-09-14**|**GRID: Scene-Graph-based Instruction-driven Robotic Task Planning**|Zhe Ni et.al.|[2309.07726v1](http://arxiv.org/abs/2309.07726v1)|null|\n", "2309.06687": "|**2023-10-02**|**Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics**|Jiayang Song et.al.|[2309.06687v2](http://arxiv.org/abs/2309.06687v2)|**[link](https://github.com/zhehuazhou/llm_reward_design)**|\n", "2309.04316": "|**2023-11-02**|**Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models**|Leonard B\u00e4rmann et.al.|[2309.04316v2](http://arxiv.org/abs/2309.04316v2)|null|\n", "2309.04077": "|**2023-09-22**|**SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments**|Abhinav Rajvanshi et.al.|[2309.04077v3](http://arxiv.org/abs/2309.04077v3)|null|\n", "2309.02721": "|**2023-09-07**|**Gesture-Informed Robot Assistance via Foundation Models**|Li-Heng Lin et.al.|[2309.02721v2](http://arxiv.org/abs/2309.02721v2)|null|\n", "2309.02561": "|**2023-09-13**|**Physically Grounded Vision-Language Models for Robotic Manipulation**|Jensen Gao et.al.|[2309.02561v2](http://arxiv.org/abs/2309.02561v2)|null|\n", "2309.01664": "|**2023-09-04**|**Fine-grained Affective Processing Capabilities Emerging from Large Language Models**|Joost Broekens et.al.|[2309.01664v1](http://arxiv.org/abs/2309.01664v1)|null|\n", "2309.00904": "|**2023-11-22**|**Developmental Scaffolding with Large Language Models**|Batuhan Celik et.al.|[2309.00904v2](http://arxiv.org/abs/2309.00904v2)|null|\n", "2308.16529": "|**2023-08-31**|**Developing Social Robots with Empathetic Non-Verbal Cues Using Large Language Models**|Yoon Kyung Lee et.al.|[2308.16529v1](http://arxiv.org/abs/2308.16529v1)|null|\n", "2308.16493": "|**2023-08-31**|**Expanding Frozen Vision-Language Models without Retraining: Towards Improved Robot Perception**|Riley Tavassoli et.al.|[2308.16493v1](http://arxiv.org/abs/2308.16493v1)|null|\n", "2308.15962": "|**2023-08-31**|**WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model**|Tianyu Wang et.al.|[2308.15962v2](http://arxiv.org/abs/2308.15962v2)|null|\n", "2308.15684": "|**2023-10-18**|**Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model**|Kazuki Hori et.al.|[2308.15684v2](http://arxiv.org/abs/2308.15684v2)|null|\n", "2308.15231": "|**2023-08-29**|**Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering**|Angus Addlesee et.al.|[2308.15231v1](http://arxiv.org/abs/2308.15231v1)|**[link](https://github.com/addleseehq/mpgt-eval)**|\n", "2308.15214": "|**2023-08-30**|**FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions**|Neeraj Cherakara et.al.|[2308.15214v2](http://arxiv.org/abs/2308.15214v2)|null|\n", "2308.14972": "|**2023-08-29**|**LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks**|Haokun Liu et.al.|[2308.14972v1](http://arxiv.org/abs/2308.14972v1)|null|\n", "2308.13724": "|**2023-08-26**|**ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning**|Zhehua Zhou et.al.|[2308.13724v1](http://arxiv.org/abs/2308.13724v1)|**[link](https://github.com/zhehuazhou/isr-llm)**|\n", "2308.13278": "|**2023-08-25**|**Integrating LLMs and Decision Transformers for Language Grounded Generative Quality-Diversity**|Achkan Salehi et.al.|[2308.13278v1](http://arxiv.org/abs/2308.13278v1)|**[link](https://github.com/salehiac/languagegroundedqd)**|\n", "2308.11339": "|**2023-08-28**|**ProAgent: Building Proactive Cooperative AI with Large Language Models**|Ceyao Zhang et.al.|[2308.11339v2](http://arxiv.org/abs/2308.11339v2)|null|\n", "2308.11236": "|**2023-08-23**|**ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts**|Bilel Benjdira et.al.|[2308.11236v2](http://arxiv.org/abs/2308.11236v2)|**[link](https://github.com/bilel-bj/rosgpt_vision)**|\n", "2308.10141": "|**2023-08-20**|**March in Chat: Interactive Prompting for Remote Embodied Referring Expression**|Yanyuan Qiao et.al.|[2308.10141v1](http://arxiv.org/abs/2308.10141v1)|**[link](https://github.com/yanyuanqiao/mic)**|\n", "2308.08520": "|**2023-08-16**|**Painter: Teaching Auto-regressive Language Models to Draw Sketches**|Reza Pourreza et.al.|[2308.08520v1](http://arxiv.org/abs/2308.08520v1)|null|\n", "2308.07997": "|**2023-08-15**|**$A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models**|Peihao Chen et.al.|[2308.07997v1](http://arxiv.org/abs/2308.07997v1)|null|\n", "2308.06810": "|**2023-10-01**|**Ground Manipulator Primitive Tasks to Executable Actions using Large Language Models**|Yue Cao et.al.|[2308.06810v2](http://arxiv.org/abs/2308.06810v2)|null|\n", "2308.06391": "|**2023-08-11**|**Dynamic Planning with a LLM**|Gautier Dagan et.al.|[2308.06391v1](http://arxiv.org/abs/2308.06391v1)|**[link](https://github.com/itl-ed/llm-dp)**|\n", "2308.04029": "|**2023-08-09**|**ChatSim: Underwater Simulation with Natural Language Prompting**|Aadi Palnitkar et.al.|[2308.04029v2](http://arxiv.org/abs/2308.04029v2)|**[link](https://github.com/apalkk/prg-underwater-simulation)**|\n", "2308.01734": "|**2023-08-03**|**Ambient Adventures: Teaching ChatGPT on Developing Complex Stories**|Zexin Chen et.al.|[2308.01734v1](http://arxiv.org/abs/2308.01734v1)|null|\n", "2307.14535": "|**2023-10-01**|**Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition**|Huy Ha et.al.|[2307.14535v2](http://arxiv.org/abs/2307.14535v2)|**[link](https://github.com/real-stanford/scalingup)**|\n", "2307.13204": "|**2023-09-20**|**GraspGPT: Leveraging Semantic Knowledge from a Large Language Model for Task-Oriented Grasping**|Chao Tang et.al.|[2307.13204v3](http://arxiv.org/abs/2307.13204v3)|null|\n", "2307.12981": "|**2023-07-24**|**3D-LLM: Injecting the 3D World into Large Language Models**|Yining Hong et.al.|[2307.12981v1](http://arxiv.org/abs/2307.12981v1)|null|\n", "2307.11922": "|**2023-07-21**|**Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors**|Kolby Nottingham et.al.|[2307.11922v1](http://arxiv.org/abs/2307.11922v1)|null|\n", "2307.11865": "|**2023-10-06**|**CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots**|Dmitriy Rivkin et.al.|[2307.11865v2](http://arxiv.org/abs/2307.11865v2)|null|\n", "2307.11319": "|**2023-09-17**|**\"Tidy Up the Table\": Grounding Common-sense Objective for Tabletop Object Rearrangement**|Yiqing Xu et.al.|[2307.11319v2](http://arxiv.org/abs/2307.11319v2)|null|\n", "2307.10690": "|**2023-07-20**|**Bridging Intelligence and Instinct: A New Control Paradigm for Autonomous Robots**|Shimian Zhang et.al.|[2307.10690v1](http://arxiv.org/abs/2307.10690v1)|null|\n", "2307.09923": "|**2023-07-19**|**Large Language Models can accomplish Business Process Management Tasks**|Michael Grohs et.al.|[2307.09923v1](http://arxiv.org/abs/2307.09923v1)|null|\n", "2307.07696": "|**2023-07-15**|**Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text**|Zhun Yang et.al.|[2307.07696v1](http://arxiv.org/abs/2307.07696v1)|**[link](https://github.com/azreasoners/llm-asp)**|\n", "2307.07162": "|**2023-07-14**|**Drive Like a Human: Rethinking Autonomous Driving with Large Language Models**|Daocheng Fu et.al.|[2307.07162v1](http://arxiv.org/abs/2307.07162v1)|**[link](https://github.com/PJLab-ADG/driveLikeAHuman)**|\n", "2307.06435": "|**2023-11-23**|**A Comprehensive Overview of Large Language Models**|Humza Naveed et.al.|[2307.06435v6](http://arxiv.org/abs/2307.06435v6)|**[link](https://github.com/humza909/llm_survey)**|\n", "2307.06135": "|**2023-09-27**|**SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning**|Krishan Rana et.al.|[2307.06135v2](http://arxiv.org/abs/2307.06135v2)|null|\n", "2307.05973": "|**2023-11-02**|**VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models**|Wenlong Huang et.al.|[2307.05973v2](http://arxiv.org/abs/2307.05973v2)|**[link](https://github.com/huangwl18/voxposer)**|\n", "2307.04738": "|**2023-07-10**|**RoCo: Dialectic Multi-Robot Collaboration with Large Language Models**|Zhao Mandi et.al.|[2307.04738v1](http://arxiv.org/abs/2307.04738v1)|**[link](https://github.com/MandiZhao/robot-collab)**|\n", "2307.04721": "|**2023-10-26**|**Large Language Models as General Pattern Machines**|Suvir Mirchandani et.al.|[2307.04721v2](http://arxiv.org/abs/2307.04721v2)|null|\n", "2307.01928": "|**2023-09-04**|**Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners**|Allen Z. Ren et.al.|[2307.01928v2](http://arxiv.org/abs/2307.01928v2)|null|\n", "2307.01848": "|**2023-07-04**|**Embodied Task Planning with Large Language Models**|Zhenyu Wu et.al.|[2307.01848v1](http://arxiv.org/abs/2307.01848v1)|**[link](https://github.com/Gary3410/TaPA)**|\n", "2307.00329": "|**2023-09-30**|**DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment**|Yanjiang Guo et.al.|[2307.00329v3](http://arxiv.org/abs/2307.00329v3)|null|\n", "2306.17840": "|**2023-07-03**|**Statler: State-Maintaining Language Models for Embodied Reasoning**|Takuma Yoneda et.al.|[2306.17840v2](http://arxiv.org/abs/2306.17840v2)|null|\n", "2306.15724": "|**2023-10-16**|**REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction**|Zeyi Liu et.al.|[2306.15724v4](http://arxiv.org/abs/2306.15724v4)|**[link](https://github.com/real-stanford/reflect)**|\n", "2306.11886": "|**2023-10-01**|**SPRINT: Scalable Policy Pre-Training via Language Instruction Relabeling**|Jesse Zhang et.al.|[2306.11886v2](http://arxiv.org/abs/2306.11886v2)|null|\n", "2306.10985": "|**2023-06-19**|**LARG, Language-based Automatic Reward and Goal Generation**|Julien Perez et.al.|[2306.10985v1](http://arxiv.org/abs/2306.10985v1)|null|\n", "2306.10376": "|**2023-10-23**|**CLARA: Classifying and Disambiguating User Commands for Reliable Interactive Robotic Agents**|Jeongeun Park et.al.|[2306.10376v5](http://arxiv.org/abs/2306.10376v5)|null|\n", "2306.10322": "|**2023-09-26**|**MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation**|Xiwen Liang et.al.|[2306.10322v2](http://arxiv.org/abs/2306.10322v2)|null|\n", "2306.09922": "|**2023-06-16**|**Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions**|Chad DeChant et.al.|[2306.09922v1](http://arxiv.org/abs/2306.09922v1)|null|\n", "2306.09523": "|**2023-06-19**|**Tell Me Where to Go: A Composable Framework for Context-Aware Embodied Robot Navigation**|Harel Biggie et.al.|[2306.09523v2](http://arxiv.org/abs/2306.09523v2)|null|\n", "2306.09273": "|**2023-09-17**|**Your Room is not Private: Gradient Inversion Attack on Reinforcement Learning**|Miao Li et.al.|[2306.09273v2](http://arxiv.org/abs/2306.09273v2)|null|\n", "2306.08651": "|**2023-06-14**|**Toward Grounded Social Reasoning**|Minae Kwon et.al.|[2306.08651v1](http://arxiv.org/abs/2306.08651v1)|null|\n", "2306.08647": "|**2023-06-16**|**Language to Rewards for Robotic Skill Synthesis**|Wenhao Yu et.al.|[2306.08647v2](http://arxiv.org/abs/2306.08647v2)|null|\n", "2306.08094": "|**2023-09-25**|**Can ChatGPT Enable ITS? The Case of Mixed Traffic Control via Reinforcement Learning**|Michael Villarreal et.al.|[2306.08094v2](http://arxiv.org/abs/2306.08094v2)|**[link](https://github.com/tmvllrrl/its-study)**|\n", "2306.07580": "|**2023-09-14**|**SayTap: Language to Quadrupedal Locomotion**|Yujin Tang et.al.|[2306.07580v3](http://arxiv.org/abs/2306.07580v3)|null|\n", "2306.06770": "|**2023-08-22**|**Improving Knowledge Extraction from LLMs for Task Learning through Agent Analysis**|James R. Kirk et.al.|[2306.06770v3](http://arxiv.org/abs/2306.06770v3)|null|\n", "2306.06531": "|**2023-09-27**|**AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers**|Yongchao Chen et.al.|[2306.06531v2](http://arxiv.org/abs/2306.06531v2)|**[link](https://github.com/yongchao98/autotamp)**|\n", "2306.06344": "|**2023-10-18**|**Language-Guided Traffic Simulation via Scene-Level Diffusion**|Ziyuan Zhong et.al.|[2306.06344v2](http://arxiv.org/abs/2306.06344v2)|null|\n", "2306.05696": "|**2023-06-09**|**Embodied Executable Policy Learning with Language-based Scene Summarization**|Jielin Qiu et.al.|[2306.05696v1](http://arxiv.org/abs/2306.05696v1)|null|\n", "2306.05171": "|**2023-06-08**|**Robot Task Planning Based on Large Language Model Representing Knowledge with Directed Graph Structures**|Yue Zhen et.al.|[2306.05171v1](http://arxiv.org/abs/2306.05171v1)|**[link](https://github.com/nomizy/think_net_prompt)**|\n", "2306.04441": "|**2023-06-07**|**STEPS: A Benchmark for Order Reasoning in Sequential Tasks**|Weizhi Wang et.al.|[2306.04441v1](http://arxiv.org/abs/2306.04441v1)|null|\n", "2306.03809": "|**2023-06-06**|**Can large language models democratize access to dual-use biotechnology?**|Emily H. Soice et.al.|[2306.03809v1](http://arxiv.org/abs/2306.03809v1)|null|\n", "2306.01872": "|**2023-06-02**|**Probabilistic Adaptation of Text-to-Video Models**|Mengjiao Yang et.al.|[2306.01872v1](http://arxiv.org/abs/2306.01872v1)|null|\n", "2306.01540": "|**2023-06-02**|**CLIPGraphs: Multimodal Graph Networks to Infer Object-Room Affinities**|Ayush Agrawal et.al.|[2306.01540v1](http://arxiv.org/abs/2306.01540v1)|null|\n", "2306.00915": "|**2023-08-28**|**The feasibility of artificial consciousness through the lens of neuroscience**|Jaan Aru et.al.|[2306.00915v3](http://arxiv.org/abs/2306.00915v3)|null|\n", "2305.19352": "|**2023-05-30**|**LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model**|Artem Lykov et.al.|[2305.19352v1](http://arxiv.org/abs/2305.19352v1)|null|\n", "2305.18898": "|**2023-05-30**|**AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation**|Chuhao Jin et.al.|[2305.18898v1](http://arxiv.org/abs/2305.18898v1)|null|\n", "2305.17590": "|**2023-10-05**|**Integrating Action Knowledge and LLMs for Task Planning and Situation Handling in Open Worlds**|Yan Ding et.al.|[2305.17590v2](http://arxiv.org/abs/2305.17590v2)|**[link](https://github.com/yding25/GPT-Planner)**|\n", "2305.17390": "|**2023-05-27**|**SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks**|Bill Yuchen Lin et.al.|[2305.17390v1](http://arxiv.org/abs/2305.17390v1)|**[link](https://github.com/yuchenlin/swiftsage)**|\n", "2305.16986": "|**2023-10-19**|**NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models**|Gengze Zhou et.al.|[2305.16986v3](http://arxiv.org/abs/2305.16986v3)|**[link](https://github.com/gengzezhou/navgpt)**|\n", "2305.16744": "|**2023-11-02**|**Demo2Code: From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought**|Huaxiaoyue Wang et.al.|[2305.16744v3](http://arxiv.org/abs/2305.16744v3)|**[link](https://github.com/portal-cornell/robotouille)**|\n", "2305.16366": "|**2023-05-25**|**Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving**|Xueliang Zhao et.al.|[2305.16366v1](http://arxiv.org/abs/2305.16366v1)|**[link](https://github.com/hkunlp/subgoal-theorem-prover)**|\n", "2305.15021": "|**2023-09-13**|**EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought**|Yao Mu et.al.|[2305.15021v2](http://arxiv.org/abs/2305.15021v2)|**[link](https://github.com/EmbodiedGPT/EmbodiedGPT_Pytorch)**|\n", "2305.14167": "|**2023-05-24**|**DetGPT: Detect What You Need via Reasoning**|Renjie Pi et.al.|[2305.14167v2](http://arxiv.org/abs/2305.14167v2)|null|\n", "2305.14078": "|**2023-10-30**|**Large Language Models as Commonsense Knowledge for Large-Scale Task Planning**|Zirui Zhao et.al.|[2305.14078v2](http://arxiv.org/abs/2305.14078v2)|null|\n", "2305.12363": "|**2023-07-01**|**Instance-Level Semantic Maps for Vision Language Navigation**|Laksh Nanwani et.al.|[2305.12363v3](http://arxiv.org/abs/2305.12363v3)|null|\n", "2305.11307": "|**2023-09-11**|**Semantic Anomaly Detection with Large Language Models**|Amine Elhafsi et.al.|[2305.11307v2](http://arxiv.org/abs/2305.11307v2)|null|\n", "2305.11176": "|**2023-05-24**|**Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model**|Siyuan Huang et.al.|[2305.11176v3](http://arxiv.org/abs/2305.11176v3)|**[link](https://github.com/opengvlab/instruct2act)**|\n", "2305.10037": "|**2023-10-30**|**Can Language Models Solve Graph Problems in Natural Language?**|Heng Wang et.al.|[2305.10037v2](http://arxiv.org/abs/2305.10037v2)|**[link](https://github.com/arthur-heng/nlgraph)**|\n", "2305.07716": "|**2023-05-12**|**Learning to Reason over Scene Graphs: A Case Study of Finetuning GPT-2 into a Robot Language Model for Grounded Task Planning**|Georgia Chalvatzaki et.al.|[2305.07716v1](http://arxiv.org/abs/2305.07716v1)|null|\n", "2305.06087": "|**2023-05-10**|**A Glimpse in ChatGPT Capabilities and its impact for AI research**|Frank Joublin et.al.|[2305.06087v1](http://arxiv.org/abs/2305.06087v1)|null|\n", "2305.05658": "|**2023-10-11**|**TidyBot: Personalized Robot Assistance with Large Language Models**|Jimmy Wu et.al.|[2305.05658v2](http://arxiv.org/abs/2305.05658v2)|**[link](https://github.com/jimmyyhwu/tidybot)**|\n", "2305.06358": "|**2023-05-08**|**Accessible Instruction-Following Agent**|Kairui Zhou et.al.|[2305.06358v1](http://arxiv.org/abs/2305.06358v1)|null|\n", "2304.14844": "|**2023-04-28**|**Using Large Language Models for Interpreting Autonomous Robots Behaviors**|Miguel A. Gonz\u00e1lez-Santamarta et.al.|[2304.14844v1](http://arxiv.org/abs/2304.14844v1)|null|\n", "2304.14721": "|**2023-07-24**|**Towards autonomous system: flexible modular production system enhanced with large language model agents**|Yuchen Xia et.al.|[2304.14721v4](http://arxiv.org/abs/2304.14721v4)|**[link](https://github.com/yuchenxia/gpt4industrialautomation)**|\n", "2304.14391": "|**2023-06-12**|**Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement**|Nikolaos Gkanatsios et.al.|[2304.14391v3](http://arxiv.org/abs/2304.14391v3)|null|\n", "2304.13676": "|**2023-04-26**|**Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning**|Selma Wanna et.al.|[2304.13676v1](http://arxiv.org/abs/2304.13676v1)|null|\n", "2304.12958": "|**2023-11-04**|**A Closer Look at Reward Decomposition for High-Level Robotic Explanations**|Wenhao Lu et.al.|[2304.12958v2](http://arxiv.org/abs/2304.12958v2)|null|\n", "2304.12529": "|**2023-04-25**|**Improved Trust in Human-Robot Collaboration with ChatGPT**|Yang Ye et.al.|[2304.12529v1](http://arxiv.org/abs/2304.12529v1)|null|\n", "2304.11520": "|**2023-09-12**|**Processing Natural Language on Embedded Devices: How Well Do Modern Models Perform?**|Souvika Sarkar et.al.|[2304.11520v3](http://arxiv.org/abs/2304.11520v3)|**[link](https://github.com/cps2rl/nlp-on-embedded-devices)**|\n", "2304.11477": "|**2023-09-27**|**LLM+P: Empowering Large Language Models with Optimal Planning Proficiency**|Bo Liu et.al.|[2304.11477v3](http://arxiv.org/abs/2304.11477v3)|**[link](https://github.com/Cranial-XIX/llm-pddl)**|\n"}, "LLM - Prompt": {"2311.15131": "|**2023-11-25**|**Localizing Lying in Llama: Understanding Instructed Dishonesty on True-False Questions Through Prompting, Probing, and Patching**|James Campbell et.al.|[2311.15131v1](http://arxiv.org/abs/2311.15131v1)|null|\n", "2311.13538": "|**2023-11-22**|**Speak Like a Native: Prompting Large Language Models in a Native Style**|Zhicheng Yang et.al.|[2311.13538v1](http://arxiv.org/abs/2311.13538v1)|null|\n", "2311.13274": "|**2023-11-22**|**Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**|Daphne van Zandvoort et.al.|[2311.13274v1](http://arxiv.org/abs/2311.13274v1)|null|\n", "2311.12188": "|**2023-11-20**|**ChatGPT and post-test probability**|Samuel J. Weisenthal et.al.|[2311.12188v1](http://arxiv.org/abs/2311.12188v1)|null|\n", "2311.14730": "|**2023-11-20**|**MemoryCompanion: A Smart Healthcare Solution to Empower Efficient Alzheimer's Care Via Unleashing Generative AI**|Lifei Zheng et.al.|[2311.14730v1](http://arxiv.org/abs/2311.14730v1)|null|\n", "2311.09773": "|**2023-11-16**|**To be or not to be? an exploration of continuously controllable prompt engineering**|Yuhan Sun et.al.|[2311.09773v1](http://arxiv.org/abs/2311.09773v1)|null|\n", "2311.09684": "|**2023-11-16**|**Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation**|Zonghai Yao et.al.|[2311.09684v1](http://arxiv.org/abs/2311.09684v1)|null|\n", "2311.10117": "|**2023-11-16**|**Automatic Engineering of Long Prompts**|Cho-Jui Hsieh et.al.|[2311.10117v1](http://arxiv.org/abs/2311.10117v1)|null|\n", "2311.09618": "|**2023-11-16**|**Simulating Opinion Dynamics with Networks of LLM-based Agents**|Yun-Shiuan Chuang et.al.|[2311.09618v1](http://arxiv.org/abs/2311.09618v1)|null|\n", "2311.09366": "|**2023-11-15**|**LOKE: Linked Open Knowledge Extraction for Automated Knowledge Graph Construction**|Jamie McCusker et.al.|[2311.09366v1](http://arxiv.org/abs/2311.09366v1)|null|\n", "2311.08957": "|**2023-11-15**|**I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots**|Giulio Antonio Abbo et.al.|[2311.08957v1](http://arxiv.org/abs/2311.08957v1)|null|\n", "2311.14708": "|**2023-11-14**|**Large Language Model-Driven Classroom Flipping: Empowering Student-Centric Peer Questioning with Flipped Interaction**|Chee Wei Tan et.al.|[2311.14708v1](http://arxiv.org/abs/2311.14708v1)|null|\n", "2311.07445": "|**2023-11-13**|**Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue**|Junkai Zhou et.al.|[2311.07445v1](http://arxiv.org/abs/2311.07445v1)|null|\n", "2311.07434": "|**2023-11-13**|**Understanding Users' Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level**|Yoonsu Kim et.al.|[2311.07434v1](http://arxiv.org/abs/2311.07434v1)|null|\n", "2311.07387": "|**2023-11-13**|**Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study**|Yinghao Li et.al.|[2311.07387v1](http://arxiv.org/abs/2311.07387v1)|**[link](https://github.com/yinghao-li/minesweeper-for-llm)**|\n", "2311.07237": "|**2023-11-13**|**In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search**|Huihan Li et.al.|[2311.07237v1](http://arxiv.org/abs/2311.07237v1)|**[link](https://github.com/ink-usc/link)**|\n", "2311.07076": "|**2023-11-13**|**On the Discussion of Large Language Models: Symmetry of Agents and Interplay with Prompts**|Qineng Wang et.al.|[2311.07076v1](http://arxiv.org/abs/2311.07076v1)|null|\n", "2311.05661": "|**2023-11-09**|**Prompt Engineering a Prompt Engineer**|Qinyuan Ye et.al.|[2311.05661v1](http://arxiv.org/abs/2311.05661v1)|null|\n", "2311.05169": "|**2023-11-09**|**Large Language Models and Prompt Engineering for Biomedical Query Focused Multi-Document Summarisation**|Diego Moll\u00e1 et.al.|[2311.05169v1](http://arxiv.org/abs/2311.05169v1)|null|\n", "2311.02192": "|**2023-11-03**|**Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models**|Jake Chanenson et.al.|[2311.02192v1](http://arxiv.org/abs/2311.02192v1)|null|\n", "2311.01882": "|**2023-11-03**|**Indicative Summarization of Long Discussions**|Shahbaz Syed et.al.|[2311.01882v1](http://arxiv.org/abs/2311.01882v1)|**[link](https://github.com/webis-de/emnlp-23)**|\n", "2311.01555": "|**2023-11-02**|**Instruction Distillation Makes Large Language Models Efficient Zero-shot Rankers**|Weiwei Sun et.al.|[2311.01555v1](http://arxiv.org/abs/2311.01555v1)|**[link](https://github.com/sunnweiwei/rankgpt)**|\n", "2311.00258": "|**2023-11-01**|**Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis**|Hongyi Zheng et.al.|[2311.00258v1](http://arxiv.org/abs/2311.00258v1)|**[link](https://github.com/hiroki39/noisy-exemplars-make-large-language-models-more-robust)**|\n", "2311.00217": "|**2023-11-01**|**Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias**|S. Lee et.al.|[2311.00217v1](http://arxiv.org/abs/2311.00217v1)|null|\n", "2310.20111": "|**2023-10-31**|**Making Large Language Models Better Data Creators**|Dong-Ho Lee et.al.|[2310.20111v1](http://arxiv.org/abs/2310.20111v1)|**[link](https://github.com/microsoft/llm-data-creation)**|\n", "2310.18025": "|**2023-10-27**|**Large language models for aspect-based sentiment analysis**|Paul F. Simmering et.al.|[2310.18025v1](http://arxiv.org/abs/2310.18025v1)|**[link](https://github.com/qagentur/absa_llm)**|\n", "2310.18373": "|**2023-10-26**|**Can LLMs Grade Short-answer Reading Comprehension Questions : Foundational Literacy Assessment in LMICs**|Owen Henkel et.al.|[2310.18373v1](http://arxiv.org/abs/2310.18373v1)|null|\n", "2310.18358": "|**2023-10-24**|**A Communication Theory Perspective on Prompting Engineering Methods for Large Language Models**|Yuanfeng Song et.al.|[2310.18358v1](http://arxiv.org/abs/2310.18358v1)|null|\n", "2310.15428": "|**2023-10-24**|**ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles**|Savvas Petridis et.al.|[2310.15428v1](http://arxiv.org/abs/2310.15428v1)|null|\n", "2310.15298": "|**2023-10-25**|**TaskDiff: A Similarity Metric for Task-Oriented Conversations**|Ankita Bhaumik et.al.|[2310.15298v2](http://arxiv.org/abs/2310.15298v2)|null|\n", "2310.15127": "|**2023-11-20**|**Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models**|Gabriel Sarch et.al.|[2310.15127v2](http://arxiv.org/abs/2310.15127v2)|null|\n", "2310.14735": "|**2023-10-27**|**Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review**|Banghao Chen et.al.|[2310.14735v2](http://arxiv.org/abs/2310.14735v2)|null|\n", "2310.14201": "|**2023-11-03**|**Prompt Engineering Through the Lens of Optimal Control**|Yifan Luo et.al.|[2310.14201v2](http://arxiv.org/abs/2310.14201v2)|null|\n", "2310.18341": "|**2023-10-31**|**CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images**|Seowoo Lee et.al.|[2310.18341v2](http://arxiv.org/abs/2310.18341v2)|**[link](https://github.com/ecofri/cxr_llava)**|\n", "2310.13896": "|**2023-10-25**|**GPTutor: an open-source AI pair programming tool alternative to Copilot**|Eason Chen et.al.|[2310.13896v3](http://arxiv.org/abs/2310.13896v3)|null|\n", "2310.13226": "|**2023-10-20**|**Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and Prompt Engineering**|Rahman S M Wahidur et.al.|[2310.13226v1](http://arxiv.org/abs/2310.13226v1)|null|\n", "2310.12541": "|**2023-10-25**|**Large Language Model for Multi-objective Evolutionary Optimization**|Fei Liu et.al.|[2310.12541v2](http://arxiv.org/abs/2310.12541v2)|null|\n", "2310.10645": "|**2023-10-16**|**Interactive Task Planning with Language Models**|Boyi Li et.al.|[2310.10645v1](http://arxiv.org/abs/2310.10645v1)|null|\n", "2310.10436": "|**2023-10-16**|**Large Language Model-Empowered Agents for Simulating Macroeconomic Activities**|Nian Li et.al.|[2310.10436v1](http://arxiv.org/abs/2310.10436v1)|null|\n", "2310.09690": "|**2023-10-15**|**Configuration Validation with Large Language Models**|Xinyu Lian et.al.|[2310.09690v1](http://arxiv.org/abs/2310.09690v1)|**[link](https://github.com/ciri4conf/ciri)**|\n", "2310.09235": "|**2023-10-13**|**CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming**|Felicia Li Feng et.al.|[2310.09235v1](http://arxiv.org/abs/2310.09235v1)|null|\n", "2310.08908": "|**2023-10-13**|**Human-in-the-loop Machine Translation with Large Language Model**|Xinyi Yang et.al.|[2310.08908v1](http://arxiv.org/abs/2310.08908v1)|**[link](https://github.com/nlp2ct/hil-mt)**|\n", "2310.08669": "|**2023-11-06**|**Multimodal Large Language Model for Visual Navigation**|Yao-Hung Hubert Tsai et.al.|[2310.08669v2](http://arxiv.org/abs/2310.08669v2)|null|\n", "2310.08101": "|**2023-10-15**|**Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques**|Junxiao Shen et.al.|[2310.08101v2](http://arxiv.org/abs/2310.08101v2)|null|\n", "2310.07653": "|**2023-10-12**|**Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models**|Zeqiang Lai et.al.|[2310.07653v2](http://arxiv.org/abs/2310.07653v2)|**[link](https://github.com/Zeqiang-Lai/MiniDALLE-3)**|\n", "2310.07289": "|**2023-10-11**|**Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators**|Liang Chen et.al.|[2310.07289v1](http://arxiv.org/abs/2310.07289v1)|**[link](https://github.com/chanliang/conner)**|\n", "2310.10508": "|**2023-10-11**|**Prompt Engineering or Fine Tuning: An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks**|Jiho Shin et.al.|[2310.10508v1](http://arxiv.org/abs/2310.10508v1)|null|\n", "2310.06936": "|**2023-10-10**|**LLMs Killed the Script Kiddie: How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing**|Stephen Moskal et.al.|[2310.06936v1](http://arxiv.org/abs/2310.06936v1)|null|\n", "2310.06646": "|**2023-10-10**|**Forgetful Large Language Models: Lessons Learned from Using LLMs in Robot Programming**|Juo-Tung Chen et.al.|[2310.06646v1](http://arxiv.org/abs/2310.06646v1)|null|\n", "2310.06422": "|**2023-11-27**|**Large Language Models for Propaganda Detection**|Kilian Sprenkamp et.al.|[2310.06422v2](http://arxiv.org/abs/2310.06422v2)|**[link](https://github.com/sprenkamp/llm_propaganda_detection)**|\n", "2310.06174": "|**2023-10-09**|**How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?**|Khanin Sisaengsuwanchai et.al.|[2310.06174v1](http://arxiv.org/abs/2310.06174v1)|null|\n", "2310.06072": "|**2023-10-09**|**JVNV: A Corpus of Japanese Emotional Speech with Verbal Content and Nonverbal Expressions**|Detai Xin et.al.|[2310.06072v1](http://arxiv.org/abs/2310.06072v1)|null|\n", "2310.04963": "|**2023-11-05**|**LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation**|Christian Munley et.al.|[2310.04963v2](http://arxiv.org/abs/2310.04963v2)|null|\n", "2310.03965": "|**2023-10-09**|**Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models**|Junchi Yu et.al.|[2310.03965v2](http://arxiv.org/abs/2310.03965v2)|null|\n", "2310.03951": "|**2023-10-09**|**Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations**|Deren Lei et.al.|[2310.03951v2](http://arxiv.org/abs/2310.03951v2)|**[link](https://github.com/microsoft/conli_hallucination)**|\n", "2310.03324": "|**2023-10-05**|**Investigating the Limitation of CLIP Models: The Worst-Performing Categories**|Jie-Jing Shao et.al.|[2310.03324v1](http://arxiv.org/abs/2310.03324v1)|null|\n", "2310.04444": "|**2023-10-10**|**What's the Magic Word? A Control Theory of LLM Prompting**|Aman Bhargava et.al.|[2310.04444v2](http://arxiv.org/abs/2310.04444v2)|**[link](https://github.com/amanb2000/magic_words)**|\n", "2310.01260": "|**2023-10-02**|**SPELL: Semantic Prompt Evolution based on a LLM**|Yujian Betterest Li et.al.|[2310.01260v1](http://arxiv.org/abs/2310.01260v1)|null|\n", "2310.01208": "|**2023-10-02**|**Label Supervised LLaMA Finetuning**|Zongxi Li et.al.|[2310.01208v1](http://arxiv.org/abs/2310.01208v1)|**[link](https://github.com/4ai/ls-llama)**|\n", "2309.17277": "|**2023-10-06**|**Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4**|Jiaxian Guo et.al.|[2309.17277v2](http://arxiv.org/abs/2309.17277v2)|**[link](https://github.com/cr-gjx/suspicion-agent)**|\n", "2309.17249": "|**2023-09-29**|**Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering**|Han Zhou et.al.|[2309.17249v1](http://arxiv.org/abs/2309.17249v1)|null|\n", "2309.16898": "|**2023-09-28**|**A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM**|JongYoon Lim et.al.|[2309.16898v1](http://arxiv.org/abs/2309.16898v1)|null|\n", "2309.16031": "|**2023-09-27**|**DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs**|Gyeongmin Kim et.al.|[2309.16031v1](http://arxiv.org/abs/2309.16031v1)|null|\n", "2309.14779": "|**2023-09-26**|**Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification**|Hengyu Luo et.al.|[2309.14779v1](http://arxiv.org/abs/2309.14779v1)|null|\n", "2309.13426": "|**2023-09-23**|**A Chat About Boring Problems: Studying GPT-based text normalization**|Yang Zhang et.al.|[2309.13426v1](http://arxiv.org/abs/2309.13426v1)|null|\n", "2309.13218": "|**2023-10-18**|**AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling**|Pivithuru Thejan Amarasinghe et.al.|[2309.13218v3](http://arxiv.org/abs/2309.13218v3)|null|\n", "2309.13205": "|**2023-09-22**|**A Practical Survey on Zero-shot Prompt Design for In-context Learning**|Yinheng Li et.al.|[2309.13205v1](http://arxiv.org/abs/2309.13205v1)|null|\n", "2309.12074": "|**2023-11-23**|**How understanding large language models can inform the use of ChatGPT in physics education**|Giulia Polverini et.al.|[2309.12074v3](http://arxiv.org/abs/2309.12074v3)|null|\n", "2309.11385": "|**2023-09-20**|**Safurai 001: New Qualitative Approach for Code LLM Evaluation**|Davide Cifarelli et.al.|[2309.11385v1](http://arxiv.org/abs/2309.11385v1)|**[link](https://github.com/openai/human-eval)**|\n", "2309.10982": "|**2023-09-20**|**Is GPT4 a Good Trader?**|Bingzhe Wu et.al.|[2309.10982v1](http://arxiv.org/abs/2309.10982v1)|null|\n", "2309.09128": "|**2023-09-17**|**ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing**|Ian Arawjo et.al.|[2309.09128v1](http://arxiv.org/abs/2309.09128v1)|**[link](https://github.com/ianarawjo/ChainForge)**|\n", "2309.08181": "|**2023-09-15**|**Large Language Models for Failure Mode Classification: An Investigation**|Michael Stewart et.al.|[2309.08181v1](http://arxiv.org/abs/2309.08181v1)|**[link](https://github.com/nlp-tlp/chatgpt-fmc)**|\n", "2309.08008": "|**2023-09-14**|**An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing**|Sonish Sivarajkumar et.al.|[2309.08008v1](http://arxiv.org/abs/2309.08008v1)|null|\n", "2309.07841": "|**2023-09-14**|**Two Timin': Repairing Smart Contracts With A Two-Layered Approach**|Abhinav Jain et.al.|[2309.07841v1](http://arxiv.org/abs/2309.07841v1)|null|\n", "2309.06424": "|**2023-09-12**|**Unveiling the potential of large language models in generating semantic and cross-language clones**|Palash R. Roy et.al.|[2309.06424v1](http://arxiv.org/abs/2309.06424v1)|null|\n", "2309.04842": "|**2023-09-12**|**Leveraging Large Language Models for Exploiting ASR Uncertainty**|Pranay Dighe et.al.|[2309.04842v2](http://arxiv.org/abs/2309.04842v2)|null|\n", "2309.04716": "|**2023-09-09**|**Toward Reproducing Network Research Results Using Large Language Models**|Qiao Xiang et.al.|[2309.04716v1](http://arxiv.org/abs/2309.04716v1)|null|\n", "2309.04663": "|**2023-09-12**|**FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning**|Xinyi Wang et.al.|[2309.04663v2](http://arxiv.org/abs/2309.04663v2)|null|\n", "2308.16622": "|**2023-08-31**|**Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering**|Lars-Peter Meyer et.al.|[2308.16622v1](http://arxiv.org/abs/2308.16622v1)|**[link](https://github.com/aksw/llm-kg-bench)**|\n", "2308.16361": "|**2023-08-30**|**Large Language Models as Data Preprocessors**|Haochen Zhang et.al.|[2308.16361v1](http://arxiv.org/abs/2308.16361v1)|null|\n", "2308.15363": "|**2023-11-20**|**Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation**|Dawei Gao et.al.|[2308.15363v4](http://arxiv.org/abs/2308.15363v4)|**[link](https://github.com/beachwang/dail-sql)**|\n", "2308.15276": "|**2023-10-02**|**Large Language Models in Fault Localisation**|Yonghao Wu et.al.|[2308.15276v3](http://arxiv.org/abs/2308.15276v3)|**[link](https://github.com/tempupload/flofchatgpt)**|\n", "2308.15231": "|**2023-08-29**|**Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering**|Angus Addlesee et.al.|[2308.15231v1](http://arxiv.org/abs/2308.15231v1)|**[link](https://github.com/addleseehq/mpgt-eval)**|\n", "2308.15214": "|**2023-08-30**|**FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions**|Neeraj Cherakara et.al.|[2308.15214v2](http://arxiv.org/abs/2308.15214v2)|null|\n", "2308.12415": "|**2023-08-23**|**Benchmarking Causal Study to Interpret Large Language Models for Source Code**|Daniel Rodriguez-Cardenas et.al.|[2308.12415v1](http://arxiv.org/abs/2308.12415v1)|null|\n", "2308.10248": "|**2023-11-13**|**Activation Addition: Steering Language Models Without Optimization**|Alexander Matt Turner et.al.|[2308.10248v3](http://arxiv.org/abs/2308.10248v3)|**[link](https://github.com/montemac/activation_additions)**|\n", "2308.09830": "|**2023-09-28**|**Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis**|Oscar J. Romero et.al.|[2308.09830v3](http://arxiv.org/abs/2308.09830v3)|null|\n", "2308.09731": "|**2023-08-17**|**ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT**|Fatemeh Nazary et.al.|[2308.09731v1](http://arxiv.org/abs/2308.09731v1)|**[link](https://github.com/atenanaz/chatgpt-healthprompt)**|\n", "2308.07610": "|**2023-08-15**|**LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis**|Yilun Liu et.al.|[2308.07610v1](http://arxiv.org/abs/2308.07610v1)|null|\n", "2308.07505": "|**2023-10-03**|**Data Race Detection Using Large Language Models**|Le Chen et.al.|[2308.07505v2](http://arxiv.org/abs/2308.07505v2)|null|\n", "2308.07411": "|**2023-08-14**|**Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering**|Edward Junprung et.al.|[2308.07411v1](http://arxiv.org/abs/2308.07411v1)|**[link](https://github.com/ejunprung/llm-agents)**|\n", "2308.07308": "|**2023-10-24**|**LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked**|Mansi Phute et.al.|[2308.07308v3](http://arxiv.org/abs/2308.07308v3)|null|\n", "2308.07935": "|**2023-08-13**|**Transforming Sentiment Analysis in the Financial Domain with ChatGPT**|Georgios Fatouros et.al.|[2308.07935v1](http://arxiv.org/abs/2308.07935v1)|**[link](https://zenodo.org/record/7976208)**|\n", "2308.05345": "|**2023-11-11**|**RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model**|Yao Lu et.al.|[2308.05345v3](http://arxiv.org/abs/2308.05345v3)|**[link](https://github.com/hkust-zhiyao/rtllm)**|\n", "2308.11628": "|**2023-08-08**|**Prompt Engineering For Students of Medicine and Their Teachers**|Thomas F. Heston et.al.|[2308.11628v1](http://arxiv.org/abs/2308.11628v1)|null|\n", "2308.03854": "|**2023-08-07**|**Revisiting Prompt Engineering via Declarative Crowdsourcing**|Aditya G. Parameswaran et.al.|[2308.03854v1](http://arxiv.org/abs/2308.03854v1)|null|\n", "2308.02122": "|**2023-10-27**|**ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP**|Lu Yan et.al.|[2308.02122v2](http://arxiv.org/abs/2308.02122v2)|null|\n", "2308.01666": "|**2023-08-03**|**Evaluating ChatGPT text-mining of clinical records for obesity monitoring**|Ivo S. Fins et.al.|[2308.01666v1](http://arxiv.org/abs/2308.01666v1)|null|\n", "2308.00229": "|**2023-08-01**|**Prompts Matter: Insights and Strategies for Prompt Engineering in Automated Software Traceability**|Alberto D. Rodriguez et.al.|[2308.00229v1](http://arxiv.org/abs/2308.00229v1)|null|\n", "2308.00016": "|**2023-07-31**|**Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment**|Saizhuo Wang et.al.|[2308.00016v1](http://arxiv.org/abs/2308.00016v1)|null|\n", "2307.16180": "|**2023-07-30**|**Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models**|Keyu Pan et.al.|[2307.16180v1](http://arxiv.org/abs/2307.16180v1)|**[link](https://github.com/harderthenharder/transformers_tasks)**|\n", "2307.14984": "|**2023-10-19**|**S3: Social-network Simulation System with Large Language Model-Empowered Agents**|Chen Gao et.al.|[2307.14984v2](http://arxiv.org/abs/2307.14984v2)|null|\n", "2307.14692": "|**2023-07-27**|**Backdoor Attacks for In-Context Learning with Language Models**|Nikhil Kandpal et.al.|[2307.14692v1](http://arxiv.org/abs/2307.14692v1)|null|\n", "2307.13779": "|**2023-07-25**|**Is GPT a Computational Model of Emotion? Detailed Analysis**|Ala N. Tak et.al.|[2307.13779v1](http://arxiv.org/abs/2307.13779v1)|null|\n", "2307.13617": "|**2023-07-26**|**GPT-3 Models are Few-Shot Financial Reasoners**|Raul Salles de Padua et.al.|[2307.13617v2](http://arxiv.org/abs/2307.13617v2)|null|\n", "2307.10633": "|**2023-07-20**|**Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa**|Shriyash K. Upadhyay et.al.|[2307.10633v1](http://arxiv.org/abs/2307.10633v1)|null|\n", "2307.09923": "|**2023-07-19**|**Large Language Models can accomplish Business Process Management Tasks**|Michael Grohs et.al.|[2307.09923v1](http://arxiv.org/abs/2307.09923v1)|null|\n", "2307.09909": "|**2023-07-19**|**Chit-Chat or Deep Talk: Prompt Engineering for Process Mining**|Urszula Jessen et.al.|[2307.09909v1](http://arxiv.org/abs/2307.09909v1)|null|\n", "2307.08925": "|**2023-07-18**|**Federated Large Language Model: A Position Paper**|Chaochao Chen et.al.|[2307.08925v1](http://arxiv.org/abs/2307.08925v1)|null|\n", "2307.11769": "|**2023-07-17**|**Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain**|Yun Tang et.al.|[2307.11769v1](http://arxiv.org/abs/2307.11769v1)|null|\n", "2307.08220": "|**2023-07-17**|**A Lightweight Framework for High-Quality Code Generation**|Mohammed Latif Siddiq et.al.|[2307.08220v1](http://arxiv.org/abs/2307.08220v1)|null|\n", "2307.08152": "|**2023-07-16**|**The Potential and Pitfalls of using a Large Language Model such as ChatGPT or GPT-4 as a Clinical Assistant**|Jingqing Zhang et.al.|[2307.08152v1](http://arxiv.org/abs/2307.08152v1)|null|\n", "2307.07221": "|**2023-07-14**|**Software Testing with Large Language Model: Survey, Landscape, and Vision**|Junjie Wang et.al.|[2307.07221v1](http://arxiv.org/abs/2307.07221v1)|null|\n", "2307.07415": "|**2023-08-08**|**AutoHint: Automatic Prompt Optimization with Hint Generation**|Hong Sun et.al.|[2307.07415v2](http://arxiv.org/abs/2307.07415v2)|null|\n", "2307.04781": "|**2023-08-26**|**Demonstrations of the Potential of AI-based Political Issue Polling**|Nathan E. Sanders et.al.|[2307.04781v2](http://arxiv.org/abs/2307.04781v2)|null|\n", "2307.03941": "|**2023-09-22**|**Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions**|Dawen Zhang et.al.|[2307.03941v3](http://arxiv.org/abs/2307.03941v3)|null|\n", "2307.14349": "|**2023-07-08**|**Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models**|Chee Wei Tan et.al.|[2307.14349v1](http://arxiv.org/abs/2307.14349v1)|null|\n", "2307.02018": "|**2023-07-05**|**Comparative Analysis of GPT-4 and Human Graders in Evaluating Praise Given to Students in Synthetic Dialogues**|Dollaya Hirunyasiri et.al.|[2307.02018v1](http://arxiv.org/abs/2307.02018v1)|null|\n", "2306.13394": "|**2023-07-02**|**MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models**|Chaoyou Fu et.al.|[2306.13394v2](http://arxiv.org/abs/2306.13394v2)|**[link](https://github.com/bradyfu/awesome-multimodal-large-language-models)**|\n", "2306.12656": "|**2023-06-22**|**Identifying and Extracting Rare Disease Phenotypes with Large Language Models**|Cathy Shyr et.al.|[2306.12656v1](http://arxiv.org/abs/2306.12656v1)|**[link](https://github.com/cathyshyr/rare_disease_phenotype_extraction)**|\n", "2306.12338": "|**2023-06-22**|**Do you still need a manual smart contract audit?**|Isaac David et.al.|[2306.12338v2](http://arxiv.org/abs/2306.12338v2)|null|\n", "2306.12255": "|**2023-06-21**|**Solving and Generating NPR Sunday Puzzles with Large Language Models**|Jingmiao Zhao et.al.|[2306.12255v1](http://arxiv.org/abs/2306.12255v1)|**[link](https://github.com/wellesley-easel-lab/puzzleqa)**|\n", "2306.11296": "|**2023-07-20**|**ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis**|Zhiling Zheng et.al.|[2306.11296v2](http://arxiv.org/abs/2306.11296v2)|**[link](https://github.com/zach-zhiling-zheng/chatgpt_chemistry_assistant)**|\n", "2306.08997": "|**2023-06-24**|**Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models**|Sarah J. Zhang et.al.|[2306.08997v2](http://arxiv.org/abs/2306.08997v2)|null|\n", "2306.07536": "|**2023-06-13**|**TART: A plug-and-play Transformer module for task-agnostic reasoning**|Kush Bhatia et.al.|[2306.07536v1](http://arxiv.org/abs/2306.07536v1)|**[link](https://github.com/hazyresearch/tart)**|\n", "2306.06770": "|**2023-08-22**|**Improving Knowledge Extraction from LLMs for Task Learning through Agent Analysis**|James R. Kirk et.al.|[2306.06770v3](http://arxiv.org/abs/2306.06770v3)|null|\n", "2306.06297": "|**2023-06-09**|**Protect Your Prompts: Protocols for IP Protection in LLM Applications**|M. A. van Wyk et.al.|[2306.06297v1](http://arxiv.org/abs/2306.06297v1)|null|\n", "2306.07402": "|**2023-06-08**|**The economic trade-offs of large language models: A case study**|Kristen Howell et.al.|[2306.07402v1](http://arxiv.org/abs/2306.07402v1)|null|\n", "2306.03799": "|**2023-06-06**|**Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models**|Fobo Shi et.al.|[2306.03799v1](http://arxiv.org/abs/2306.03799v1)|null|\n", "2306.03553": "|**2023-06-06**|**An Approach to Solving the Abstraction and Reasoning Corpus (ARC) Challenge**|Tan John Chong Min et.al.|[2306.03553v1](http://arxiv.org/abs/2306.03553v1)|**[link](https://github.com/tanchongmin/arc-challenge)**|\n", "2306.03204": "|**2023-06-05**|**ChatGPT as a mapping assistant: A novel method to enrich maps with generative AI and content derived from street-level photographs**|Levente Juh\u00e1sz et.al.|[2306.03204v1](http://arxiv.org/abs/2306.03204v1)|null|\n", "2306.02776": "|**2023-06-05**|**Cheap-fake Detection with LLM using Prompt Engineering**|Guangyang Wu et.al.|[2306.02776v1](http://arxiv.org/abs/2306.02776v1)|null|\n", "2306.02140": "|**2023-06-03**|**Unsupervised Human Activity Recognition through Two-stage Prompting with ChatGPT**|Qingxin Xia et.al.|[2306.02140v1](http://arxiv.org/abs/2306.02140v1)|null|\n", "2306.01987": "|**2023-07-18**|**Prompting Is All You Need: Automated Android Bug Replay with Large Language Models**|Sidong Feng et.al.|[2306.01987v2](http://arxiv.org/abs/2306.01987v2)|null|\n", "2306.01242": "|**2023-06-02**|**Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators**|Zhizheng Zhang et.al.|[2306.01242v1](http://arxiv.org/abs/2306.01242v1)|null|\n", "2306.00190": "|**2023-05-31**|**Contextualizing Problems to Student Interests at Scale in Intelligent Tutoring System Using Large Language Models**|Gautam Yadav et.al.|[2306.00190v1](http://arxiv.org/abs/2306.00190v1)|null|\n", "2306.01779": "|**2023-05-30**|**Conceptual Design Generation Using Large Language Models**|Kevin Ma et.al.|[2306.01779v1](http://arxiv.org/abs/2306.01779v1)|**[link](https://github.com/kevinma1515/gpt_idetc)**|\n", "2305.18752": "|**2023-05-30**|**GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction**|Rui Yang et.al.|[2305.18752v1](http://arxiv.org/abs/2305.18752v1)|**[link](https://github.com/stevengrove/gpt4tools)**|\n", "2305.18466": "|**2023-06-07**|**Test-Time Training on Nearest Neighbors for Large Language Models**|Moritz Hardt et.al.|[2305.18466v2](http://arxiv.org/abs/2305.18466v2)|**[link](https://github.com/socialfoundations/tttlm)**|\n", "2305.18404": "|**2023-07-08**|**Conformal Prediction with Large Language Models for Multi-Choice Question Answering**|Bhawesh Kumar et.al.|[2305.18404v3](http://arxiv.org/abs/2305.18404v3)|**[link](https://github.com/bhaweshiitk/conformalllm)**|\n", "2305.18620": "|**2023-05-26**|**CONA: A novel CONtext-Aware instruction paradigm for communication using large language model**|Nan Zhou et.al.|[2305.18620v1](http://arxiv.org/abs/2305.18620v1)|null|\n", "2305.13860": "|**2023-05-23**|**Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study**|Yi Liu et.al.|[2305.13860v1](http://arxiv.org/abs/2305.13860v1)|null|\n", "2305.13514": "|**2023-05-22**|**Small Language Models Improve Giants by Rewriting Their Outputs**|Giorgos Vernikos et.al.|[2305.13514v1](http://arxiv.org/abs/2305.13514v1)|null|\n", "2305.09858": "|**2023-05-17**|**Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs**|Jiao Chen et.al.|[2305.09858v1](http://arxiv.org/abs/2305.09858v1)|null|\n", "2305.08714": "|**2023-06-08**|**Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks**|Chengguang Gan et.al.|[2305.08714v2](http://arxiv.org/abs/2305.08714v2)|null|\n", "2305.06972": "|**2023-05-12**|**Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns**|Julian Hazell et.al.|[2305.06972v2](http://arxiv.org/abs/2305.06972v2)|null|\n", "2305.04039": "|**2023-05-06**|**Refining the Responses of LLMs by Themselves**|Tianqiang Yan et.al.|[2305.04039v1](http://arxiv.org/abs/2305.04039v1)|**[link](https://github.com/henryyantq/optimallm)**|\n", "2305.03429": "|**2023-05-05**|**Simulating H.P. Lovecraft horror literature with the ChatGPT large language model**|Eduardo C. Garrido-Merch\u00e1n et.al.|[2305.03429v1](http://arxiv.org/abs/2305.03429v1)|null|\n", "2304.14827": "|**2023-05-11**|**ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations**|Chunkit Chan et.al.|[2304.14827v2](http://arxiv.org/abs/2304.14827v2)|null|\n", "2304.14670": "|**2023-04-28**|**Prompt Engineering for Healthcare: Methodologies and Applications**|Jiaqi Wang et.al.|[2304.14670v1](http://arxiv.org/abs/2304.14670v1)|null|\n", "2304.14456": "|**2023-04-27**|**Framing the News:From Human Perception to Large Language Model Inferences**|David Alonso del Barrio et.al.|[2304.14456v1](http://arxiv.org/abs/2304.14456v1)|null|\n", "2304.13714": "|**2023-05-01**|**Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery**|Debadutta Dash et.al.|[2304.13714v3](http://arxiv.org/abs/2304.13714v3)|null|\n", "2304.11111": "|**2023-04-21**|**Inducing anxiety in large language models increases exploration and bias**|Julian Coda-Forno et.al.|[2304.11111v1](http://arxiv.org/abs/2304.11111v1)|null|\n", "2304.07840": "|**2023-07-21**|**Enhancing Automated Program Repair through Fine-tuning and Prompt Engineering**|Rishov Paul et.al.|[2304.07840v2](http://arxiv.org/abs/2304.07840v2)|null|\n", "2304.06962": "|**2023-04-14**|**Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning**|Chenkai Ma et.al.|[2304.06962v1](http://arxiv.org/abs/2304.06962v1)|null|\n", "2304.06815": "|**2023-08-29**|**Improving Few-Shot Prompts with Relevant Static Analysis Products**|Toufique Ahmed et.al.|[2304.06815v2](http://arxiv.org/abs/2304.06815v2)|null|\n", "2304.06712": "|**2023-08-18**|**What does CLIP know about a red circle? Visual prompt engineering for VLMs**|Aleksandar Shtedritski et.al.|[2304.06712v2](http://arxiv.org/abs/2304.06712v2)|null|\n", "2304.04083": "|**2023-04-08**|**VOICE: Visual Oracle for Interaction, Conversation, and Explanation**|Donggang Jia et.al.|[2304.04083v1](http://arxiv.org/abs/2304.04083v1)|null|\n", "2304.03347": "|**2023-10-11**|**Towards Interpretable Mental Health Analysis with Large Language Models**|Kailai Yang et.al.|[2304.03347v4](http://arxiv.org/abs/2304.03347v4)|**[link](https://github.com/stevekgyang/mentalllama)**|\n", "2304.03022": "|**2023-04-06**|**TagGPT: Large Language Models are Zero-shot Multimodal Taggers**|Chen Li et.al.|[2304.03022v1](http://arxiv.org/abs/2304.03022v1)|**[link](https://github.com/tencentarc/taggpt)**|\n", "2304.02496": "|**2023-04-05**|**Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification**|Shan Chen et.al.|[2304.02496v1](http://arxiv.org/abs/2304.02496v1)|**[link](https://github.com/shan23chen/healthllm_eval)**|\n", "2304.02138": "|**2023-06-21**|**Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering**|Krishna Kumar et.al.|[2304.02138v3](http://arxiv.org/abs/2304.02138v3)|null|\n", "2304.01246": "|**2023-11-05**|**Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT**|Yi Qi et.al.|[2304.01246v2](http://arxiv.org/abs/2304.01246v2)|**[link](https://github.com/yiqi0318/chatgpt-stpa)**|\n", "2303.18116": "|**2023-03-31**|**Pair Programming with Large Language Models for Sampling and Estimation of Copulas**|Jan G\u00f3recki et.al.|[2303.18116v1](http://arxiv.org/abs/2303.18116v1)|null|\n", "2303.17276": "|**2023-03-30**|**Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure**|Philipp Koralus et.al.|[2303.17276v1](http://arxiv.org/abs/2303.17276v1)|null|\n", "2303.16429": "|**2023-03-29**|**Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology**|Tiago Lubiana et.al.|[2303.16429v1](http://arxiv.org/abs/2303.16429v1)|**[link](https://github.com/csbl-br/awesome-compbio-chatgpt)**|\n", "2304.02017": "|**2023-11-15**|**Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing**|Walid Hariri et.al.|[2304.02017v6](http://arxiv.org/abs/2304.02017v6)|null|\n", "2303.08518": "|**2023-10-11**|**UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation**|Daixuan Cheng et.al.|[2303.08518v3](http://arxiv.org/abs/2303.08518v3)|**[link](https://github.com/microsoft/lmops)**|\n", "2303.07142": "|**2023-04-18**|**Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification**|Benjamin Clavi\u00e9 et.al.|[2303.07142v3](http://arxiv.org/abs/2303.07142v3)|null|\n", "2303.05352": "|**2023-06-27**|**Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering**|Maciej P. Polak et.al.|[2303.05352v2](http://arxiv.org/abs/2303.05352v2)|null|\n", "2302.11382": "|**2023-02-21**|**A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT**|Jules White et.al.|[2302.11382v1](http://arxiv.org/abs/2302.11382v1)|null|\n", "2302.02094": "|**2023-02-12**|**Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models**|Paula Maddigan et.al.|[2302.02094v2](http://arxiv.org/abs/2302.02094v2)|null|\n", "2302.01215": "|**2023-02-02**|**Fixing Hardware Security Bugs with Large Language Models**|Baleegh Ahmad et.al.|[2302.01215v1](http://arxiv.org/abs/2302.01215v1)|null|\n", "2301.12073": "|**2023-04-26**|**Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset**|Zhixuan Liu et.al.|[2301.12073v2](http://arxiv.org/abs/2301.12073v2)|**[link](https://github.com/cmubig/ccub)**|\n", "2212.14047": "|**2022-12-27**|**Using Large Language Models to Generate Engaging Captions for Data Visualizations**|Ashley Liew et.al.|[2212.14047v1](http://arxiv.org/abs/2212.14047v1)|null|\n", "2212.02199": "|**2022-12-05**|**Legal Prompt Engineering for Multilingual Legal Judgement Prediction**|Dietrich Trautmann et.al.|[2212.02199v1](http://arxiv.org/abs/2212.02199v1)|null|\n", "2212.01326": "|**2022-12-08**|**Legal Prompting: Teaching a Language Model to Think Like a Lawyer**|Fangyi Yu et.al.|[2212.01326v2](http://arxiv.org/abs/2212.01326v2)|null|\n", "2211.01910": "|**2023-03-10**|**Large Language Models Are Human-Level Prompt Engineers**|Yongchao Zhou et.al.|[2211.01910v2](http://arxiv.org/abs/2211.01910v2)|**[link](https://github.com/keirp/automatic_prompt_engineer)**|\n", "2209.08966": "|**2022-10-05**|**Will It Blend? Mixing Training Paradigms & Prompting for Argument Quality Prediction**|Michiel van der Meer et.al.|[2209.08966v2](http://arxiv.org/abs/2209.08966v2)|null|\n", "2208.07852": "|**2022-08-16**|**Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models**|Hendrik Strobelt et.al.|[2208.07852v1](http://arxiv.org/abs/2208.07852v1)|null|\n", "2205.11605": "|**2022-05-23**|**On Measuring Social Biases in Prompt-Based Multi-Task Learning**|Afra Feyza Aky\u00fcrek et.al.|[2205.11605v1](http://arxiv.org/abs/2205.11605v1)|**[link](https://github.com/feyzaakyurek/bbnli)**|\n", "2205.07407": "|**2022-05-16**|**What GPT Knows About Who is Who**|Xiaohan Yang et.al.|[2205.07407v1](http://arxiv.org/abs/2205.07407v1)|**[link](https://github.com/awesomecoref/prompt-coref)**|\n", "2111.08267": "|**2021-11-16**|**Solving Probability and Statistics Problems by Program Synthesis**|Leonard Tang et.al.|[2111.08267v1](http://arxiv.org/abs/2111.08267v1)|null|\n"}, "LLM - Finetuning": {"2311.15983": "|**2023-11-27**|**Sparsify-then-Classify: From Internal Neurons of Large Language Models To Efficient Text Classifiers**|Yilun Liu et.al.|[2311.15983v1](http://arxiv.org/abs/2311.15983v1)|null|\n", "2311.15879": "|**2023-11-27**|**EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension**|Jiaxuan Li et.al.|[2311.15879v1](http://arxiv.org/abs/2311.15879v1)|null|\n", "2311.15876": "|**2023-11-27**|**RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation and Consistency Regularization**|Kwanyoung Kim et.al.|[2311.15876v1](http://arxiv.org/abs/2311.15876v1)|null|\n", "2311.15786": "|**2023-11-27**|**YUAN 2.0: A Large Language Model with Localized Filtering-based Attention**|Shaohua Wu et.al.|[2311.15786v1](http://arxiv.org/abs/2311.15786v1)|**[link](https://github.com/ieit-yuan/yuan-2.0)**|\n", "2311.15653": "|**2023-11-27**|**MoDS: Model-oriented Data Selection for Instruction Tuning**|Qianlong Du et.al.|[2311.15653v1](http://arxiv.org/abs/2311.15653v1)|null|\n", "2311.15649": "|**2023-11-27**|**RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**|Yaran Chen et.al.|[2311.15649v1](http://arxiv.org/abs/2311.15649v1)|null|\n", "2311.15490": "|**2023-11-27**|**Optimizing and Fine-tuning Large Language Model for Urban Renewal**|Xi Wang et.al.|[2311.15490v1](http://arxiv.org/abs/2311.15490v1)|null|\n", "2311.15271": "|**2023-11-26**|**Synthesizing mixed-integer linear programming models from natural language descriptions**|Qingyang Li et.al.|[2311.15271v1](http://arxiv.org/abs/2311.15271v1)|null|\n", "2311.14543": "|**2023-11-24**|**Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language**|Di Jin et.al.|[2311.14543v1](http://arxiv.org/abs/2311.14543v1)|null|\n", "2311.14519": "|**2023-11-24**|**Benchmarking Large Language Models for Log Analysis, Security, and Interpretation**|Egil Karlsen et.al.|[2311.14519v1](http://arxiv.org/abs/2311.14519v1)|null|\n", "2311.14332": "|**2023-11-24**|**GATGPT: A Pre-trained Large Language Model with Graph Attention Network for Spatiotemporal Imputation**|Yakun Chen et.al.|[2311.14332v1](http://arxiv.org/abs/2311.14332v1)|null|\n", "2311.14284": "|**2023-11-24**|**Paragraph-to-Image Generation with Information-Enriched Diffusion Model**|Weijia Wu et.al.|[2311.14284v1](http://arxiv.org/abs/2311.14284v1)|**[link](https://github.com/weijiawu/paradiffusion)**|\n", "2311.14759": "|**2023-11-23**|**Forecasting Cryptocurrency Prices Using Deep Learning: Integrating Financial, Blockchain, and Text Data**|Vincent Gurgul et.al.|[2311.14759v1](http://arxiv.org/abs/2311.14759v1)|null|\n", "2311.13878": "|**2023-11-23**|**Minimizing Factual Inconsistency and Hallucination in Large Language Models**|Muneeswaran I et.al.|[2311.13878v1](http://arxiv.org/abs/2311.13878v1)|null|\n", "2311.13784": "|**2023-11-23**|**DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for Korean NLP**|Dongjun Jang et.al.|[2311.13784v1](http://arxiv.org/abs/2311.13784v1)|null|\n", "2311.13743": "|**2023-11-23**|**FinMe: A Performance-Enhanced Large Language Model Trading Agent with Layered Memory and Character Design**|Yangyang Yu et.al.|[2311.13743v1](http://arxiv.org/abs/2311.13743v1)|null|\n", "2311.13668": "|**2023-11-22**|**MAIRA-1: A specialised large multimodal model for radiology report generation**|Stephanie L. Hyland et.al.|[2311.13668v1](http://arxiv.org/abs/2311.13668v1)|null|\n", "2311.13381": "|**2023-11-22**|**Confidant: Customizing Transformer-based LLMs via Collaborative Edge Training**|Yuhao Chen et.al.|[2311.13381v1](http://arxiv.org/abs/2311.13381v1)|null|\n", "2311.13281": "|**2023-11-22**|**Intention and Context Elicitation with Large Language Models in the Legal Aid Intake Process**|Nick Goodson et.al.|[2311.13281v1](http://arxiv.org/abs/2311.13281v1)|null|\n", "2311.13231": "|**2023-11-23**|**Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model**|Kai Yang et.al.|[2311.13231v2](http://arxiv.org/abs/2311.13231v2)|**[link](https://github.com/yk7333/d3po)**|\n", "2311.13194": "|**2023-11-22**|**Towards Improving Document Understanding: An Exploration on Text-Grounding via MLLMs**|Yonghui Wang et.al.|[2311.13194v1](http://arxiv.org/abs/2311.13194v1)|null|\n", "2311.13126": "|**2023-11-22**|**Towards Better Parameter-Efficient Fine-Tuning for Large Language Models: A Position Paper**|Chengyu Wang et.al.|[2311.13126v1](http://arxiv.org/abs/2311.13126v1)|null|\n", "2311.13120": "|**2023-11-23**|**Multi-modal In-Context Learning Makes an Ego-evolving Scene Text Recognizer**|Zhen Zhao et.al.|[2311.13120v2](http://arxiv.org/abs/2311.13120v2)|null|\n", "2311.12908": "|**2023-11-21**|**Diffusion Model Alignment Using Direct Preference Optimization**|Bram Wallace et.al.|[2311.12908v1](http://arxiv.org/abs/2311.12908v1)|null|\n", "2311.12448": "|**2023-11-21**|**Extracting Definienda in Mathematical Scholarly Articles with Transformers**|Shufan Jiang et.al.|[2311.12448v1](http://arxiv.org/abs/2311.12448v1)|**[link](https://github.com/sufianj/def_extraction)**|\n", "2311.12410": "|**2023-11-21**|**nach0: Multimodal Natural and Chemical Languages Foundation Model**|Micha Livne et.al.|[2311.12410v1](http://arxiv.org/abs/2311.12410v1)|null|\n", "2311.12371": "|**2023-11-21**|**AudioLog: LLMs-Powered Long Audio Logging with Acoustic Scenes and Events Joint Estimation**|Jisheng Bai et.al.|[2311.12371v1](http://arxiv.org/abs/2311.12371v1)|**[link](https://github.com/jishengbai/audiolog)**|\n", "2311.12275": "|**2023-11-21**|**Enabling On-Device Large Language Model Personalization with Self-Supervised Data Selection and Synthesis**|Ruiyang Qin et.al.|[2311.12275v1](http://arxiv.org/abs/2311.12275v1)|null|\n", "2311.11865": "|**2023-11-20**|**VLM-Eval: A General Evaluation on Video Large Language Models**|Shuailin Li et.al.|[2311.11865v1](http://arxiv.org/abs/2311.11865v1)|null|\n", "2311.11696": "|**2023-11-20**|**Sparse Low-rank Adaptation of Pre-trained Language Models**|Ning Ding et.al.|[2311.11696v1](http://arxiv.org/abs/2311.11696v1)|**[link](https://github.com/tsinghuac3i/sora)**|\n", "2311.11608": "|**2023-11-20**|**Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks**|Ling Luo et.al.|[2311.11608v1](http://arxiv.org/abs/2311.11608v1)|**[link](https://github.com/dutir-bionlp/taiyi-llm)**|\n", "2311.11462": "|**2023-11-23**|**LLM aided semi-supervision for Extractive Dialog Summarization**|Nishant Mishra et.al.|[2311.11462v2](http://arxiv.org/abs/2311.11462v2)|null|\n", "2311.11077": "|**2023-11-18**|**Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**|Clifton Poth et.al.|[2311.11077v1](http://arxiv.org/abs/2311.11077v1)|null|\n", "2311.11012": "|**2023-11-18**|**Bit Cipher -- A Simple yet Powerful Word Representation System that Integrates Efficiently with Language Models**|Haoran Zhao et.al.|[2311.11012v1](http://arxiv.org/abs/2311.11012v1)|null|\n", "2311.10898": "|**2023-11-17**|**On Functional Activations in Deep Neural Networks**|Andrew S. Nencka et.al.|[2311.10898v1](http://arxiv.org/abs/2311.10898v1)|null|\n", "2311.10697": "|**2023-11-17**|**PEFT-MedAware: Large Language Model for Medical Awareness**|Keivalya Pandya et.al.|[2311.10697v1](http://arxiv.org/abs/2311.10697v1)|null|\n", "2311.10614": "|**2023-11-17**|**A Self-enhancement Approach for Domain-specific Chatbot Training via Knowledge Mining and Digest**|Ruohong Zhang et.al.|[2311.10614v1](http://arxiv.org/abs/2311.10614v1)|null|\n", "2311.10483": "|**2023-11-17**|**Towards General Loop Invariant Generation via Coordinating Symbolic Execution and Large Language Models**|Chang Liu et.al.|[2311.10483v1](http://arxiv.org/abs/2311.10483v1)|null|\n", "2311.10388": "|**2023-11-17**|**Automatic Smart Contract Comment Generation via Large Language Models and In-Context Learning**|Junjie Zhao et.al.|[2311.10388v1](http://arxiv.org/abs/2311.10388v1)|**[link](https://github.com/jun-jie-zhao/sccllm)**|\n", "2311.10372": "|**2023-11-17**|**A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends**|Zibin Zheng et.al.|[2311.10372v1](http://arxiv.org/abs/2311.10372v1)|null|\n", "2311.10219": "|**2023-11-16**|**Measuring Moral Dimensions in Social Media with Mformer**|Tuan Dung Nguyen et.al.|[2311.10219v1](http://arxiv.org/abs/2311.10219v1)|null|\n", "2311.09807": "|**2023-11-16**|**The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text**|Yanzhu Guo et.al.|[2311.09807v1](http://arxiv.org/abs/2311.09807v1)|null|\n", "2311.09800": "|**2023-11-16**|**$\\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of Information-Seeking Dialogue via Behavioural Fine-Tuning**|Evgeniia Razumovskaia et.al.|[2311.09800v1](http://arxiv.org/abs/2311.09800v1)|null|\n", "2311.09773": "|**2023-11-16**|**To be or not to be? an exploration of continuously controllable prompt engineering**|Yuhan Sun et.al.|[2311.09773v1](http://arxiv.org/abs/2311.09773v1)|null|\n", "2311.09758": "|**2023-11-16**|**OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking**|Chia-Hsuan Lee et.al.|[2311.09758v1](http://arxiv.org/abs/2311.09758v1)|null|\n", "2311.09707": "|**2023-11-16**|**GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding**|Andor Diera et.al.|[2311.09707v1](http://arxiv.org/abs/2311.09707v1)|null|\n", "2311.09665": "|**2023-11-16**|**Evaluating LLM Agent Group Dynamics against Human Group Dynamics: A Case Study on Wisdom of Partisan Crowds**|Yun-Shiuan Chuang et.al.|[2311.09665v1](http://arxiv.org/abs/2311.09665v1)|null|\n", "2311.09656": "|**2023-11-16**|**Structured Chemistry Reasoning with Large Language Models**|Siru Ouyang et.al.|[2311.09656v1](http://arxiv.org/abs/2311.09656v1)|null|\n", "2311.10779": "|**2023-11-16**|**Knowledge Plugins: Enhancing Large Language Models for Domain-Specific Recommendations**|Jing Yao et.al.|[2311.10779v1](http://arxiv.org/abs/2311.10779v1)|null|\n", "2311.09606": "|**2023-11-16**|**GistScore: Learning Better Representations for In-Context Example Selection with Gist Bottlenecks**|Shivanshu Gupta et.al.|[2311.09606v1](http://arxiv.org/abs/2311.09606v1)|null|\n", "2311.09602": "|**2023-11-16**|**Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion**|Smriti Singh et.al.|[2311.09602v1](http://arxiv.org/abs/2311.09602v1)|null|\n", "2311.09593": "|**2023-11-16**|**Multi-Step Dialogue Workflow Action Prediction**|Ramya Ramakrishnan et.al.|[2311.09593v1](http://arxiv.org/abs/2311.09593v1)|null|\n", "2311.09585": "|**2023-11-16**|**LifeTox: Unveiling Implicit Toxicity in Life Advice**|Minbeom Kim et.al.|[2311.09585v1](http://arxiv.org/abs/2311.09585v1)|null|\n", "2311.09535": "|**2023-11-17**|**FunctionMarker: Watermarking Language Datasets via Knowledge Injection**|Shuai Li et.al.|[2311.09535v2](http://arxiv.org/abs/2311.09535v2)|null|\n", "2311.09517": "|**2023-11-16**|**GEE! Grammar Error Explanation with Large Language Models**|Yixiao Song et.al.|[2311.09517v1](http://arxiv.org/abs/2311.09517v1)|**[link](https://github.com/yixiao-song/gee-with-llms)**|\n", "2311.09447": "|**2023-11-15**|**How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities**|Lingbo Mo et.al.|[2311.09447v1](http://arxiv.org/abs/2311.09447v1)|**[link](https://github.com/osu-nlp-group/eval-llm-trust)**|\n", "2311.09344": "|**2023-11-15**|**Language and Task Arithmetic with Parameter-Efficient Layers for Zero-Shot Summarization**|Alexandra Chronopoulou et.al.|[2311.09344v1](http://arxiv.org/abs/2311.09344v1)|null|\n", "2311.09216": "|**2023-11-15**|**Assessing Translation capabilities of Large Language Models involving English and Indian Languages**|Vandan Mujadia et.al.|[2311.09216v1](http://arxiv.org/abs/2311.09216v1)|null|\n", "2311.09206": "|**2023-11-15**|**TableLlama: Towards Open Large Generalist Models for Tables**|Tianshu Zhang et.al.|[2311.09206v1](http://arxiv.org/abs/2311.09206v1)|null|\n", "2311.09154": "|**2023-11-15**|**CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models**|Wenhong Zhu et.al.|[2311.09154v1](http://arxiv.org/abs/2311.09154v1)|null|\n", "2311.09136": "|**2023-11-15**|**RRescue: Ranking LLM Responses to Enhance Reasoning Over Context**|Yikun Wang et.al.|[2311.09136v1](http://arxiv.org/abs/2311.09136v1)|null|\n", "2311.09105": "|**2023-11-15**|**MAVEN-Arg: Completing the Puzzle of All-in-One Event Understanding Dataset with Event Argument Annotation**|Xiaozhi Wang et.al.|[2311.09105v1](http://arxiv.org/abs/2311.09105v1)|null|\n", "2311.09049": "|**2023-11-15**|**Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation**|Bowen Zheng et.al.|[2311.09049v1](http://arxiv.org/abs/2311.09049v1)|**[link](https://github.com/rucaibox/lc-rec)**|\n", "2311.09033": "|**2023-11-15**|**MELA: Multilingual Evaluation of Linguistic Acceptability**|Ziyin Zhang et.al.|[2311.09033v1](http://arxiv.org/abs/2311.09033v1)|null|\n", "2311.08993": "|**2023-11-15**|**When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks**|Hao Peng et.al.|[2311.08993v1](http://arxiv.org/abs/2311.08993v1)|null|\n", "2311.08896": "|**2023-11-15**|**HELLaMA: LLaMA-based Table to Text Generation by Highlighting the Important Evidence**|Junyi Bian et.al.|[2311.08896v1](http://arxiv.org/abs/2311.08896v1)|null|\n", "2311.08890": "|**2023-11-15**|**Large Language Models are legal but they are not: Making the case for a powerful LegalLLM**|Thanmay Jayakumar et.al.|[2311.08890v1](http://arxiv.org/abs/2311.08890v1)|null|\n", "2311.08723": "|**2023-11-15**|**Token Prediction as Implicit Classification to Identify LLM-Generated Text**|Yutian Chen et.al.|[2311.08723v1](http://arxiv.org/abs/2311.08723v1)|**[link](https://github.com/markchenyutian/t5-sentinel-public)**|\n", "2311.08704": "|**2023-11-15**|**Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains**|Marcio Fonseca et.al.|[2311.08704v1](http://arxiv.org/abs/2311.08704v1)|null|\n", "2311.08669": "|**2023-11-15**|**Understanding Calibration for Multilingual Question Answering Models**|Yahan Yang et.al.|[2311.08669v1](http://arxiv.org/abs/2311.08669v1)|null|\n", "2311.08662": "|**2023-11-15**|**Multi-Set Inoculation: Assessing Model Robustness Across Multiple Challenge Sets**|Vatsal Gupta et.al.|[2311.08662v1](http://arxiv.org/abs/2311.08662v1)|null|\n", "2311.08590": "|**2023-11-14**|**PEMA: Plug-in External Memory Adaptation for Language Models**|HyunJin Kim et.al.|[2311.08590v1](http://arxiv.org/abs/2311.08590v1)|null|\n", "2311.08572": "|**2023-11-14**|**Parameter-Efficient Multilingual Summarisation: An Empirical Study**|Chenxi Whitehouse et.al.|[2311.08572v1](http://arxiv.org/abs/2311.08572v1)|null|\n", "2311.08526": "|**2023-11-14**|**GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer**|Urchade Zaratiana et.al.|[2311.08526v1](http://arxiv.org/abs/2311.08526v1)|**[link](https://github.com/urchade/gliner)**|\n", "2311.08505": "|**2023-11-14**|**Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning**|Xin Su et.al.|[2311.08505v1](http://arxiv.org/abs/2311.08505v1)|null|\n", "2311.08469": "|**2023-11-14**|**UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations**|Wenting Zhao et.al.|[2311.08469v1](http://arxiv.org/abs/2311.08469v1)|null|\n", "2311.08380": "|**2023-11-14**|**Direct Preference Optimization for Neural Machine Translation with Minimum Bayes Risk Decoding**|Guangyu Yang et.al.|[2311.08380v1](http://arxiv.org/abs/2311.08380v1)|null|\n", "2311.08349": "|**2023-11-14**|**Artificial Text Boundary Detection with Topological Data Analysis and Sliding Window Techniques**|Laida Kushnareva et.al.|[2311.08349v1](http://arxiv.org/abs/2311.08349v1)|null|\n", "2311.08107": "|**2023-11-14**|**SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training with Adversarial Remarks**|Mengsay Loem et.al.|[2311.08107v1](http://arxiv.org/abs/2311.08107v1)|null|\n", "2311.08045": "|**2023-11-14**|**Adversarial Preference Optimization**|Pengyu Cheng et.al.|[2311.08045v1](http://arxiv.org/abs/2311.08045v1)|null|\n", "2311.08011": "|**2023-11-14**|**Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models**|Shiwen Ni et.al.|[2311.08011v1](http://arxiv.org/abs/2311.08011v1)|null|\n", "2311.07978": "|**2023-11-14**|**How good are Large Language Models on African Languages?**|Jessica Ojo et.al.|[2311.07978v1](http://arxiv.org/abs/2311.07978v1)|null|\n", "2311.07961": "|**2023-11-14**|**The ART of LLM Refinement: Ask, Refine, and Trust**|Kumar Shridhar et.al.|[2311.07961v1](http://arxiv.org/abs/2311.07961v1)|null|\n", "2311.07957": "|**2023-11-14**|**Language Models are Better Bug Detector Through Code-Pair Classification**|Kamel Alrashedy et.al.|[2311.07957v1](http://arxiv.org/abs/2311.07957v1)|**[link](https://github.com/kamel773/code_pair_classification)**|\n", "2311.07689": "|**2023-11-13**|**MART: Improving LLM Safety with Multi-round Automatic Red-Teaming**|Suyu Ge et.al.|[2311.07689v1](http://arxiv.org/abs/2311.07689v1)|null|\n", "2311.07687": "|**2023-11-13**|**Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games**|Arjun Vaithilingam Sudhakar et.al.|[2311.07687v1](http://arxiv.org/abs/2311.07687v1)|null|\n", "2311.07468": "|**2023-11-16**|**Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse**|Ang Lv et.al.|[2311.07468v2](http://arxiv.org/abs/2311.07468v2)|**[link](https://github.com/trestad/mitigating-reversal-curse)**|\n", "2311.07418": "|**2023-11-13**|**Speech-based Slot Filling using Large Language Models**|Guangzhi Sun et.al.|[2311.07418v1](http://arxiv.org/abs/2311.07418v1)|null|\n", "2311.07387": "|**2023-11-13**|**Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study**|Yinghao Li et.al.|[2311.07387v1](http://arxiv.org/abs/2311.07387v1)|**[link](https://github.com/yinghao-li/minesweeper-for-llm)**|\n", "2311.07194": "|**2023-11-16**|**Exploring the Dialogue Comprehension Ability of Large Language Models**|Shuaijie She et.al.|[2311.07194v2](http://arxiv.org/abs/2311.07194v2)|null|\n", "2311.06838": "|**2023-11-12**|**GIELLM: Japanese General Information Extraction Large Language Model Utilizing Mutual Reinforcement Effect**|Chengguang Gan et.al.|[2311.06838v1](http://arxiv.org/abs/2311.06838v1)|null|\n", "2311.06791": "|**2023-11-12**|**InfMLLM: A Unified Framework for Visual-Language Tasks**|Qiang Zhou et.al.|[2311.06791v1](http://arxiv.org/abs/2311.06791v1)|**[link](https://github.com/mightyzau/infmllm)**|\n", "2311.06668": "|**2023-11-16**|**In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**|Sheng Liu et.al.|[2311.06668v2](http://arxiv.org/abs/2311.06668v2)|**[link](https://github.com/shengliu66/icv)**|\n", "2311.06503": "|**2023-11-11**|**Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering**|Yichi Zhang et.al.|[2311.06503v1](http://arxiv.org/abs/2311.06503v1)|**[link](https://github.com/zjukg/knowpat)**|\n", "2311.06495": "|**2023-11-11**|**LayoutPrompter: Awaken the Design Ability of Large Language Models**|Jiawei Lin et.al.|[2311.06495v1](http://arxiv.org/abs/2311.06495v1)|**[link](https://github.com/microsoft/layoutgeneration)**|\n", "2311.06364": "|**2023-11-10**|**Relation Extraction in underexplored biomedical domains: A diversity-optimised sampling and synthetic data generation approach**|Maxime Delmas et.al.|[2311.06364v1](http://arxiv.org/abs/2311.06364v1)|**[link](https://github.com/idiap/abroad-re)**|\n", "2311.06158": "|**2023-11-10**|**Language Models can be Logical Solvers**|Jiazhan Feng et.al.|[2311.06158v1](http://arxiv.org/abs/2311.06158v1)|null|\n", "2311.06121": "|**2023-11-10**|**Is it indeed bigger better? The comprehensive study of claim detection LMs applied for disinformation tackling**|Martin Hyben et.al.|[2311.06121v1](http://arxiv.org/abs/2311.06121v1)|null|\n", "2311.06062": "|**2023-11-10**|**Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration**|Wenjie Fu et.al.|[2311.06062v1](http://arxiv.org/abs/2311.06062v1)|null|\n", "2311.06025": "|**2023-11-23**|**ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences**|Yuanhe Tian et.al.|[2311.06025v2](http://arxiv.org/abs/2311.06025v2)|**[link](https://github.com/synlp/chimed-gpt)**|\n", "2311.05965": "|**2023-11-10**|**Large Language Models are Zero Shot Hypothesis Proposers**|Biqing Qi et.al.|[2311.05965v1](http://arxiv.org/abs/2311.05965v1)|null|\n", "2311.05903": "|**2023-11-10**|**Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users**|Jennifer Dodgson et.al.|[2311.05903v1](http://arxiv.org/abs/2311.05903v1)|null|\n", "2311.05850": "|**2023-11-10**|**Exploring Fine-tuning ChatGPT for News Recommendation**|Xinyi Li et.al.|[2311.05850v1](http://arxiv.org/abs/2311.05850v1)|null|\n", "2311.05845": "|**2023-11-10**|**Tamil-Llama: A New Tamil Language Model Based on Llama 2**|Abhinand Balachandran et.al.|[2311.05845v1](http://arxiv.org/abs/2311.05845v1)|**[link](https://github.com/abhinand5/tamil-llama)**|\n", "2311.06318": "|**2023-11-10**|**Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion**|Jinheon Baek et.al.|[2311.06318v1](http://arxiv.org/abs/2311.06318v1)|null|\n", "2311.05800": "|**2023-11-10**|**Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval**|Nandan Thakur et.al.|[2311.05800v1](http://arxiv.org/abs/2311.05800v1)|**[link](https://github.com/google-research-datasets/swim-ir)**|\n", "2311.05584": "|**2023-11-09**|**Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations**|Joey Hong et.al.|[2311.05584v1](http://arxiv.org/abs/2311.05584v1)|null|\n", "2311.05553": "|**2023-11-10**|**Removing RLHF Protections in GPT-4 via Fine-Tuning**|Qiusi Zhan et.al.|[2311.05553v2](http://arxiv.org/abs/2311.05553v2)|null|\n", "2311.06310": "|**2023-11-20**|**$\\textit{Labor Space}$: A Unifying Representation of the Labor Market via Large Language Models**|Seongwoon Kim et.al.|[2311.06310v2](http://arxiv.org/abs/2311.06310v2)|null|\n", "2311.05657": "|**2023-11-09**|**Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs**|Da Yin et.al.|[2311.05657v1](http://arxiv.org/abs/2311.05657v1)|**[link](https://github.com/allenai/lumos)**|\n", "2311.04850": "|**2023-11-11**|**Rethinking Benchmark and Contamination for Language Models with Rephrased Samples**|Shuo Yang et.al.|[2311.04850v2](http://arxiv.org/abs/2311.04850v2)|**[link](https://github.com/lm-sys/llm-decontaminator)**|\n", "2311.04177": "|**2023-11-07**|**Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation**|Eric Melz et.al.|[2311.04177v1](http://arxiv.org/abs/2311.04177v1)|null|\n", "2311.04076": "|**2023-11-07**|**Do LLMs exhibit human-like response biases? A case study in survey design**|Lindia Tjuatja et.al.|[2311.04076v1](http://arxiv.org/abs/2311.04076v1)|**[link](https://github.com/lindiatjuatja/biasmonkey)**|\n", "2311.04072": "|**2023-11-07**|**Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment**|Geyang Guo et.al.|[2311.04072v1](http://arxiv.org/abs/2311.04072v1)|null|\n", "2311.04046": "|**2023-11-07**|**Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features**|Diogo Cruz et.al.|[2311.04046v1](http://arxiv.org/abs/2311.04046v1)|**[link](https://github.com/edoardopona/predicting-inductive-biases-rl)**|\n", "2311.03812": "|**2023-11-07**|**Conversations in Galician: a Large Language Model for an Underrepresented Language**|Eliseo Bao et.al.|[2311.03812v1](http://arxiv.org/abs/2311.03812v1)|**[link](https://gitlab.irlab.org/irlab/cabuxa)**|\n", "2311.03778": "|**2023-11-07**|**Bridging the Information Gap Between Domain-Specific Model and General LLM for Personalized Recommendation**|Wenxuan Zhang et.al.|[2311.03778v1](http://arxiv.org/abs/2311.03778v1)|null|\n", "2311.03758": "|**2023-11-12**|**Large Language Model based Long-tail Query Rewriting in Taobao Search**|Wenjun Peng et.al.|[2311.03758v2](http://arxiv.org/abs/2311.03758v2)|null|\n", "2311.03755": "|**2023-11-09**|**Multilingual Mathematical Autoformalization**|Albert Q. Jiang et.al.|[2311.03755v2](http://arxiv.org/abs/2311.03755v2)|**[link](https://github.com/albertqjiang/mma)**|\n", "2311.03748": "|**2023-11-07**|**Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning**|Sarkar Snigdha Sarathi Das et.al.|[2311.03748v1](http://arxiv.org/abs/2311.03748v1)|**[link](https://github.com/psunlpgroup/fish-dip)**|\n", "2311.03716": "|**2023-11-07**|**LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators**|Allen Roush et.al.|[2311.03716v1](http://arxiv.org/abs/2311.03716v1)|null|\n", "2311.03687": "|**2023-11-07**|**Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models**|Longteng Zhang et.al.|[2311.03687v1](http://arxiv.org/abs/2311.03687v1)|null|\n", "2311.03311": "|**2023-11-06**|**Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance**|Thiemo Wambsganss et.al.|[2311.03311v1](http://arxiv.org/abs/2311.03311v1)|**[link](https://github.com/epfl-ml4ed/unraveling-llm-bias)**|\n", "2311.03285": "|**2023-11-07**|**S-LoRA: Serving Thousands of Concurrent LoRA Adapters**|Ying Sheng et.al.|[2311.03285v2](http://arxiv.org/abs/2311.03285v2)|**[link](https://github.com/s-lora/s-lora)**|\n", "2311.02805": "|**2023-11-06**|**Tailoring Self-Rationalizers with Multi-Reward Distillation**|Sahana Ramnath et.al.|[2311.02805v1](http://arxiv.org/abs/2311.02805v1)|**[link](https://github.com/ink-usc/rationalemultirewarddistillation)**|\n", "2311.02775": "|**2023-11-13**|**ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**|Yann Hicke et.al.|[2311.02775v2](http://arxiv.org/abs/2311.02775v2)|null|\n", "2311.02192": "|**2023-11-03**|**Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models**|Jake Chanenson et.al.|[2311.02192v1](http://arxiv.org/abs/2311.02192v1)|null|\n", "2311.01937": "|**2023-11-03**|**Supermind Ideator: Exploring generative AI to support creative problem-solving**|Steven R. Rick et.al.|[2311.01937v1](http://arxiv.org/abs/2311.01937v1)|null|\n", "2311.01920": "|**2023-11-03**|**ChartGPT: Leveraging LLMs to Generate Charts from Abstract Natural Language**|Yuan Tian et.al.|[2311.01920v1](http://arxiv.org/abs/2311.01920v1)|**[link](https://github.com/bebinca/chartgpt-materials)**|\n", "2311.02126": "|**2023-11-03**|**PILL: Plug Into LLM with Adapter Expert and Attention Gate**|Fangyuan Zhang et.al.|[2311.02126v1](http://arxiv.org/abs/2311.02126v1)|**[link](https://github.com/dsaltyfish/pill)**|\n", "2311.01786": "|**2023-11-03**|**TCM-GPT: Efficient Pre-training of Large Language Models for Domain Adaptation in Traditional Chinese Medicine**|Guoxing Yang et.al.|[2311.01786v1](http://arxiv.org/abs/2311.01786v1)|null|\n", "2311.01732": "|**2023-11-12**|**Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models**|Sean Xie et.al.|[2311.01732v2](http://arxiv.org/abs/2311.01732v2)|**[link](https://github.com/yx131/proto-lm)**|\n", "2311.01677": "|**2023-11-03**|**DialogBench: Evaluating LLMs as Human-like Dialogue Systems**|Jiao Ou et.al.|[2311.01677v1](http://arxiv.org/abs/2311.01677v1)|null|\n", "2311.01487": "|**2023-11-02**|**What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning**|Yifan Du et.al.|[2311.01487v1](http://arxiv.org/abs/2311.01487v1)|**[link](https://github.com/rucaibox/comvint)**|\n", "2311.01108": "|**2023-11-02**|**Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance**|Song Wang et.al.|[2311.01108v1](http://arxiv.org/abs/2311.01108v1)|null|\n", "2311.02105": "|**2023-11-02**|**Making Harmful Behaviors Unlearnable for Large Language Models**|Xin Zhou et.al.|[2311.02105v1](http://arxiv.org/abs/2311.02105v1)|null|\n", "2311.01049": "|**2023-11-02**|**Multi-dimensional data refining strategy for effective fine-tuning LLMs**|Thanh Nguyen Ngoc et.al.|[2311.01049v1](http://arxiv.org/abs/2311.01049v1)|null|\n", "2311.00835": "|**2023-11-01**|**Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing**|Yanlin Feng et.al.|[2311.00835v1](http://arxiv.org/abs/2311.00835v1)|**[link](https://github.com/yanlinf/casent)**|\n", "2311.04913": "|**2023-11-12**|**An Improved Transformer-based Model for Detecting Phishing, Spam, and Ham: A Large Language Model Approach**|Suhaima Jamal et.al.|[2311.04913v2](http://arxiv.org/abs/2311.04913v2)|null|\n", "2311.00444": "|**2023-11-01**|**Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements**|Peter A. Zachares et.al.|[2311.00444v1](http://arxiv.org/abs/2311.00444v1)|null|\n", "2311.00339": "|**2023-11-01**|**Space Narrative: Generating Images and 3D Scenes of Chinese Garden from Text using Deep Learning**|Jiaxi Shi1 et.al.|[2311.00339v1](http://arxiv.org/abs/2311.00339v1)|null|\n", "2311.00273": "|**2023-11-01**|**SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations**|Yirong Chen et.al.|[2311.00273v1](http://arxiv.org/abs/2311.00273v1)|**[link](https://github.com/scutcyr/soulchat)**|\n", "2311.00272": "|**2023-11-01**|**ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation**|Zejun Wang et.al.|[2311.00272v1](http://arxiv.org/abs/2311.00272v1)|null|\n", "2311.00262": "|**2023-11-01**|**Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents**|Yang Deng et.al.|[2311.00262v1](http://arxiv.org/abs/2311.00262v1)|null|\n", "2311.00204": "|**2023-11-01**|**Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering**|Zhen Guo et.al.|[2311.00204v1](http://arxiv.org/abs/2311.00204v1)|null|\n", "2311.00176": "|**2023-11-13**|**ChipNeMo: Domain-Adapted LLMs for Chip Design**|Mingjie Liu et.al.|[2311.00176v2](http://arxiv.org/abs/2311.00176v2)|null|\n", "2311.00117": "|**2023-10-31**|**BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B**|Pranav Gade et.al.|[2311.00117v1](http://arxiv.org/abs/2311.00117v1)|null|\n", "2310.20689": "|**2023-11-14**|**Learning From Mistakes Makes LLM Better Reasoner**|Shengnan An et.al.|[2310.20689v2](http://arxiv.org/abs/2310.20689v2)|**[link](https://github.com/microsoft/lema)**|\n", "2310.20624": "|**2023-10-31**|**LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B**|Simon Lermen et.al.|[2310.20624v1](http://arxiv.org/abs/2310.20624v1)|null|\n", "2310.20587": "|**2023-11-27**|**Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning**|Ruizhe Shi et.al.|[2310.20587v4](http://arxiv.org/abs/2310.20587v4)|**[link](https://github.com/srzer/LaMo-2023)**|\n", "2310.20440": "|**2023-10-31**|**The SourceData-NLP dataset: integrating curation into scientific publishing for training large language models**|Jorge Abreu-Vicente et.al.|[2310.20440v1](http://arxiv.org/abs/2310.20440v1)|**[link](https://github.com/source-data/soda-data)**|\n", "2310.20329": "|**2023-10-31**|**InstructCoder: Empowering Language Models for Code Editing**|Qisheng Hu et.al.|[2310.20329v1](http://arxiv.org/abs/2310.20329v1)|**[link](https://github.com/qishenghu/CodeInstruct)**|\n", "2310.20153": "|**2023-10-31**|**Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision**|Jiaxin Zhang et.al.|[2310.20153v1](http://arxiv.org/abs/2310.20153v1)|null|\n", "2310.20105": "|**2023-10-31**|**Efficient Classification of Student Help Requests in Programming Courses Using Large Language Models**|Jaromir Savelka et.al.|[2310.20105v1](http://arxiv.org/abs/2310.20105v1)|null|\n", "2310.20034": "|**2023-10-30**|**GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning**|Moritz A. Graule et.al.|[2310.20034v1](http://arxiv.org/abs/2310.20034v1)|null|\n", "2310.20033": "|**2023-11-03**|**Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization**|Prakamya Mishra et.al.|[2310.20033v2](http://arxiv.org/abs/2310.20033v2)|**[link](https://github.com/seasonyao/learnfromhumanedit)**|\n", "2310.19998": "|**2023-10-30**|**Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design**|Markus J. Buehler et.al.|[2310.19998v1](http://arxiv.org/abs/2310.19998v1)|null|\n", "2310.19975": "|**2023-11-06**|**BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing**|Hieu Tran et.al.|[2310.19975v2](http://arxiv.org/abs/2310.19975v2)|null|\n", "2310.19915": "|**2023-10-30**|**GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models**|Seongwon Kim et.al.|[2310.19915v1](http://arxiv.org/abs/2310.19915v1)|null|\n", "2310.19792": "|**2023-10-30**|**The Eval4NLP 2023 Shared Task on Prompting Large Language Models as Explainable Metrics**|Christoph Leiter et.al.|[2310.19792v1](http://arxiv.org/abs/2310.19792v1)|**[link](https://github.com/eval4nlp/sharedtask2023)**|\n", "2310.19292": "|**2023-10-30**|**Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering**|Xin Su et.al.|[2310.19292v1](http://arxiv.org/abs/2310.19292v1)|null|\n", "2310.19240": "|**2023-10-30**|**M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models**|Wai-Chung Kwan et.al.|[2310.19240v1](http://arxiv.org/abs/2310.19240v1)|**[link](https://github.com/kwanwaichung/m4le)**|\n", "2310.19233": "|**2023-11-08**|**Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective**|Md Tahmid Rahman Laskar et.al.|[2310.19233v3](http://arxiv.org/abs/2310.19233v3)|null|\n", "2310.18964": "|**2023-10-29**|**LLMs and Finetuning: Benchmarking cross-domain performance for hate speech detection**|Ahmad Nasir et.al.|[2310.18964v1](http://arxiv.org/abs/2310.18964v1)|null|\n", "2310.18502": "|**2023-10-27**|**On the Automatic Generation and Simplification of Children's Stories**|Maria Valentini et.al.|[2310.18502v1](http://arxiv.org/abs/2310.18502v1)|null|\n", "2310.18454": "|**2023-10-27**|**T5 meets Tybalt: Author Attribution in Early Modern English Drama Using Large Language Models**|Rebecca M. M. Hicke et.al.|[2310.18454v1](http://arxiv.org/abs/2310.18454v1)|null|\n", "2310.18313": "|**2023-10-27**|**FP8-LM: Training FP8 Large Language Models**|Houwen Peng et.al.|[2310.18313v1](http://arxiv.org/abs/2310.18313v1)|**[link](https://github.com/azure/ms-amp)**|\n", "2310.18208": "|**2023-11-06**|**ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models**|Benjamin Feuer et.al.|[2310.18208v2](http://arxiv.org/abs/2310.18208v2)|**[link](https://github.com/penfever/archetype)**|\n", "2310.18167": "|**2023-10-27**|**MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension**|Guoxin Chen et.al.|[2310.18167v1](http://arxiv.org/abs/2310.18167v1)|null|\n", "2310.18025": "|**2023-10-27**|**Large language models for aspect-based sentiment analysis**|Paul F. Simmering et.al.|[2310.18025v1](http://arxiv.org/abs/2310.18025v1)|**[link](https://github.com/qagentur/absa_llm)**|\n", "2310.17877": "|**2023-10-27**|**ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation**|Martin Vejvar et.al.|[2310.17877v1](http://arxiv.org/abs/2310.17877v1)|**[link](https://github.com/vejvarm/aspiro)**|\n", "2310.17857": "|**2023-10-27**|**From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models**|Dongjun Kang et.al.|[2310.17857v1](http://arxiv.org/abs/2310.17857v1)|**[link](https://github.com/dongjunkang/vim)**|\n", "2310.17752": "|**2023-10-26**|**PockEngine: Sparse and Efficient Fine-tuning in a Pocket**|Ligeng Zhu et.al.|[2310.17752v1](http://arxiv.org/abs/2310.17752v1)|null|\n", "2310.17715": "|**2023-10-26**|**Outlier Dimensions Encode Task-Specific Knowledge**|William Rudman et.al.|[2310.17715v1](http://arxiv.org/abs/2310.17715v1)|**[link](https://github.com/wrudman/outlier_dimensions)**|\n", "2310.17714": "|**2023-10-26**|**Nearest Neighbor Search over Vectorized Lexico-Syntactic Patterns for Relation Extraction from Financial Documents**|Pawan Kumar Rajpoot et.al.|[2310.17714v1](http://arxiv.org/abs/2310.17714v1)|**[link](https://github.com/pawan2411/pan-dl_refind)**|\n", "2310.17631": "|**2023-10-26**|**JudgeLM: Fine-tuned Large Language Models are Scalable Judges**|Lianghui Zhu et.al.|[2310.17631v1](http://arxiv.org/abs/2310.17631v1)|**[link](https://github.com/baaivision/judgelm)**|\n", "2310.17630": "|**2023-10-26**|**InstOptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators**|Heng Yang et.al.|[2310.17630v1](http://arxiv.org/abs/2310.17630v1)|**[link](https://github.com/yangheng95/instoptima)**|\n", "2310.17513": "|**2023-10-27**|**The Expressive Power of Low-Rank Adaptation**|Yuchen Zeng et.al.|[2310.17513v2](http://arxiv.org/abs/2310.17513v2)|**[link](https://github.com/uw-madison-lee-lab/expressive_power_of_lora)**|\n", "2310.17162": "|**2023-10-26**|**Content-based Controls For Music Large Language Modeling**|Liwei Lin et.al.|[2310.17162v1](http://arxiv.org/abs/2310.17162v1)|null|\n", "2310.17054": "|**2023-10-25**|**BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs' Generation**|Yufei Tian et.al.|[2310.17054v1](http://arxiv.org/abs/2310.17054v1)|null|\n", "2310.16959": "|**2023-10-25**|**Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning**|Ananth Balashankar et.al.|[2310.16959v1](http://arxiv.org/abs/2310.16959v1)|null|\n", "2310.16958": "|**2023-10-25**|**Transferring a molecular foundation model for polymer property predictions**|Pei Zhang et.al.|[2310.16958v1](http://arxiv.org/abs/2310.16958v1)|null|\n", "2310.16937": "|**2023-10-25**|**Learning Transfers over Several Programming Languages**|Razan Baltaji et.al.|[2310.16937v1](http://arxiv.org/abs/2310.16937v1)|null|\n", "2310.16776": "|**2023-11-16**|**DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection**|Devleena Das et.al.|[2310.16776v3](http://arxiv.org/abs/2310.16776v3)|null|\n", "2310.16763": "|**2023-10-25**|**SuperHF: Supervised Iterative Learning from Human Feedback**|Gabriel Mukobi et.al.|[2310.16763v1](http://arxiv.org/abs/2310.16763v1)|**[link](https://github.com/openfeedback/superhf)**|\n", "2310.16713": "|**2023-10-26**|**SkyMath: Technical Report**|Liu Yang et.al.|[2310.16713v2](http://arxiv.org/abs/2310.16713v2)|null|\n", "2310.18233": "|**2023-11-01**|**Will releasing the weights of future large language models grant widespread access to pandemic agents?**|Anjali Gopal et.al.|[2310.18233v2](http://arxiv.org/abs/2310.18233v2)|null|\n", "2310.16582": "|**2023-10-25**|**Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons**|Tianlong Li et.al.|[2310.16582v1](http://arxiv.org/abs/2310.16582v1)|null|\n", "2310.16517": "|**2023-10-25**|**OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models**|Mingfeng Xue et.al.|[2310.16517v1](http://arxiv.org/abs/2310.16517v1)|null|\n", "2310.16436": "|**2023-10-26**|**DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models**|Ge Zheng et.al.|[2310.16436v2](http://arxiv.org/abs/2310.16436v2)|null|\n", "2310.16861": "|**2023-10-25**|**General Point Model with Autoencoding and Autoregressive**|Zhe Li et.al.|[2310.16861v1](http://arxiv.org/abs/2310.16861v1)|null|\n", "2310.16271": "|**2023-10-25**|**CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment**|Jixiang Hong et.al.|[2310.16271v1](http://arxiv.org/abs/2310.16271v1)|null|\n", "2310.16218": "|**2023-10-26**|**Knowledge Editing for Large Language Models: A Survey**|Song Wang et.al.|[2310.16218v2](http://arxiv.org/abs/2310.16218v2)|null|\n", "2310.16183": "|**2023-10-24**|**BLP 2023 Task 2: Sentiment Analysis**|Md. Arid Hasan et.al.|[2310.16183v1](http://arxiv.org/abs/2310.16183v1)|**[link](https://github.com/blp-workshop/blp_task2)**|\n", "2310.16048": "|**2023-10-24**|**AI Alignment and Social Choice: Fundamental Limitations and Policy Implications**|Abhilash Mishra et.al.|[2310.16048v1](http://arxiv.org/abs/2310.16048v1)|null|\n", "2310.15941": "|**2023-10-24**|**This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models**|Iker Garc\u00eda-Ferrero et.al.|[2310.15941v1](http://arxiv.org/abs/2310.15941v1)|**[link](https://github.com/hitz-zentroa/this-is-not-a-dataset)**|\n", "2310.15819": "|**2023-10-24**|**Generative Language Models Exhibit Social Identity Biases**|Tiancheng Hu et.al.|[2310.15819v1](http://arxiv.org/abs/2310.15819v1)|null|\n", "2310.15793": "|**2023-10-24**|**Improving generalization in large language models by learning prefix subspaces**|Louis Falissard et.al.|[2310.15793v1](http://arxiv.org/abs/2310.15793v1)|null|\n", "2310.15556": "|**2023-10-25**|**TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction**|Junyi Liu et.al.|[2310.15556v2](http://arxiv.org/abs/2310.15556v2)|null|\n", "2310.15539": "|**2023-10-24**|**SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation**|Jialing Pan et.al.|[2310.15539v1](http://arxiv.org/abs/2310.15539v1)|**[link](https://github.com/sade-adrien/stelocoder)**|\n"}, "LLM - XAI": {"2311.16017": "|**2023-11-27**|**Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models**|Stephen MacNeil et.al.|[2311.16017v1](http://arxiv.org/abs/2311.16017v1)|null|\n", "2311.15716": "|**2023-11-27**|**Justifiable Artificial Intelligence: Engineering Large Language Models for Legal Applications**|Sabine Wehnert et.al.|[2311.15716v1](http://arxiv.org/abs/2311.15716v1)|null|\n", "2311.15548": "|**2023-11-27**|**Deficiency of Large Language Models in Finance: An Empirical Examination of Hallucination**|Haoqiang Kang et.al.|[2311.15548v1](http://arxiv.org/abs/2311.15548v1)|null|\n", "2311.14903": "|**2023-11-25**|**Code Generation Based Grading: Evaluating an Auto-grading Mechanism for \"Explain-in-Plain-English\" Questions**|David H. Smith IV et.al.|[2311.14903v1](http://arxiv.org/abs/2311.14903v1)|null|\n", "2311.14126": "|**2023-11-23**|**Towards Auditing Large Language Models: Improving Text-based Stereotype Detection**|Wu Zekun et.al.|[2311.14126v1](http://arxiv.org/abs/2311.14126v1)|null|\n", "2311.14061": "|**2023-11-23**|**Towards Explainable Strategy Templates using NLP Transformers**|Pallavi Bagga et.al.|[2311.14061v1](http://arxiv.org/abs/2311.14061v1)|null|\n", "2311.13160": "|**2023-11-22**|**Large Language Models in Education: Vision and Opportunities**|Wensheng Gan et.al.|[2311.13160v1](http://arxiv.org/abs/2311.13160v1)|null|\n", "2311.12338": "|**2023-11-21**|**A Survey on Large Language Models for Personalized and Explainable Recommendations**|Junyi Chen et.al.|[2311.12338v1](http://arxiv.org/abs/2311.12338v1)|null|\n", "2311.12233": "|**2023-11-20**|**Unifying Corroborative and Contributive Attributions in Large Language Models**|Theodora Worledge et.al.|[2311.12233v1](http://arxiv.org/abs/2311.12233v1)|null|\n", "2311.11904": "|**2023-11-20**|**LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions**|Songhao Han et.al.|[2311.11904v1](http://arxiv.org/abs/2311.11904v1)|null|\n", "2311.11811": "|**2023-11-20**|**Large Language Models and Explainable Law: a Hybrid Methodology**|Marco Billi et.al.|[2311.11811v1](http://arxiv.org/abs/2311.11811v1)|null|\n", "2311.11552": "|**2023-11-20**|**Exploring Prompting Large Language Models as Explainable Metrics**|Ghazaleh Mahmoudi et.al.|[2311.11552v1](http://arxiv.org/abs/2311.11552v1)|**[link](https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics)**|\n", "2311.11334": "|**2023-11-19**|**Using Causal Threads to Explain Changes in a Dynamic System**|Robert B. Allen et.al.|[2311.11334v1](http://arxiv.org/abs/2311.11334v1)|null|\n", "2311.11267": "|**2023-11-19**|**Rethinking Large Language Models in Mental Health Applications**|Shaoxiong Ji et.al.|[2311.11267v1](http://arxiv.org/abs/2311.11267v1)|null|\n", "2311.10075": "|**2023-11-16**|**ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve Health Literacy and Communication in Pediatric Populations and Beyond**|Kanhai S. Amin et.al.|[2311.10075v1](http://arxiv.org/abs/2311.10075v1)|null|\n", "2311.10054": "|**2023-11-16**|**Is \"A Helpful Assistant\" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts**|Mingqian Zheng et.al.|[2311.10054v1](http://arxiv.org/abs/2311.10054v1)|null|\n", "2311.09020": "|**2023-11-15**|**Explaining Explanation: An Empirical Study on Explanation in Code Reviews**|Ratnadira Widyasari et.al.|[2311.09020v1](http://arxiv.org/abs/2311.09020v1)|null|\n", "2311.09006": "|**2023-11-15**|**Data Similarity is Not Enough to Explain Language Model Performance**|Gregory Yauney et.al.|[2311.09006v1](http://arxiv.org/abs/2311.09006v1)|**[link](https://github.com/gyauney/data-similarity-is-not-enough)**|\n", "2311.08614": "|**2023-11-15**|**XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making**|Zichen Chen et.al.|[2311.08614v1](http://arxiv.org/abs/2311.08614v1)|null|\n", "2311.08469": "|**2023-11-14**|**UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations**|Wenting Zhao et.al.|[2311.08469v1](http://arxiv.org/abs/2311.08469v1)|null|\n", "2311.08398": "|**2023-11-16**|**Are Large Language Models Temporally Grounded?**|Yifu Qiu et.al.|[2311.08398v2](http://arxiv.org/abs/2311.08398v2)|**[link](https://github.com/yfqiu-nlp/temporal-llms)**|\n", "2311.07811": "|**2023-11-13**|**In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax**|Aaron Mueller et.al.|[2311.07811v1](http://arxiv.org/abs/2311.07811v1)|**[link](https://github.com/aaronmueller/syntax-icl)**|\n", "2311.07466": "|**2023-11-13**|**On Measuring Faithfulness of Natural Language Explanations**|Letitia Parcalabescu et.al.|[2311.07466v1](http://arxiv.org/abs/2311.07466v1)|**[link](https://github.com/heidelberg-nlp/cc-shap)**|\n", "2311.06985": "|**2023-11-12**|**SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves**|Jiachen Zhao et.al.|[2311.06985v1](http://arxiv.org/abs/2311.06985v1)|null|\n", "2311.06383": "|**2023-11-10**|**Distilling Large Language Models using Skill-Occupation Graph Context for HR-Related Tasks**|Pouya Pezeshkpour et.al.|[2311.06383v1](http://arxiv.org/abs/2311.06383v1)|**[link](https://github.com/megagonlabs/rjdb)**|\n", "2311.14703": "|**2023-11-10**|**ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management**|Angela Zhang et.al.|[2311.14703v1](http://arxiv.org/abs/2311.14703v1)|null|\n", "2311.05019": "|**2023-11-08**|**DEMASQ: Unmasking the ChatGPT Wordsmith**|Kavita Kumari et.al.|[2311.05019v1](http://arxiv.org/abs/2311.05019v1)|null|\n", "2311.04047": "|**2023-11-07**|**Extracting human interpretable structure-property relationships in chemistry using XAI and large language models**|Geemi P. Wellawatte et.al.|[2311.04047v1](http://arxiv.org/abs/2311.04047v1)|**[link](https://github.com/geemi725/xpertai)**|\n", "2311.03754": "|**2023-11-07**|**Which is better? Exploring Prompting Strategy For LLM-based Metrics**|Joonghoon Kim et.al.|[2311.03754v1](http://arxiv.org/abs/2311.03754v1)|null|\n", "2311.03734": "|**2023-11-07**|**Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning**|Ruosen Li et.al.|[2311.03734v1](http://arxiv.org/abs/2311.03734v1)|**[link](https://github.com/bcdnlp/structure-qa)**|\n", "2311.02433": "|**2023-11-04**|**Can ChatGPT support software verification?**|Christian Jan\u00dfen et.al.|[2311.02433v1](http://arxiv.org/abs/2311.02433v1)|null|\n", "2311.01732": "|**2023-11-12**|**Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models**|Sean Xie et.al.|[2311.01732v2](http://arxiv.org/abs/2311.01732v2)|**[link](https://github.com/yx131/proto-lm)**|\n", "2311.04911": "|**2023-11-01**|**From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems**|Samyar Janatian et.al.|[2311.04911v1](http://arxiv.org/abs/2311.04911v1)|**[link](https://github.com/samyarj/jcapg-jurix2023)**|\n", "2311.00671": "|**2023-11-01**|**Emotion Detection for Misinformation: A Review**|Zhiwei Liu et.al.|[2311.00671v1](http://arxiv.org/abs/2311.00671v1)|null|\n", "2311.00321": "|**2023-11-22**|**HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning**|Yongjin Yang et.al.|[2311.00321v2](http://arxiv.org/abs/2311.00321v2)|**[link](https://github.com/joonkeekim/hare-hate-speech)**|\n", "2311.00206": "|**2023-11-01**|**ChatGPT-Powered Hierarchical Comparisons for Image Classification**|Zhiyuan Ren et.al.|[2311.00206v1](http://arxiv.org/abs/2311.00206v1)|**[link](https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification)**|\n", "2310.20689": "|**2023-11-14**|**Learning From Mistakes Makes LLM Better Reasoner**|Shengnan An et.al.|[2310.20689v2](http://arxiv.org/abs/2310.20689v2)|**[link](https://github.com/microsoft/lema)**|\n", "2310.20320": "|**2023-10-31**|**Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests**|Max J. van Duijn et.al.|[2310.20320v1](http://arxiv.org/abs/2310.20320v1)|null|\n", "2310.19792": "|**2023-10-30**|**The Eval4NLP 2023 Shared Task on Prompting Large Language Models as Explainable Metrics**|Christoph Leiter et.al.|[2310.19792v1](http://arxiv.org/abs/2310.19792v1)|**[link](https://github.com/eval4nlp/sharedtask2023)**|\n", "2310.19658": "|**2023-10-30**|**Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection**|Noah Ziems et.al.|[2310.19658v1](http://arxiv.org/abs/2310.19658v1)|null|\n", "2310.18813": "|**2023-10-28**|**The Synergy of Speculative Decoding and Batching in Serving Large Language Models**|Qidong Su et.al.|[2310.18813v1](http://arxiv.org/abs/2310.18813v1)|null|\n", "2310.17217": "|**2023-10-26**|**Beyond MLE: Convex Learning for Text Generation**|Chenze Shao et.al.|[2310.17217v1](http://arxiv.org/abs/2310.17217v1)|**[link](https://github.com/ictnlp/convex-learning)**|\n", "2310.18233": "|**2023-11-01**|**Will releasing the weights of future large language models grant widespread access to pandemic agents?**|Anjali Gopal et.al.|[2310.18233v2](http://arxiv.org/abs/2310.18233v2)|null|\n", "2310.16436": "|**2023-10-26**|**DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models**|Ge Zheng et.al.|[2310.16436v2](http://arxiv.org/abs/2310.16436v2)|null|\n", "2310.16421": "|**2023-10-25**|**Graph Agent: Explicit Reasoning Agent for Graphs**|Qinyong Wang et.al.|[2310.16421v1](http://arxiv.org/abs/2310.16421v1)|null|\n", "2310.15455": "|**2023-10-24**|**UI Layout Generation with LLMs Guided by UI Grammar**|Yuwen Lu et.al.|[2310.15455v1](http://arxiv.org/abs/2310.15455v1)|null|\n", "2310.14389": "|**2023-10-22**|**Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models**|Hongli Zhan et.al.|[2310.14389v1](http://arxiv.org/abs/2310.14389v1)|**[link](https://github.com/honglizhan/covidet-appraisals-public)**|\n", "2310.14325": "|**2023-10-22**|**Towards Harmful Erotic Content Detection through Coreference-Driven Contextual Analysis**|Inez Okulska et.al.|[2310.14325v1](http://arxiv.org/abs/2310.14325v1)|null|\n", "2310.14025": "|**2023-10-21**|**Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation**|Anastasia Kritharoula et.al.|[2310.14025v1](http://arxiv.org/abs/2310.14025v1)|**[link](https://github.com/anastasiakrith/multimodal-retrieval-for-vwsd)**|\n", "2310.13850": "|**2023-10-20**|**Ecologically Valid Explanations for Label Variation in NLI**|Nan-Jiang Jiang et.al.|[2310.13850v1](http://arxiv.org/abs/2310.13850v1)|**[link](https://github.com/njjiang/livenli)**|\n", "2310.13571": "|**2023-10-30**|**Why Can Large Language Models Generate Correct Chain-of-Thoughts?**|Rasul Tutunov et.al.|[2310.13571v2](http://arxiv.org/abs/2310.13571v2)|null|\n", "2310.13549": "|**2023-10-20**|**The Perils & Promises of Fact-checking with Large Language Models**|Dorian Quelle et.al.|[2310.13549v1](http://arxiv.org/abs/2310.13549v1)|null|\n", "2310.13506": "|**2023-10-20**|**Explaining Interactions Between Text Spans**|Sagnik Ray Choudhury et.al.|[2310.13506v1](http://arxiv.org/abs/2310.13506v1)|**[link](https://github.com/copenlu/spanex)**|\n", "2310.12973": "|**2023-10-19**|**Frozen Transformers in Language Models Are Effective Visual Encoder Layers**|Ziqi Pang et.al.|[2310.12973v1](http://arxiv.org/abs/2310.12973v1)|**[link](https://github.com/ziqipang/lm4visualencoding)**|\n", "2310.12860": "|**2023-10-28**|**Probing LLMs for hate speech detection: strengths and vulnerabilities**|Sarthak Roy et.al.|[2310.12860v2](http://arxiv.org/abs/2310.12860v2)|null|\n", "2310.12558": "|**2023-10-19**|**Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong**|Chenglei Si et.al.|[2310.12558v1](http://arxiv.org/abs/2310.12558v1)|null|\n", "2310.11207": "|**2023-10-17**|**Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations**|Shiyuan Huang et.al.|[2310.11207v1](http://arxiv.org/abs/2310.11207v1)|null|\n", "2310.10418": "|**2023-11-11**|**Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms**|Seungju Han et.al.|[2310.10418v2](http://arxiv.org/abs/2310.10418v2)|**[link](https://github.com/wade3han/normlens)**|\n", "2310.09754": "|**2023-10-15**|**EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification**|Huanhuan Ma et.al.|[2310.09754v1](http://arxiv.org/abs/2310.09754v1)|**[link](https://github.com/dependentsign/EX-FEVER)**|\n", "2310.08797": "|**2023-10-13**|**A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models**|Takuma Udagawa et.al.|[2310.08797v1](http://arxiv.org/abs/2310.08797v1)|null|\n", "2310.08744": "|**2023-10-12**|**Circuit Component Reuse Across Tasks in Transformer Language Models**|Jack Merullo et.al.|[2310.08744v1](http://arxiv.org/abs/2310.08744v1)|null|\n", "2310.08123": "|**2023-10-12**|**Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification**|Chia-Yu Hung et.al.|[2310.08123v1](http://arxiv.org/abs/2310.08123v1)|null|\n", "2310.07984": "|**2023-10-12**|**Large Language Models for Scientific Synthesis, Inference and Explanation**|Yizhen Zheng et.al.|[2310.07984v1](http://arxiv.org/abs/2310.07984v1)|**[link](https://github.com/zyzisastudyreallyhardguy/llm4sd)**|\n", "2310.07820": "|**2023-10-11**|**Large Language Models Are Zero-Shot Time Series Forecasters**|Nate Gruver et.al.|[2310.07820v1](http://arxiv.org/abs/2310.07820v1)|**[link](https://github.com/ngruver/llmtime)**|\n", "2310.06680": "|**2023-10-10**|**Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach**|Zhenlan Ji et.al.|[2310.06680v1](http://arxiv.org/abs/2310.06680v1)|null|\n", "2310.06257": "|**2023-10-10**|**SCAR: Power Side-Channel Analysis at RTL-Level**|Amisha Srivastava et.al.|[2310.06257v1](http://arxiv.org/abs/2310.06257v1)|null|\n", "2310.06200": "|**2023-10-11**|**The Importance of Prompt Tuning for Automated Neuron Explanations**|Justin Lee et.al.|[2310.06200v2](http://arxiv.org/abs/2310.06200v2)|null|\n", "2310.05884": "|**2023-10-09**|**A Meta-Learning Perspective on Transformers for Causal Language Modeling**|Xinbo Wu et.al.|[2310.05884v1](http://arxiv.org/abs/2310.05884v1)|null|\n", "2310.05797": "|**2023-10-10**|**Are Large Language Models Post Hoc Explainers?**|Nicholas Kroeger et.al.|[2310.05797v2](http://arxiv.org/abs/2310.05797v2)|**[link](https://github.com/AI4LIFE-GROUP/LLM_Explainer)**|\n", "2310.05657": "|**2023-10-09**|**A Closer Look into Automatic Evaluation Using Large Language Models**|Cheng-Han Chiang et.al.|[2310.05657v1](http://arxiv.org/abs/2310.05657v1)|**[link](https://github.com/d223302/a-closer-look-to-llm-evaluation)**|\n", "2310.05452": "|**2023-10-09**|**Explaining the Complex Task Reasoning of Large Language Models with Template-Content Structure**|Haotong Yang et.al.|[2310.05452v1](http://arxiv.org/abs/2310.05452v1)|null|\n", "2310.05253": "|**2023-10-20**|**Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models**|Haoran Wang et.al.|[2310.05253v2](http://arxiv.org/abs/2310.05253v2)|**[link](https://github.com/wang2226/folk)**|\n", "2310.05209": "|**2023-10-08**|**Scaling Laws of RoPE-based Extrapolation**|Xiaoran Liu et.al.|[2310.05209v1](http://arxiv.org/abs/2310.05209v1)|null|\n", "2310.05046": "|**2023-10-08**|**Harnessing the Power of ChatGPT in Fake News: An In-Depth Exploration in Generation, Detection and Explanation**|Yue Huang et.al.|[2310.05046v1](http://arxiv.org/abs/2310.05046v1)|null|\n", "2310.05029": "|**2023-10-08**|**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**|Howard Chen et.al.|[2310.05029v1](http://arxiv.org/abs/2310.05029v1)|null|\n", "2310.04949": "|**2023-10-08**|**Domain Knowledge Graph Construction Via A Simple Checker**|Yueling Zeng et.al.|[2310.04949v1](http://arxiv.org/abs/2310.04949v1)|null|\n", "2310.04793": "|**2023-11-11**|**FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets**|Neng Wang et.al.|[2310.04793v2](http://arxiv.org/abs/2310.04793v2)|**[link](https://github.com/ai4finance-foundation/fingpt)**|\n", "2310.02439": "|**2023-10-03**|**Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions**|Naiming Liu et.al.|[2310.02439v1](http://arxiv.org/abs/2310.02439v1)|null|\n", "2310.01957": "|**2023-10-13**|**Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving**|Long Chen et.al.|[2310.01957v2](http://arxiv.org/abs/2310.01957v2)|**[link](https://github.com/wayveai/driving-with-llms)**|\n", "2310.01870": "|**2023-10-03**|**DeepDecipher: Accessing and Investigating Neuron Activation in Large Language Models**|Albert Garde et.al.|[2310.01870v1](http://arxiv.org/abs/2310.01870v1)|null|\n", "2310.01132": "|**2023-10-02**|**Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback**|Jacob Whitehill et.al.|[2310.01132v1](http://arxiv.org/abs/2310.01132v1)|null|\n", "2310.01074": "|**2023-10-08**|**Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models**|Chenhan Yuan et.al.|[2310.01074v2](http://arxiv.org/abs/2310.01074v2)|**[link](https://github.com/chenhan97/timellama)**|\n", "2310.00647": "|**2023-10-01**|**Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning**|Mustafa Shukor et.al.|[2310.00647v1](http://arxiv.org/abs/2310.00647v1)|**[link](https://github.com/mshukor/EvALign-ICL)**|\n", "2310.00603": "|**2023-11-22**|**Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals**|Yair Gat et.al.|[2310.00603v2](http://arxiv.org/abs/2310.00603v2)|null|\n", "2310.01441": "|**2023-09-30**|**UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities**|Hejia Geng et.al.|[2310.01441v1](http://arxiv.org/abs/2310.01441v1)|null|\n", "2309.17057": "|**2023-09-29**|**Tell Me a Story! Narrative-Driven XAI with Large Language Models**|David Martens et.al.|[2309.17057v1](http://arxiv.org/abs/2309.17057v1)|**[link](https://github.com/admantwerp/xaistories)**|\n", "2309.16146": "|**2023-09-28**|**T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems**|Ming Wang et.al.|[2309.16146v1](http://arxiv.org/abs/2309.16146v1)|**[link](https://github.com/neu-datamining/t-col)**|\n", "2309.16090": "|**2023-09-28**|**TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration**|Hongru Wang et.al.|[2309.16090v1](http://arxiv.org/abs/2309.16090v1)|null|\n", "2309.16021": "|**2023-09-27**|**HuntGPT: Integrating Machine Learning-Based Anomaly Detection and Explainable AI with Large Language Models (LLMs)**|Tarek Ali et.al.|[2309.16021v1](http://arxiv.org/abs/2309.16021v1)|null|\n", "2309.15729": "|**2023-09-27**|**MindGPT: Interpreting What You See with Non-invasive Brain Recordings**|Jiaxuan Chen et.al.|[2309.15729v1](http://arxiv.org/abs/2309.15729v1)|**[link](https://github.com/jxuanc/mindgpt)**|\n", "2311.01463": "|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|\n", "2309.13340": "|**2023-09-23**|**LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?**|Amrita Bhattacharjee et.al.|[2309.13340v1](http://arxiv.org/abs/2309.13340v1)|null|\n", "2309.11805": "|**2023-09-21**|**JobRecoGPT -- Explainable job recommendations using LLMs**|Preetam Ghosh et.al.|[2309.11805v1](http://arxiv.org/abs/2309.11805v1)|null|\n", "2309.11439": "|**2023-09-20**|**Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction**|Masahiro Kaneko et.al.|[2309.11439v1](http://arxiv.org/abs/2309.11439v1)|**[link](https://github.com/kanekomasahiro/gec-explanation)**|\n", "2309.11063": "|**2023-09-20**|**XATU: A Fine-grained Instruction-based Benchmark for Explainable Text Updates**|Haopeng Zhang et.al.|[2309.11063v1](http://arxiv.org/abs/2309.11063v1)|**[link](https://github.com/megagonlabs/xatu)**|\n", "2309.10346": "|**2023-09-19**|**Explaining Agent Behavior with Large Language Models**|Xijia Zhang et.al.|[2309.10346v1](http://arxiv.org/abs/2309.10346v1)|null|\n", "2309.10312": "|**2023-09-19**|**Rigorously Assessing Natural Language Explanations of Neurons**|Jing Huang et.al.|[2309.10312v1](http://arxiv.org/abs/2309.10312v1)|null|\n", "2309.09919": "|**2023-10-14**|**Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents**|Ziyi Yang et.al.|[2309.09919v2](http://arxiv.org/abs/2309.09919v2)|null|\n", "2309.08583": "|**2023-09-15**|**ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer**|Arkadiy Saakyan et.al.|[2309.08583v1](http://arxiv.org/abs/2309.08583v1)|**[link](https://github.com/asaakyan/explain-st)**|\n", "2309.08182": "|**2023-09-20**|**Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level**|Jingzhe Ding et.al.|[2309.08182v2](http://arxiv.org/abs/2309.08182v2)|null|\n", "2309.07864": "|**2023-09-19**|**The Rise and Potential of Large Language Model Based Agents: A Survey**|Zhiheng Xi et.al.|[2309.07864v3](http://arxiv.org/abs/2309.07864v3)|**[link](https://github.com/woooodyy/llm-agent-paper-list)**|\n", "2309.05951": "|**2023-09-12**|**Balanced and Explainable Social Media Analysis for Public Health with Large Language Models**|Yan Jiang et.al.|[2309.05951v1](http://arxiv.org/abs/2309.05951v1)|**[link](https://github.com/yanjiangjerry/alex)**|\n", "2309.05918": "|**2023-09-14**|**Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs**|Walid S. Saba et.al.|[2309.05918v3](http://arxiv.org/abs/2309.05918v3)|null|\n", "2309.04842": "|**2023-09-12**|**Leveraging Large Language Models for Exploiting ASR Uncertainty**|Pranay Dighe et.al.|[2309.04842v2](http://arxiv.org/abs/2309.04842v2)|null|\n", "2309.04823": "|**2023-09-09**|**FaNS: a Facet-based Narrative Similarity Metric**|Mousumi Akter et.al.|[2309.04823v1](http://arxiv.org/abs/2309.04823v1)|null|\n", "2309.04292": "|**2023-09-08**|**Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations**|Patr\u00edcia Pereira et.al.|[2309.04292v1](http://arxiv.org/abs/2309.04292v1)|null|\n", "2309.03118": "|**2023-09-06**|**Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs**|Chao Feng et.al.|[2309.03118v1](http://arxiv.org/abs/2309.03118v1)|null|\n", "2309.02726": "|**2023-09-06**|**Large Language Models for Automated Open-domain Scientific Hypotheses Discovery**|Zonglin Yang et.al.|[2309.02726v1](http://arxiv.org/abs/2309.02726v1)|**[link](https://github.com/zongliny/moose)**|\n", "2309.01029": "|**2023-09-17**|**Explainability for Large Language Models: A Survey**|Haiyan Zhao et.al.|[2309.01029v2](http://arxiv.org/abs/2309.01029v2)|null|\n", "2309.00733": "|**2023-11-02**|**Learned Visual Features to Textual Explanations**|Saeid Asgari Taghanaki et.al.|[2309.00733v2](http://arxiv.org/abs/2309.00733v2)|null|\n", "2309.00254": "|**2023-09-01**|**Why do universal adversarial attacks work on large language models?: Geometry might be the answer**|Varshini Subhash et.al.|[2309.00254v1](http://arxiv.org/abs/2309.00254v1)|null|\n", "2308.15812": "|**2023-08-30**|**Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models**|Hritik Bansal et.al.|[2308.15812v1](http://arxiv.org/abs/2308.15812v1)|**[link](https://github.com/hritikbansal/sparse_feedback)**|\n", "2308.15399": "|**2023-08-29**|**Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?**|Jingyan Zhou et.al.|[2308.15399v1](http://arxiv.org/abs/2308.15399v1)|null|\n", "2308.15047": "|**2023-08-29**|**Large language models converge toward human-like concept organization**|Mathias Lykke Gammelgaard et.al.|[2308.15047v1](http://arxiv.org/abs/2308.15047v1)|null|\n", "2308.14321": "|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|\n", "2308.12287": "|**2023-08-23**|**Devising and Detecting Phishing: Large Language Models vs. Smaller Human Models**|Fredrik Heiding et.al.|[2308.12287v1](http://arxiv.org/abs/2308.12287v1)|null|\n", "2308.12241": "|**2023-08-23**|**LLMRec: Benchmarking Large Language Models on Recommendation Task**|Junling Liu et.al.|[2308.12241v1](http://arxiv.org/abs/2308.12241v1)|**[link](https://github.com/williamliujl/llmrec)**|\n", "2308.11920": "|**2023-08-23**|**Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification**|Injae Kim et.al.|[2308.11920v1](http://arxiv.org/abs/2308.11920v1)|null|\n", "2308.10397": "|**2023-10-27**|**FairMonitor: A Four-Stage Automatic Framework for Detecting Stereotypes and Biases in Large Language Models**|Yanhong Bai et.al.|[2308.10397v2](http://arxiv.org/abs/2308.10397v2)|null|\n", "2308.10380": "|**2023-08-23**|**A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability**|Ming Jin et.al.|[2308.10380v2](http://arxiv.org/abs/2308.10380v2)|null|\n", "2308.11585": "|**2023-08-19**|**Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes**|Yosuke Miyanishi et.al.|[2308.11585v1](http://arxiv.org/abs/2308.11585v1)|null|\n", "2308.09890": "|**2023-08-19**|**Inductive-bias Learning: Generating Code Models with Large Language Model**|Toma Tanaka et.al.|[2308.09890v1](http://arxiv.org/abs/2308.09890v1)|**[link](https://github.com/fuyu-quant/iblm)**|\n", "2308.09033": "|**2023-09-19**|**Uni-NLX: Unifying Textual Explanations for Vision and Vision-Language Tasks**|Fawaz Sammani et.al.|[2308.09033v2](http://arxiv.org/abs/2308.09033v2)|**[link](https://github.com/fawazsammani/uni-nlx)**|\n", "2308.13534": "|**2023-08-13**|**Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph**|Ahtsham Zafar et.al.|[2308.13534v1](http://arxiv.org/abs/2308.13534v1)|null|\n", "2308.06261": "|**2023-08-11**|**Enhancing Network Management Using Code Generated by Large Language Models**|Sathiya Kumaran Mani et.al.|[2308.06261v1](http://arxiv.org/abs/2308.06261v1)|**[link](https://github.com/microsoft/nemoeval)**|\n", "2308.05585": "|**2023-08-10**|**Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length**|Miao Fan et.al.|[2308.05585v1](http://arxiv.org/abs/2308.05585v1)|null|\n", "2308.05487": "|**2023-08-26**|**A Preliminary Evaluation of LLM-Based Fault Localization**|Sungmin Kang et.al.|[2308.05487v2](http://arxiv.org/abs/2308.05487v2)|null|\n", "2308.05374": "|**2023-08-10**|**Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment**|Yang Liu et.al.|[2308.05374v1](http://arxiv.org/abs/2308.05374v1)|**[link](https://github.com/kevinyaobytedance/llm_eval)**|\n", "2308.03873": "|**2023-08-07**|**Evaluating and Explaining Large Language Models for Code Using Syntactic Structures**|David N Palacio et.al.|[2308.03873v1](http://arxiv.org/abs/2308.03873v1)|null|\n", "2308.02357": "|**2023-08-04**|**Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text**|Nandana Mihindukulasooriya et.al.|[2308.02357v1](http://arxiv.org/abs/2308.02357v1)|**[link](https://zenodo.org/record/7916716)**|\n", "2308.02575": "|**2023-08-03**|**Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings**|Veronika Hackl et.al.|[2308.02575v1](http://arxiv.org/abs/2308.02575v1)|null|\n", "2308.01936": "|**2023-09-12**|**Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?**|Thilini Wijesiriwardene et.al.|[2308.01936v2](http://arxiv.org/abs/2308.01936v2)|null|\n", "2308.01264": "|**2023-08-02**|**Exploring the psychology of GPT-4's Moral and Legal Reasoning**|Guilherme F. C. F. Almeida et.al.|[2308.01264v1](http://arxiv.org/abs/2308.01264v1)|null|\n", "2308.01222": "|**2023-08-02**|**Calibration in Deep Learning: A Survey of the State-of-the-Art**|Cheng Wang et.al.|[2308.01222v1](http://arxiv.org/abs/2308.01222v1)|null|\n", "2308.00319": "|**2023-08-01**|**LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial Attack**|Hai Zhu et.al.|[2308.00319v1](http://arxiv.org/abs/2308.00319v1)|null|\n", "2308.00189": "|**2023-07-31**|**Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?**|Ari Holtzman et.al.|[2308.00189v1](http://arxiv.org/abs/2308.00189v1)|null|\n", "2307.16376": "|**2023-07-31**|**When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities**|Jin Chen et.al.|[2307.16376v1](http://arxiv.org/abs/2307.16376v1)|null|\n", "2307.15331": "|**2023-07-28**|**Tutorials on Stance Detection using Pre-trained Language Models: Fine-tuning BERT and Prompting Large Language Models**|Yun-Shiuan Chuang et.al.|[2307.15331v1](http://arxiv.org/abs/2307.15331v1)|null|\n", "2307.14225": "|**2023-07-26**|**Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences**|Scott Sanner et.al.|[2307.14225v1](http://arxiv.org/abs/2307.14225v1)|null|\n", "2307.10793": "|**2023-07-20**|**Addressing Compiler Errors: Stack Overflow or Large Language Models?**|Patricia Widjojo et.al.|[2307.10793v1](http://arxiv.org/abs/2307.10793v1)|**[link](https://github.com/patwdj/java-compiler-error-help)**|\n", "2307.09009": "|**2023-10-31**|**How is ChatGPT's behavior changing over time?**|Lingjiao Chen et.al.|[2307.09009v3](http://arxiv.org/abs/2307.09009v3)|**[link](https://github.com/lchen001/llmdrift)**|\n", "2307.08678": "|**2023-07-17**|**Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations**|Yanda Chen et.al.|[2307.08678v1](http://arxiv.org/abs/2307.08678v1)|null|\n", "2307.08423": "|**2023-11-15**|**Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems**|Xuan Zhang et.al.|[2307.08423v2](http://arxiv.org/abs/2307.08423v2)|**[link](https://github.com/divelab/AIRS)**|\n", "2307.08321": "|**2023-07-17**|**Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction**|Cong Jiang et.al.|[2307.08321v1](http://arxiv.org/abs/2307.08321v1)|**[link](https://github.com/jiangcong7/legal-syllogism-prompting)**|\n", "2307.08177": "|**2023-08-10**|**In-IDE Generation-based Information Support with a Large Language Model**|Daye Nam et.al.|[2307.08177v2](http://arxiv.org/abs/2307.08177v2)|null|\n", "2307.07922": "|**2023-07-16**|**InkSight: Leveraging Sketch Interaction for Documenting Chart Findings in Computational Notebooks**|Yanna Lin et.al.|[2307.07922v1](http://arxiv.org/abs/2307.07922v1)|null|\n", "2307.05052": "|**2023-07-11**|**Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps**|Zongxia Li et.al.|[2307.05052v1](http://arxiv.org/abs/2307.05052v1)|**[link](https://github.com/paihengxu/xicl)**|\n", "2307.03875": "|**2023-07-13**|**Large Language Models for Supply Chain Optimization**|Beibin Li et.al.|[2307.03875v2](http://arxiv.org/abs/2307.03875v2)|null|\n", "2307.03381": "|**2023-07-07**|**Teaching Arithmetic to Small Transformers**|Nayoung Lee et.al.|[2307.03381v1](http://arxiv.org/abs/2307.03381v1)|**[link](https://github.com/lee-ny/teaching_arithmetic)**|\n", "2307.02157": "|**2023-07-05**|**Generative Job Recommendations with Large Language Model**|Zhi Zheng et.al.|[2307.02157v1](http://arxiv.org/abs/2307.02157v1)|null|\n", "2307.01981": "|**2023-07-05**|**A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image Diagnosis**|Jiaxiang Liu et.al.|[2307.01981v1](http://arxiv.org/abs/2307.01981v1)|null|\n", "2306.15887": "|**2023-06-28**|**Beyond the Hype: Assessing the Performance, Trustworthiness, and Clinical Suitability of GPT3.5**|Salmonn Talebi et.al.|[2306.15887v1](http://arxiv.org/abs/2306.15887v1)|null|\n", "2306.15724": "|**2023-10-16**|**REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction**|Zeyi Liu et.al.|[2306.15724v4](http://arxiv.org/abs/2306.15724v4)|**[link](https://github.com/real-stanford/reflect)**|\n", "2306.15401": "|**2023-08-24**|**Explainable Multimodal Emotion Reasoning**|Zheng Lian et.al.|[2306.15401v3](http://arxiv.org/abs/2306.15401v3)|**[link](https://github.com/zeroqiaoba/affectgpt)**|\n", "2306.14504": "|**2023-06-26**|**ChatIDS: Explainable Cybersecurity Using Generative AI**|Victor J\u00fcttner et.al.|[2306.14504v1](http://arxiv.org/abs/2306.14504v1)|null|\n", "2306.13041": "|**2023-06-22**|**Towards Explainable Evaluation Metrics for Machine Translation**|Christoph Leiter et.al.|[2306.13041v1](http://arxiv.org/abs/2306.13041v1)|null|\n", "2306.11585": "|**2023-07-20**|**FAIR: A Causal Framework for Accurately Inferring Judgments Reversals**|Minghua He et.al.|[2306.11585v2](http://arxiv.org/abs/2306.11585v2)|null|\n", "2306.11025": "|**2023-06-19**|**Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting**|Xinli Yu et.al.|[2306.11025v1](http://arxiv.org/abs/2306.11025v1)|null|\n", "2307.01201": "|**2023-06-16**|**Schema-learning and rebinding as mechanisms of in-context learning and emergence**|Sivaramakrishnan Swaminathan et.al.|[2307.01201v1](http://arxiv.org/abs/2307.01201v1)|null|\n", "2306.09525": "|**2023-06-22**|**Explaining Legal Concepts with Augmented Large Language Models (GPT-4)**|Jaromir Savelka et.al.|[2306.09525v2](http://arxiv.org/abs/2306.09525v2)|null|\n", "2306.09299": "|**2023-11-14**|**Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Personalization**|Swarnadeep Saha et.al.|[2306.09299v2](http://arxiv.org/abs/2306.09299v2)|**[link](https://github.com/swarnahub/explanationintervention)**|\n", "2306.10062": "|**2023-06-14**|**Revealing the structure of language model capabilities**|Ryan Burnell et.al.|[2306.10062v1](http://arxiv.org/abs/2306.10062v1)|**[link](https://github.com/ryanburnell/revealing-llm-capabilities)**|\n", "2306.07486": "|**2023-06-13**|**Knowledge-Prompted Estimator: A Novel Approach to Explainable Machine Translation Assessment**|Hao Yang et.al.|[2306.07486v1](http://arxiv.org/abs/2306.07486v1)|null|\n", "2306.07377": "|**2023-06-12**|**Lost in Translation: Large Language Models in Non-English Content Analysis**|Gabriel Nicholas et.al.|[2306.07377v1](http://arxiv.org/abs/2306.07377v1)|null|\n", "2306.05715": "|**2023-06-09**|**Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests**|Arto Hellas et.al.|[2306.05715v1](http://arxiv.org/abs/2306.05715v1)|null|\n", "2306.05685": "|**2023-10-15**|**Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena**|Lianmin Zheng et.al.|[2306.05685v3](http://arxiv.org/abs/2306.05685v3)|**[link](https://github.com/lm-sys/fastchat)**|\n", "2306.04746": "|**2023-10-31**|**Using Imperfect Surrogates for Downstream Inference: Design-based Supervised Learning for Social Science Applications of Large Language Models**|Naoki Egami et.al.|[2306.04746v2](http://arxiv.org/abs/2306.04746v2)|null|\n", "2306.04563": "|**2023-06-07**|**ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models**|Sophie Jentzsch et.al.|[2306.04563v1](http://arxiv.org/abs/2306.04563v1)|**[link](https://github.com/dlr-sc/jokegpt-wassa23)**|\n", "2306.05524": "|**2023-06-07**|**Check Me If You Can: Detecting ChatGPT-Generated Academic Writing using CheckGPT**|Zeyan Liu et.al.|[2306.05524v1](http://arxiv.org/abs/2306.05524v1)|**[link](https://github.com/liuzey/CheckGPT)**|\n", "2306.03809": "|**2023-06-06**|**Can large language models democratize access to dual-use biotechnology?**|Emily H. Soice et.al.|[2306.03809v1](http://arxiv.org/abs/2306.03809v1)|null|\n", "2306.03100": "|**2023-06-29**|**Rethinking Model Evaluation as Narrowing the Socio-Technical Gap**|Q. Vera Liao et.al.|[2306.03100v3](http://arxiv.org/abs/2306.03100v3)|null|\n", "2306.00108": "|**2023-08-16**|**Better patching using LLM prompting, via Self-Consistency**|Toufique Ahmed et.al.|[2306.00108v2](http://arxiv.org/abs/2306.00108v2)|null|\n", "2306.00017": "|**2023-07-27**|**Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale**|Walid S. Saba et.al.|[2306.00017v4](http://arxiv.org/abs/2306.00017v4)|null|\n", "2305.18125": "|**2023-05-29**|**The Utility of Large Language Models and Generative AI for Education Research**|Andrew Katz et.al.|[2305.18125v1](http://arxiv.org/abs/2305.18125v1)|null|\n", "2305.18410": "|**2023-05-28**|**Understanding Breast Cancer Survival: Using Causality and Language Models on Multi-omics Data**|Mugariya Farooq et.al.|[2305.18410v1](http://arxiv.org/abs/2305.18410v1)|null|\n", "2305.17727": "|**2023-05-28**|**Learning a Structural Causal Model for Intuition Reasoning in Conversation**|Hang Chen et.al.|[2305.17727v1](http://arxiv.org/abs/2305.17727v1)|null|\n", "2305.18365": "|**2023-09-10**|**What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks**|Taicheng Guo et.al.|[2305.18365v2](http://arxiv.org/abs/2305.18365v2)|**[link](https://github.com/chemfoundationmodels/chemllmbench)**|\n", "2305.17359": "|**2023-10-04**|**DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text**|Xianjun Yang et.al.|[2305.17359v2](http://arxiv.org/abs/2305.17359v2)|**[link](https://github.com/xianjun-yang/dna-gpt)**|\n", "2305.17040": "|**2023-05-26**|**A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks**|Jacob Abernethy et.al.|[2305.17040v1](http://arxiv.org/abs/2305.17040v1)|null|\n", "2305.15328": "|**2023-10-27**|**Visual Programming for Text-to-Image Generation and Evaluation**|Jaemin Cho et.al.|[2305.15328v2](http://arxiv.org/abs/2305.15328v2)|null|\n", "2305.14928": "|**2023-10-31**|**Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4**|Kellin Pelrine et.al.|[2305.14928v3](http://arxiv.org/abs/2305.14928v3)|**[link](https://github.com/complexdata-mila/mitigatemisinfo)**|\n", "2305.14847": "|**2023-05-24**|**Drafting Event Schemas using Language Models**|Anisha Gunjal et.al.|[2305.14847v1](http://arxiv.org/abs/2305.14847v1)|null|\n", "2305.13112": "|**2023-11-03**|**Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models**|Xiaolei Wang et.al.|[2305.13112v2](http://arxiv.org/abs/2305.13112v2)|**[link](https://github.com/rucaibox/ievalm-crs)**|\n", "2305.12962": "|**2023-10-24**|**Distilling ChatGPT for Explainable Automated Student Answer Assessment**|Jiazheng Li et.al.|[2305.12962v2](http://arxiv.org/abs/2305.12962v2)|**[link](https://github.com/lijiazheng99/aera)**|\n", "2305.12766": "|**2023-10-05**|**Explaining Emergent In-Context Learning as Kernel Regression**|Chi Han et.al.|[2305.12766v2](http://arxiv.org/abs/2305.12766v2)|null|\n", "2305.12477": "|**2023-09-19**|**GPT-3.5, GPT-4, or BARD? Evaluating LLMs Reasoning Ability in Zero-Shot Setting and Performance Boosting Through Prompts**|Jessica L\u00f3pez Espejel et.al.|[2305.12477v2](http://arxiv.org/abs/2305.12477v2)|null|\n", "2305.12265": "|**2023-05-20**|**Tweetorial Hooks: Generative AI Tools to Motivate Science on Social Media**|Tao Long et.al.|[2305.12265v1](http://arxiv.org/abs/2305.12265v1)|null|\n", "2305.12182": "|**2023-05-26**|**Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages**|Ayyoob Imani et.al.|[2305.12182v2](http://arxiv.org/abs/2305.12182v2)|**[link](https://github.com/cisnlp/glot500)**|\n", "2305.12167": "|**2023-05-20**|**The Case Against Explainability**|Hofit Wasserman Rozen et.al.|[2305.12167v1](http://arxiv.org/abs/2305.12167v1)|null|\n", "2305.10843": "|**2023-05-26**|**X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models**|Yixiong Chen et.al.|[2305.10843v2](http://arxiv.org/abs/2305.10843v2)|**[link](https://github.com/schuture/benchmarking-awesome-diffusion-models)**|\n", "2305.10790": "|**2023-10-02**|**Listen, Think, and Understand**|Yuan Gong et.al.|[2305.10790v2](http://arxiv.org/abs/2305.10790v2)|**[link](https://github.com/YuanGongND/ltu)**|\n", "2305.10614": "|**2023-06-02**|**Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions**|Byung-Doh Oh et.al.|[2305.10614v2](http://arxiv.org/abs/2305.10614v2)|**[link](https://github.com/byungdoh/llm_decomposition)**|\n", "2305.10266": "|**2023-05-17**|**Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability**|Eleftheria Briakou et.al.|[2305.10266v1](http://arxiv.org/abs/2305.10266v1)|null|\n", "2305.09863": "|**2023-11-15**|**Explaining black box text modules in natural language with language models**|Chandan Singh et.al.|[2305.09863v2](http://arxiv.org/abs/2305.09863v2)|**[link](https://github.com/csinva/imodelsX)**|\n", "2305.07961": "|**2023-05-16**|**Leveraging Large Language Models in Conversational Recommender Systems**|Luke Friedman et.al.|[2305.07961v2](http://arxiv.org/abs/2305.07961v2)|null|\n", "2305.07457": "|**2023-07-13**|**Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation**|Tu Anh Dinh et.al.|[2305.07457v2](http://arxiv.org/abs/2305.07457v2)|**[link](https://github.com/tuanh23/perturbation-basedqe)**|\n", "2305.06841": "|**2023-05-11**|**Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models**|Luk\u00e1\u0161 Mikula et.al.|[2305.06841v1](http://arxiv.org/abs/2305.06841v1)|null|\n", "2305.06358": "|**2023-05-08**|**Accessible Instruction-Following Agent**|Kairui Zhou et.al.|[2305.06358v1](http://arxiv.org/abs/2305.06358v1)|null|\n", "2305.04812": "|**2023-10-20**|**Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns**|Ning Bian et.al.|[2305.04812v3](http://arxiv.org/abs/2305.04812v3)|null|\n", "2305.04388": "|**2023-05-07**|**Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting**|Miles Turpin et.al.|[2305.04388v1](http://arxiv.org/abs/2305.04388v1)|**[link](https://github.com/milesaturpin/cot-unfaithfulness)**|\n"}, "LLM - Safety": {"2311.15936": "|**2023-11-27**|**Towards Responsible Governance of Biological Design Tools**|Richard Moulange et.al.|[2311.15936v1](http://arxiv.org/abs/2311.15936v1)|null|\n", "2311.15180": "|**2023-11-26**|**Benchmarking Large Language Model Volatility**|Boyang Yu et.al.|[2311.15180v1](http://arxiv.org/abs/2311.15180v1)|null|\n", "2311.14966": "|**2023-11-25**|**Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains**|Chia-Chien Hung et.al.|[2311.14966v1](http://arxiv.org/abs/2311.14966v1)|null|\n", "2311.13577": "|**2023-11-22**|**Physical Reasoning and Object Planning for Household Embodied Agents**|Ayush Agrawal et.al.|[2311.13577v1](http://arxiv.org/abs/2311.13577v1)|**[link](https://github.com/com-phy-affordance/coat)**|\n", "2311.12893": "|**2023-11-21**|**A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs**|Jiageng Zhong et.al.|[2311.12893v1](http://arxiv.org/abs/2311.12893v1)|null|\n", "2311.11855": "|**2023-11-20**|**Evil Geniuses: Delving into the Safety of LLM-based Agents**|Yu Tian et.al.|[2311.11855v1](http://arxiv.org/abs/2311.11855v1)|**[link](https://github.com/t1ans1r/evil-geniuses)**|\n", "2311.11797": "|**2023-11-20**|**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**|Zhuosheng Zhang et.al.|[2311.11797v1](http://arxiv.org/abs/2311.11797v1)|**[link](https://github.com/zoeyyao27/cot-igniting-agent)**|\n", "2311.11415": "|**2023-11-19**|**A Security Risk Taxonomy for Large Language Models**|Erik Derner et.al.|[2311.11415v1](http://arxiv.org/abs/2311.11415v1)|null|\n", "2311.09827": "|**2023-11-16**|**Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking**|Nan Xu et.al.|[2311.09827v1](http://arxiv.org/abs/2311.09827v1)|null|\n", "2311.14712": "|**2023-11-16**|**Multiagent Simulators for Social Networks**|Aditya Surve et.al.|[2311.14712v1](http://arxiv.org/abs/2311.14712v1)|null|\n", "2311.09641": "|**2023-11-16**|**On the Exploitability of Reinforcement Learning with Human Feedback for Large Language Models**|Jiongxiao Wang et.al.|[2311.09641v1](http://arxiv.org/abs/2311.09641v1)|null|\n", "2311.09585": "|**2023-11-16**|**LifeTox: Unveiling Implicit Toxicity in Life Advice**|Minbeom Kim et.al.|[2311.09585v1](http://arxiv.org/abs/2311.09585v1)|null|\n", "2311.09447": "|**2023-11-15**|**How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities**|Lingbo Mo et.al.|[2311.09447v1](http://arxiv.org/abs/2311.09447v1)|**[link](https://github.com/osu-nlp-group/eval-llm-trust)**|\n", "2311.09433": "|**2023-11-24**|**Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment**|Haoran Wang et.al.|[2311.09433v2](http://arxiv.org/abs/2311.09433v2)|**[link](https://github.com/wang2226/backdoor-activation-attack)**|\n", "2311.09358": "|**2023-11-15**|**Empirical evaluation of Uncertainty Quantification in Retrieval-Augmented Language Models for Science**|Sridevi Wagle et.al.|[2311.09358v1](http://arxiv.org/abs/2311.09358v1)|**[link](https://github.com/pnnl/expert2)**|\n", "2311.09335": "|**2023-11-15**|**Lighter, yet More Faithful: Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization**|George Chrysostomou et.al.|[2311.09335v1](http://arxiv.org/abs/2311.09335v1)|null|\n", "2311.09096": "|**2023-11-15**|**Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization**|Zhexin Zhang et.al.|[2311.09096v1](http://arxiv.org/abs/2311.09096v1)|**[link](https://github.com/thu-coai/jailbreakdefense_goalpriority)**|\n", "2311.08838": "|**2023-11-15**|**Disinformation Capabilities of Large Language Models**|Ivan Vykopal et.al.|[2311.08838v1](http://arxiv.org/abs/2311.08838v1)|null|\n", "2311.08592": "|**2023-11-14**|**AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications**|Bhaktipriya Radharapu et.al.|[2311.08592v1](http://arxiv.org/abs/2311.08592v1)|null|\n", "2311.08370": "|**2023-11-14**|**SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models**|Bertie Vidgen et.al.|[2311.08370v1](http://arxiv.org/abs/2311.08370v1)|null|\n", "2311.08303": "|**2023-11-14**|**Extrinsically-Focused Evaluation of Omissions in Medical Summarization**|Elliot Schumacher et.al.|[2311.08303v1](http://arxiv.org/abs/2311.08303v1)|null|\n", "2311.08298": "|**2023-11-14**|**A Survey of Language Model Confidence Estimation and Calibration**|Jiahui Geng et.al.|[2311.08298v1](http://arxiv.org/abs/2311.08298v1)|null|\n", "2311.07689": "|**2023-11-13**|**MART: Improving LLM Safety with Multi-round Automatic Red-Teaming**|Suyu Ge et.al.|[2311.07689v1](http://arxiv.org/abs/2311.07689v1)|null|\n", "2311.07469": "|**2023-11-15**|**InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models**|Ken E. Friedl et.al.|[2311.07469v2](http://arxiv.org/abs/2311.07469v2)|null|\n", "2311.07377": "|**2023-11-13**|**Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach**|Xi Zheng et.al.|[2311.07377v1](http://arxiv.org/abs/2311.07377v1)|null|\n", "2311.06899": "|**2023-11-12**|**Flames: Benchmarking Value Alignment of Chinese Large Language Models**|Kexin Huang et.al.|[2311.06899v1](http://arxiv.org/abs/2311.06899v1)|null|\n", "2311.06668": "|**2023-11-16**|**In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**|Sheng Liu et.al.|[2311.06668v2](http://arxiv.org/abs/2311.06668v2)|**[link](https://github.com/shengliu66/icv)**|\n", "2311.06622": "|**2023-11-23**|**TrainerAgent: Customizable and Efficient Model Training through LLM-Powered Multi-Agent System**|Haoyuan Li et.al.|[2311.06622v2](http://arxiv.org/abs/2311.06622v2)|null|\n", "2311.05915": "|**2023-11-14**|**Fake Alignment: Are LLMs Really Aligned Well?**|Yixu Wang et.al.|[2311.05915v2](http://arxiv.org/abs/2311.05915v2)|null|\n", "2311.05608": "|**2023-11-09**|**FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts**|Yichen Gong et.al.|[2311.05608v1](http://arxiv.org/abs/2311.05608v1)|**[link](https://github.com/thuccslab/figstep)**|\n", "2311.04124": "|**2023-11-07**|**Unveiling Safety Vulnerabilities of Large Language Models**|George Kour et.al.|[2311.04124v1](http://arxiv.org/abs/2311.04124v1)|null|\n", "2311.03191": "|**2023-11-06**|**DeepInception: Hypnotize Large Language Model to Be Jailbreaker**|Xuan Li et.al.|[2311.03191v1](http://arxiv.org/abs/2311.03191v1)|**[link](https://github.com/tmlr-group/deepinception)**|\n", "2311.02147": "|**2023-11-03**|**The Alignment Problem in Context**|Rapha\u00ebl Milli\u00e8re et.al.|[2311.02147v1](http://arxiv.org/abs/2311.02147v1)|null|\n", "2311.01918": "|**2023-11-03**|**Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review**|Mingze Yuan et.al.|[2311.01918v1](http://arxiv.org/abs/2311.01918v1)|**[link](https://github.com/mingze-yuan/awesome-llm-healthcare)**|\n", "2311.04921": "|**2023-11-03**|**Successor Features for Efficient Multisubject Controlled Text Generation**|Meng Cao et.al.|[2311.04921v1](http://arxiv.org/abs/2311.04921v1)|null|\n", "2311.02105": "|**2023-11-02**|**Making Harmful Behaviors Unlearnable for Large Language Models**|Xin Zhou et.al.|[2311.02105v1](http://arxiv.org/abs/2311.02105v1)|null|\n", "2311.01025": "|**2023-11-02**|**Incorporating Language-Driven Appearance Knowledge Units with Visual Cues in Pedestrian Detection**|Sungjune Park et.al.|[2311.01025v1](http://arxiv.org/abs/2311.01025v1)|null|\n", "2311.00321": "|**2023-11-22**|**HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning**|Yongjin Yang et.al.|[2311.00321v2](http://arxiv.org/abs/2311.00321v2)|**[link](https://github.com/joonkeekim/hare-hate-speech)**|\n", "2311.00172": "|**2023-10-31**|**Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield**|Jinhwa Kim et.al.|[2311.00172v1](http://arxiv.org/abs/2311.00172v1)|null|\n", "2311.00168": "|**2023-10-31**|**The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback**|Nathan Lambert et.al.|[2311.00168v1](http://arxiv.org/abs/2311.00168v1)|null|\n", "2311.00117": "|**2023-10-31**|**BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B**|Pranav Gade et.al.|[2311.00117v1](http://arxiv.org/abs/2311.00117v1)|null|\n", "2310.20624": "|**2023-10-31**|**LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B**|Simon Lermen et.al.|[2310.20624v1](http://arxiv.org/abs/2310.20624v1)|null|\n", "2310.19736": "|**2023-11-25**|**Evaluating Large Language Models: A Comprehensive Survey**|Zishan Guo et.al.|[2310.19736v3](http://arxiv.org/abs/2310.19736v3)|**[link](https://github.com/tjunlp-lab/awesome-llms-evaluation-papers)**|\n", "2310.19626": "|**2023-10-30**|**Transformation vs Tradition: Artificial General Intelligence (AGI) for Arts and Humanities**|Zhengliang Liu et.al.|[2310.19626v1](http://arxiv.org/abs/2310.19626v1)|null|\n", "2310.18130": "|**2023-11-07**|**DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues**|David Q. Sun et.al.|[2310.18130v2](http://arxiv.org/abs/2310.18130v2)|**[link](https://github.com/zidixiu/delphi)**|\n", "2310.16959": "|**2023-10-25**|**Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning**|Ananth Balashankar et.al.|[2310.16959v1](http://arxiv.org/abs/2310.16959v1)|null|\n", "2310.16763": "|**2023-10-25**|**SuperHF: Supervised Iterative Learning from Human Feedback**|Gabriel Mukobi et.al.|[2310.16763v1](http://arxiv.org/abs/2310.16763v1)|**[link](https://github.com/openfeedback/superhf)**|\n", "2310.15851": "|**2023-10-24**|**Self-Guard: Empower the LLM to Safeguard Itself**|Zezhong Wang et.al.|[2310.15851v1](http://arxiv.org/abs/2310.15851v1)|null|\n", "2310.15140": "|**2023-10-23**|**AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models**|Sicheng Zhu et.al.|[2310.15140v1](http://arxiv.org/abs/2310.15140v1)|null|\n", "2310.14414": "|**2023-10-22**|**Vision Language Models in Autonomous Driving and Intelligent Transportation Systems**|Xingcheng Zhou et.al.|[2310.14414v1](http://arxiv.org/abs/2310.14414v1)|**[link](https://github.com/ge25nab/Awesome-VLM-AD-ITS)**|\n", "2310.14303": "|**2023-11-13**|**Language Model Unalignment: Parametric Red-Teaming to Expose Hidden Harms and Biases**|Rishabh Bhardwaj et.al.|[2310.14303v2](http://arxiv.org/abs/2310.14303v2)|null|\n", "2310.13345": "|**2023-10-20**|**An LLM can Fool Itself: A Prompt-Based Adversarial Attack**|Xilie Xu et.al.|[2310.13345v1](http://arxiv.org/abs/2310.13345v1)|null|\n", "2310.13132": "|**2023-10-23**|**Better to Ask in English: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries**|Yiqiao Jin et.al.|[2310.13132v2](http://arxiv.org/abs/2310.13132v2)|**[link](https://github.com/claws-lab/XLingEval)**|\n", "2310.12931": "|**2023-10-19**|**Eureka: Human-Level Reward Design via Coding Large Language Models**|Yecheng Jason Ma et.al.|[2310.12931v1](http://arxiv.org/abs/2310.12931v1)|**[link](https://github.com/eureka-research/Eureka)**|\n", "2310.12803": "|**2023-10-19**|**Causal-structure Driven Augmentations for Text OOD Generalization**|Amir Feder et.al.|[2310.12803v1](http://arxiv.org/abs/2310.12803v1)|null|\n", "2310.12773": "|**2023-10-19**|**Safe RLHF: Safe Reinforcement Learning from Human Feedback**|Josef Dai et.al.|[2310.12773v1](http://arxiv.org/abs/2310.12773v1)|**[link](https://github.com/pku-alignment/safe-rlhf)**|\n", "2310.12505": "|**2023-10-19**|**Attack Prompt Generation for Red Teaming and Defending Large Language Models**|Boyi Deng et.al.|[2310.12505v1](http://arxiv.org/abs/2310.12505v1)|**[link](https://github.com/aatrox103/sap)**|\n", "2310.10844": "|**2023-10-16**|**Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks**|Erfan Shayegani et.al.|[2310.10844v1](http://arxiv.org/abs/2310.10844v1)|null|\n", "2310.10477": "|**2023-10-20**|**Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis**|Kai Chen et.al.|[2310.10477v2](http://arxiv.org/abs/2310.10477v2)|null|\n", "2310.10383": "|**2023-10-16**|**Privacy in Large Language Models: Attacks, Defenses and Future Directions**|Haoran Li et.al.|[2310.10383v1](http://arxiv.org/abs/2310.10383v1)|null|\n", "2310.10077": "|**2023-10-16**|**Prompt Packer: Deceiving LLMs through Compositional Instruction with Hidden Attacks**|Shuyu Jiang et.al.|[2310.10077v1](http://arxiv.org/abs/2310.10077v1)|null|\n", "2310.09624": "|**2023-11-11**|**ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models**|Alex Mei et.al.|[2310.09624v2](http://arxiv.org/abs/2310.09624v2)|**[link](https://github.com/alexmeigz/assert)**|\n", "2310.08419": "|**2023-10-13**|**Jailbreaking Black Box Large Language Models in Twenty Queries**|Patrick Chao et.al.|[2310.08419v2](http://arxiv.org/abs/2310.08419v2)|**[link](https://github.com/patrickrchao/jailbreakingllms)**|\n", "2310.08034": "|**2023-10-12**|**Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2310.08034v1](http://arxiv.org/abs/2310.08034v1)|null|\n", "2310.07944": "|**2023-10-11**|**AutoRepo: A general framework for multi-modal LLM-based automated construction reporting**|Hongxu Pu et.al.|[2310.07944v1](http://arxiv.org/abs/2310.07944v1)|null|\n", "2310.06987": "|**2023-10-10**|**Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation**|Yangsibo Huang et.al.|[2310.06987v1](http://arxiv.org/abs/2310.06987v1)|**[link](https://github.com/princeton-sysml/jailbreak_llm)**|\n", "2310.06762": "|**2023-10-10**|**TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models**|Xiao Wang et.al.|[2310.06762v1](http://arxiv.org/abs/2310.06762v1)|**[link](https://github.com/beyonderxx/trace)**|\n", "2310.06474": "|**2023-10-10**|**Multilingual Jailbreak Challenges in Large Language Models**|Yue Deng et.al.|[2310.06474v1](http://arxiv.org/abs/2310.06474v1)|**[link](https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs)**|\n", "2310.06387": "|**2023-10-10**|**Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations**|Zeming Wei et.al.|[2310.06387v1](http://arxiv.org/abs/2310.06387v1)|null|\n", "2310.06200": "|**2023-10-11**|**The Importance of Prompt Tuning for Automated Neuron Explanations**|Justin Lee et.al.|[2310.06200v2](http://arxiv.org/abs/2310.06200v2)|null|\n", "2310.05818": "|**2023-10-09**|**SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese**|Liang Xu et.al.|[2310.05818v1](http://arxiv.org/abs/2310.05818v1)|null|\n", "2310.05553": "|**2023-10-09**|**Regulation and NLP (RegNLP): Taming Large Language Models**|Catalina Goanta et.al.|[2310.05553v1](http://arxiv.org/abs/2310.05553v1)|null|\n", "2310.03693": "|**2023-10-05**|**Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!**|Xiangyu Qi et.al.|[2310.03693v1](http://arxiv.org/abs/2310.03693v1)|**[link](https://github.com/llm-tuning-safety/llms-finetuning-safety)**|\n", "2310.03026": "|**2023-10-13**|**LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving**|Hao Sha et.al.|[2310.03026v2](http://arxiv.org/abs/2310.03026v2)|null|\n", "2310.02949": "|**2023-10-04**|**Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models**|Xianjun Yang et.al.|[2310.02949v1](http://arxiv.org/abs/2310.02949v1)|null|\n", "2310.02446": "|**2023-10-03**|**Low-Resource Languages Jailbreak GPT-4**|Zheng-Xin Yong et.al.|[2310.02446v1](http://arxiv.org/abs/2310.02446v1)|null|\n", "2310.01708": "|**2023-10-03**|**Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making**|D. Umerenkov et.al.|[2310.01708v1](http://arxiv.org/abs/2310.01708v1)|null|\n", "2310.01581": "|**2023-10-02**|**On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?**|Hangfan Zhang et.al.|[2310.01581v1](http://arxiv.org/abs/2310.01581v1)|null|\n", "2310.01405": "|**2023-10-10**|**Representation Engineering: A Top-Down Approach to AI Transparency**|Andy Zou et.al.|[2310.01405v3](http://arxiv.org/abs/2310.01405v3)|**[link](https://github.com/andyzoujm/representation-engineering)**|\n", "2310.01386": "|**2023-10-02**|**Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench**|Jen-tse Huang et.al.|[2310.01386v1](http://arxiv.org/abs/2310.01386v1)|**[link](https://github.com/cuhk-arise/psychobench)**|\n", "2310.01320": "|**2023-10-24**|**Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation**|Shenzhi Wang et.al.|[2310.01320v3](http://arxiv.org/abs/2310.01320v3)|null|\n", "2310.00905": "|**2023-10-02**|**All Languages Matter: On the Multilingual Safety of Large Language Models**|Wenxuan Wang et.al.|[2310.00905v1](http://arxiv.org/abs/2310.00905v1)|**[link](https://github.com/jarviswang94/multilingual_safety_benchmark)**|\n", "2310.00603": "|**2023-11-22**|**Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals**|Yair Gat et.al.|[2310.00603v2](http://arxiv.org/abs/2310.00603v2)|null|\n", "2309.16436": "|**2023-09-28**|**Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving**|Sumit Kumar Jha et.al.|[2309.16436v1](http://arxiv.org/abs/2309.16436v1)|null|\n", "2309.16240": "|**2023-09-28**|**Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints**|Chaoqi Wang et.al.|[2309.16240v1](http://arxiv.org/abs/2309.16240v1)|null|\n", "2309.14504": "|**2023-09-25**|**People's Perceptions Toward Bias and Related Concepts in Large Language Models: A Systematic Review**|Lu Wang et.al.|[2309.14504v1](http://arxiv.org/abs/2309.14504v1)|null|\n", "2309.14122": "|**2023-09-25**|**SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution**|Zhongjie Ba et.al.|[2309.14122v1](http://arxiv.org/abs/2309.14122v1)|**[link](https://github.com/zjm1900/surrogateprompt)**|\n", "2309.13788": "|**2023-09-25**|**Can LLM-Generated Misinformation Be Detected?**|Canyu Chen et.al.|[2309.13788v1](http://arxiv.org/abs/2309.13788v1)|null|\n", "2309.12941": "|**2023-09-22**|**Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models**|Zezhong Chen et.al.|[2309.12941v1](http://arxiv.org/abs/2309.12941v1)|null|\n", "2309.11998": "|**2023-09-30**|**LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset**|Lianmin Zheng et.al.|[2309.11998v3](http://arxiv.org/abs/2309.11998v3)|**[link](https://github.com/lm-sys/fastchat)**|\n", "2309.11830": "|**2023-09-21**|**A Chinese Prompt Attack Dataset for LLMs with Evil Content**|Chengyuan Liu et.al.|[2309.11830v1](http://arxiv.org/abs/2309.11830v1)|null|\n", "2309.11751": "|**2023-10-14**|**How Robust is Google's Bard to Adversarial Image Attacks?**|Yinpeng Dong et.al.|[2309.11751v2](http://arxiv.org/abs/2309.11751v2)|**[link](https://github.com/thu-ml/attack-bard)**|\n", "2309.10346": "|**2023-09-19**|**Explaining Agent Behavior with Large Language Models**|Xijia Zhang et.al.|[2309.10346v1](http://arxiv.org/abs/2309.10346v1)|null|\n", "2309.10254": "|**2023-09-19**|**LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins**|Umar Iqbal et.al.|[2309.10254v1](http://arxiv.org/abs/2309.10254v1)|**[link](https://github.com/llm-platform-security/chatgpt-plugin-eval)**|\n", "2309.10253": "|**2023-10-04**|**GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts**|Jiahao Yu et.al.|[2309.10253v2](http://arxiv.org/abs/2309.10253v2)|**[link](https://github.com/sherdencooper/gptfuzz)**|\n", "2309.09919": "|**2023-10-14**|**Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents**|Ziyi Yang et.al.|[2309.09919v2](http://arxiv.org/abs/2309.09919v2)|null|\n", "2309.09843": "|**2023-09-18**|**Instruction-Following Speech Recognition**|Cheng-I Jeff Lai et.al.|[2309.09843v1](http://arxiv.org/abs/2309.09843v1)|null|\n", "2309.09437": "|**2023-09-28**|**Using LLMs to Facilitate Formal Verification of RTL**|Marcelo Orenes-Vera et.al.|[2309.09437v2](http://arxiv.org/abs/2309.09437v2)|null|\n", "2309.07875": "|**2023-09-25**|**Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions**|Federico Bianchi et.al.|[2309.07875v2](http://arxiv.org/abs/2309.07875v2)|**[link](https://github.com/vinid/instruction-llms-safety-eval)**|\n", "2309.07124": "|**2023-10-09**|**RAIN: Your Language Models Can Align Themselves without Finetuning**|Yuhui Li et.al.|[2309.07124v2](http://arxiv.org/abs/2309.07124v2)|**[link](https://github.com/SafeAILab/RAIN)**|\n", "2309.07045": "|**2023-09-13**|**SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions**|Zhexin Zhang et.al.|[2309.07045v1](http://arxiv.org/abs/2309.07045v1)|**[link](https://github.com/thu-coai/safetybench)**|\n", "2309.05274": "|**2023-09-11**|**FuzzLLM: A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models**|Dongyu Yao et.al.|[2309.05274v1](http://arxiv.org/abs/2309.05274v1)|null|\n", "2309.02705": "|**2023-09-06**|**Certifying LLM Safety against Adversarial Prompting**|Aounon Kumar et.al.|[2309.02705v1](http://arxiv.org/abs/2309.02705v1)|null|\n", "2309.01809": "|**2023-09-04**|**Are Emergent Abilities in Large Language Models just In-Context Learning?**|Sheng Lu et.al.|[2309.01809v1](http://arxiv.org/abs/2309.01809v1)|**[link](https://github.com/ukplab/on-emergence)**|\n", "2309.00900": "|**2023-09-11**|**Large Process Models: Business Process Management in the Age of Generative AI**|Timotheus Kampik et.al.|[2309.00900v2](http://arxiv.org/abs/2309.00900v2)|null|\n", "2309.00667": "|**2023-09-01**|**Taken out of context: On measuring situational awareness in LLMs**|Lukas Berglund et.al.|[2309.00667v1](http://arxiv.org/abs/2309.00667v1)|**[link](https://github.com/asacooperstickland/situational-awareness-evals)**|\n", "2308.16149": "|**2023-09-29**|**Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models**|Neha Sengupta et.al.|[2308.16149v2](http://arxiv.org/abs/2308.16149v2)|null|\n", "2308.15231": "|**2023-08-29**|**Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering**|Angus Addlesee et.al.|[2308.15231v1](http://arxiv.org/abs/2308.15231v1)|**[link](https://github.com/addleseehq/mpgt-eval)**|\n", "2308.14683": "|**2023-08-28**|**Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts**|Thanh Thi Nguyen et.al.|[2308.14683v1](http://arxiv.org/abs/2308.14683v1)|null|\n", "2308.13449": "|**2023-08-25**|**The Poison of Alignment**|Aibek Bekbayev et.al.|[2308.13449v1](http://arxiv.org/abs/2308.13449v1)|null|\n", "2308.13387": "|**2023-09-04**|**Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs**|Yuxia Wang et.al.|[2308.13387v2](http://arxiv.org/abs/2308.13387v2)|**[link](https://github.com/libr-ai/do-not-answer)**|\n", "2308.13563": "|**2023-08-25**|**Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4**|Maroa Mumtarin et.al.|[2308.13563v1](http://arxiv.org/abs/2308.13563v1)|null|\n", "2308.09662": "|**2023-08-30**|**Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment**|Rishabh Bhardwaj et.al.|[2308.09662v3](http://arxiv.org/abs/2308.09662v3)|**[link](https://github.com/declare-lab/red-instruct)**|\n", "2308.07902": "|**2023-08-15**|**Through the Lens of Core Competency: Survey on Evaluation of Large Language Models**|Ziyu Zhuang et.al.|[2308.07902v1](http://arxiv.org/abs/2308.07902v1)|null|\n", "2308.07847": "|**2023-08-15**|**Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models**|Yugeng Liu et.al.|[2308.07847v1](http://arxiv.org/abs/2308.07847v1)|null|\n", "2308.07308": "|**2023-10-24**|**LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked**|Mansi Phute et.al.|[2308.07308v3](http://arxiv.org/abs/2308.07308v3)|null|\n", "2308.06610": "|**2023-08-12**|**Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation**|Ambrose Robinson et.al.|[2308.06610v1](http://arxiv.org/abs/2308.06610v1)|**[link](https://github.com/ambroser53/bio-sieve)**|\n", "2308.06463": "|**2023-08-12**|**GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher**|Youliang Yuan et.al.|[2308.06463v1](http://arxiv.org/abs/2308.06463v1)|**[link](https://github.com/robustnlp/cipherchat)**|\n", "2308.05374": "|**2023-08-10**|**Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment**|Yang Liu et.al.|[2308.05374v1](http://arxiv.org/abs/2308.05374v1)|**[link](https://github.com/kevinyaobytedance/llm_eval)**|\n", "2308.05177": "|**2023-08-09**|**Fixing Rust Compilation Errors using LLMs**|Pantazis Deligiannis et.al.|[2308.05177v1](http://arxiv.org/abs/2308.05177v1)|null|\n", "2308.04030": "|**2023-08-08**|**Gentopia: A Collaborative Platform for Tool-Augmented LLMs**|Binfeng Xu et.al.|[2308.04030v1](http://arxiv.org/abs/2308.04030v1)|**[link](https://github.com/gentopia-ai/gentopia)**|\n", "2308.03638": "|**2023-08-07**|**KITLM: Domain-Specific Knowledge InTegration into Language Models for Question Answering**|Ankush Agarwal et.al.|[2308.03638v1](http://arxiv.org/abs/2308.03638v1)|**[link](https://github.com/sakharamg/kitlm)**|\n", "2308.03549": "|**2023-08-14**|**Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue**|Songhua Yang et.al.|[2308.03549v2](http://arxiv.org/abs/2308.03549v2)|**[link](https://github.com/suprityoung/zhongjing)**|\n", "2308.02955": "|**2023-08-19**|**An Empirical Study of AI-based Smart Contract Creation**|Rabimba Karanjai et.al.|[2308.02955v2](http://arxiv.org/abs/2308.02955v2)|null|\n", "2308.02068": "|**2023-08-03**|**Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale**|Hans W. A. Hanley et.al.|[2308.02068v1](http://arxiv.org/abs/2308.02068v1)|null|\n", "2308.01666": "|**2023-08-03**|**Evaluating ChatGPT text-mining of clinical records for obesity monitoring**|Ivo S. Fins et.al.|[2308.01666v1](http://arxiv.org/abs/2308.01666v1)|null|\n", "2308.01263": "|**2023-10-17**|**XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models**|Paul R\u00f6ttger et.al.|[2308.01263v2](http://arxiv.org/abs/2308.01263v2)|**[link](https://github.com/paul-rottger/exaggerated-safety)**|\n", "2308.01222": "|**2023-08-02**|**Calibration in Deep Learning: A Survey of the State-of-the-Art**|Cheng Wang et.al.|[2308.01222v1](http://arxiv.org/abs/2308.01222v1)|null|\n", "2307.15311": "|**2023-07-28**|**TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety**|Ou Zheng et.al.|[2307.15311v1](http://arxiv.org/abs/2307.15311v1)|**[link](https://github.com/ozheng1993/trafficsafetygpt)**|\n", "2307.11137": "|**2023-09-13**|**Of Models and Tin Men: A Behavioural Economics Study of Principal-Agent Problems in AI Alignment using Large-Language Models**|Steve Phelps et.al.|[2307.11137v3](http://arxiv.org/abs/2307.11137v3)|**[link](https://github.com/phelps-sg/llm-cooperation)**|\n", "2307.10690": "|**2023-07-20**|**Bridging Intelligence and Instinct: A New Control Paradigm for Autonomous Robots**|Shimian Zhang et.al.|[2307.10690v1](http://arxiv.org/abs/2307.10690v1)|null|\n", "2307.09705": "|**2023-07-19**|**CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility**|Guohai Xu et.al.|[2307.09705v1](http://arxiv.org/abs/2307.09705v1)|**[link](https://github.com/x-plug/cvalues)**|\n", "2307.09288": "|**2023-07-19**|**Llama 2: Open Foundation and Fine-Tuned Chat Models**|Hugo Touvron et.al.|[2307.09288v2](http://arxiv.org/abs/2307.09288v2)|**[link](https://github.com/facebookresearch/llama)**|\n", "2307.08487": "|**2023-08-28**|**Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models**|Huachuan Qiu et.al.|[2307.08487v3](http://arxiv.org/abs/2307.08487v3)|**[link](https://github.com/qiuhuachuan/latent-jailbreak)**|\n", "2307.11768": "|**2023-07-25**|**Question Decomposition Improves the Faithfulness of Model-Generated Reasoning**|Ansh Radhakrishnan et.al.|[2307.11768v2](http://arxiv.org/abs/2307.11768v2)|**[link](https://github.com/anthropics/decompositionfaithfulnesspaper)**|\n", "2307.04657": "|**2023-11-07**|**BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset**|Jiaming Ji et.al.|[2307.04657v3](http://arxiv.org/abs/2307.04657v3)|null|\n", "2307.03699": "|**2023-07-07**|**Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media**|Chuanbo Hu et.al.|[2307.03699v1](http://arxiv.org/abs/2307.03699v1)|null|\n", "2307.02483": "|**2023-07-05**|**Jailbroken: How Does LLM Safety Training Fail?**|Alexander Wei et.al.|[2307.02483v1](http://arxiv.org/abs/2307.02483v1)|null|\n", "2307.02192": "|**2023-09-02**|**The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification**|Norbert Tihanyi et.al.|[2307.02192v2](http://arxiv.org/abs/2307.02192v2)|null|\n", "2307.00593": "|**2023-07-02**|**LLM4CBI: Taming LLMs to Generate Effective Test Programs for Compiler Bug Isolation**|Haoxin Tu et.al.|[2307.00593v1](http://arxiv.org/abs/2307.00593v1)|**[link](https://github.com/haoxintu/LLM4CBI)**|\n", "2306.17439": "|**2023-10-13**|**Provable Robust Watermarking for AI-Generated Text**|Xuandong Zhao et.al.|[2306.17439v2](http://arxiv.org/abs/2306.17439v2)|**[link](https://github.com/xuandongzhao/unigram-watermark)**|\n", "2306.15887": "|**2023-06-28**|**Beyond the Hype: Assessing the Performance, Trustworthiness, and Clinical Suitability of GPT3.5**|Salmonn Talebi et.al.|[2306.15887v1](http://arxiv.org/abs/2306.15887v1)|null|\n", "2306.13213": "|**2023-08-16**|**Visual Adversarial Examples Jailbreak Aligned Large Language Models**|Xiangyu Qi et.al.|[2306.13213v2](http://arxiv.org/abs/2306.13213v2)|**[link](https://github.com/unispac/visual-adversarial-examples-jailbreak-large-language-models)**|\n", "2306.04362": "|**2023-06-07**|**Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks**|Haiyang Xu et.al.|[2306.04362v1](http://arxiv.org/abs/2306.04362v1)|**[link](https://github.com/x-plug/youku-mplug)**|\n", "2305.19713": "|**2023-10-19**|**Red Teaming Language Model Detectors with Language Models**|Zhouxing Shi et.al.|[2305.19713v2](http://arxiv.org/abs/2305.19713v2)|**[link](https://github.com/shizhouxing/Attack-LM-Detectors)**|\n", "2306.00020": "|**2023-05-30**|**GPT4GEO: How a Language Model Sees the World's Geography**|Jonathan Roberts et.al.|[2306.00020v1](http://arxiv.org/abs/2306.00020v1)|null|\n", "2305.18404": "|**2023-07-08**|**Conformal Prediction with Large Language Models for Multi-Choice Question Answering**|Bhawesh Kumar et.al.|[2305.18404v3](http://arxiv.org/abs/2305.18404v3)|**[link](https://github.com/bhaweshiitk/conformalllm)**|\n", "2305.16934": "|**2023-10-29**|**On Evaluating Adversarial Robustness of Large Vision-Language Models**|Yunqing Zhao et.al.|[2305.16934v2](http://arxiv.org/abs/2305.16934v2)|**[link](https://github.com/yunqing-me/attackvlm)**|\n", "2305.12945": "|**2023-10-26**|**ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination**|Dongfang Li et.al.|[2305.12945v2](http://arxiv.org/abs/2305.12945v2)|**[link](https://github.com/hitsz-tmg/explaincpe)**|\n", "2305.12031": "|**2023-08-17**|**Clinical Camel: An Open Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding**|Augustin Toma et.al.|[2305.12031v2](http://arxiv.org/abs/2305.12031v2)|**[link](https://github.com/bowang-lab/clinical-camel)**|\n", "2305.11391": "|**2023-08-27**|**A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation**|Xiaowei Huang et.al.|[2305.11391v2](http://arxiv.org/abs/2305.11391v2)|null|\n", "2305.08809": "|**2023-05-15**|**Interpretability at Scale: Identifying Causal Mechanisms in Alpaca**|Zhengxuan Wu et.al.|[2305.08809v1](http://arxiv.org/abs/2305.08809v1)|**[link](https://github.com/frankaging/align-transformers)**|\n", "2305.08005": "|**2023-05-13**|**Beyond the Safeguards: Exploring the Security Risks of ChatGPT**|Erik Derner et.al.|[2305.08005v1](http://arxiv.org/abs/2305.08005v1)|null|\n", "2305.06018": "|**2023-10-08**|**TARGET: Automated Scenario Generation from Traffic Rules for Testing Autonomous Vehicles**|Yao Deng et.al.|[2305.06018v2](http://arxiv.org/abs/2305.06018v2)|null|\n", "2305.04388": "|**2023-05-07**|**Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting**|Miles Turpin et.al.|[2305.04388v1](http://arxiv.org/abs/2305.04388v1)|**[link](https://github.com/milesaturpin/cot-unfaithfulness)**|\n", "2305.02469": "|**2023-05-04**|**The System Model and the User Model: Exploring AI Dashboard Design**|Fernanda Vi\u00e9gas et.al.|[2305.02469v1](http://arxiv.org/abs/2305.02469v1)|null|\n", "2304.13714": "|**2023-05-01**|**Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery**|Debadutta Dash et.al.|[2304.13714v3](http://arxiv.org/abs/2304.13714v3)|null|\n", "2304.11163": "|**2023-04-21**|**ChatGPT, Large Language Technologies, and the Bumpy Road of Benefiting Humanity**|Atoosa Kasirzadeh et.al.|[2304.11163v1](http://arxiv.org/abs/2304.11163v1)|null|\n", "2304.10436": "|**2023-04-20**|**Safety Assessment of Chinese Large Language Models**|Hao Sun et.al.|[2304.10436v1](http://arxiv.org/abs/2304.10436v1)|**[link](https://github.com/thu-coai/safety-prompts)**|\n", "2304.11082": "|**2023-10-11**|**Fundamental Limitations of Alignment in Large Language Models**|Yotam Wolf et.al.|[2304.11082v4](http://arxiv.org/abs/2304.11082v4)|null|\n", "2304.09655": "|**2023-04-19**|**How Secure is Code Generated by ChatGPT?**|Rapha\u00ebl Khoury et.al.|[2304.09655v1](http://arxiv.org/abs/2304.09655v1)|**[link](https://github.com/raphaelkhoury/programsgeneratedbychatgpt)**|\n", "2304.09865": "|**2023-04-18**|**Safer Conversational AI as a Source of User Delight**|Xiaoding Lu et.al.|[2304.09865v1](http://arxiv.org/abs/2304.09865v1)|null|\n", "2304.05335": "|**2023-04-11**|**Toxicity in ChatGPT: Analyzing Persona-assigned Language Models**|Ameet Deshpande et.al.|[2304.05335v1](http://arxiv.org/abs/2304.05335v1)|null|\n", "2304.05332": "|**2023-04-11**|**Emergent autonomous scientific research capabilities of large language models**|Daniil A. Boiko et.al.|[2304.05332v1](http://arxiv.org/abs/2304.05332v1)|null|\n", "2304.05197": "|**2023-11-01**|**Multi-step Jailbreaking Privacy Attacks on ChatGPT**|Haoran Li et.al.|[2304.05197v3](http://arxiv.org/abs/2304.05197v3)|**[link](https://github.com/hkust-knowcomp/llm-multistep-jailbreak)**|\n", "2304.01246": "|**2023-11-05**|**Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT**|Yi Qi et.al.|[2304.01246v2](http://arxiv.org/abs/2304.01246v2)|**[link](https://github.com/yiqi0318/chatgpt-stpa)**|\n", "2303.17071": "|**2023-03-30**|**DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents**|Varun Nair et.al.|[2303.17071v1](http://arxiv.org/abs/2303.17071v1)|**[link](https://github.com/curai/curai-research)**|\n", "2303.16104": "|**2023-03-28**|**Hallucinations in Large Multilingual Translation Models**|Nuno M. Guerreiro et.al.|[2303.16104v1](http://arxiv.org/abs/2303.16104v1)|**[link](https://github.com/deep-spin/lmt_hallucinations)**|\n", "2303.15473": "|**2023-03-25**|**Can Large Language Models assist in Hazard Analysis?**|Simon Diemert et.al.|[2303.15473v1](http://arxiv.org/abs/2303.15473v1)|null|\n", "2303.13375": "|**2023-04-12**|**Capabilities of GPT-4 on Medical Challenge Problems**|Harsha Nori et.al.|[2303.13375v2](http://arxiv.org/abs/2303.13375v2)|null|\n", "2303.10831": "|**2023-03-27**|**Bridging Deliberative Democracy and Deployment of Societal-Scale Technology**|Ned Cooper et.al.|[2303.10831v2](http://arxiv.org/abs/2303.10831v2)|null|\n", "2303.05453": "|**2023-03-09**|**Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback**|Hannah Rose Kirk et.al.|[2303.05453v1](http://arxiv.org/abs/2303.05453v1)|null|\n", "2303.05382": "|**2023-09-05**|**ChatGPT is on the Horizon: Could a Large Language Model be Suitable for Intelligent Traffic Safety Research and Applications?**|Ou Zheng et.al.|[2303.05382v3](http://arxiv.org/abs/2303.05382v3)|null|\n", "2303.00855": "|**2023-03-01**|**Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control**|Wenlong Huang et.al.|[2303.00855v1](http://arxiv.org/abs/2303.00855v1)|null|\n", "2303.01229": "|**2023-05-31**|**Almanac: Retrieval-Augmented Language Models for Clinical Medicine**|Cyril Zakka et.al.|[2303.01229v2](http://arxiv.org/abs/2303.01229v2)|null|\n", "2302.09051": "|**2023-04-07**|**Complex QA and language models hybrid architectures, Survey**|Xavier Daull et.al.|[2302.09051v4](http://arxiv.org/abs/2302.09051v4)|null|\n", "2302.08091": "|**2023-02-16**|**Do We Still Need Clinical Language Models?**|Eric Lehman et.al.|[2302.08091v1](http://arxiv.org/abs/2302.08091v1)|null|\n", "2302.06598": "|**2023-02-13**|**Gradient-Based Automated Iterative Recovery for Parameter-Efficient Tuning**|Maximilian Mozes et.al.|[2302.06598v1](http://arxiv.org/abs/2302.06598v1)|null|\n", "2302.06541": "|**2023-10-21**|**Towards Agile Text Classifiers for Everyone**|Maximilian Mozes et.al.|[2302.06541v2](http://arxiv.org/abs/2302.06541v2)|null|\n", "2302.00805": "|**2023-02-06**|**Conditioning Predictive Models: Risks and Strategies**|Evan Hubinger et.al.|[2302.00805v2](http://arxiv.org/abs/2302.00805v2)|null|\n", "2301.04013": "|**2023-01-10**|**There is No Big Brother or Small Brother: Knowledge Infusion in Language Models for Link Prediction and Question Answering**|Ankush Agarwal et.al.|[2301.04013v1](http://arxiv.org/abs/2301.04013v1)|**[link](https://github.com/ankush9812/knowledge-infusion-in-lm-for-qa)**|\n", "2212.14834": "|**2023-03-07**|**Large Language Models are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models**|Yinlin Deng et.al.|[2212.14834v4](http://arxiv.org/abs/2212.14834v4)|null|\n", "2212.10529": "|**2023-05-08**|**Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective**|Xingxuan Li et.al.|[2212.10529v2](http://arxiv.org/abs/2212.10529v2)|null|\n", "2212.06295": "|**2022-12-13**|**Despite \"super-human\" performance, current LLMs are unsuited for decisions about ethics and safety**|Joshua Albrecht et.al.|[2212.06295v1](http://arxiv.org/abs/2212.06295v1)|null|\n", "2211.09527": "|**2022-11-17**|**Ignore Previous Prompt: Attack Techniques For Language Models**|F\u00e1bio Perez et.al.|[2211.09527v1](http://arxiv.org/abs/2211.09527v1)|**[link](https://github.com/agencyenterprise/promptinject)**|\n", "2211.05853": "|**2023-04-11**|**Measuring Reliability of Large Language Models through Semantic Consistency**|Harsh Raj et.al.|[2211.05853v2](http://arxiv.org/abs/2211.05853v2)|**[link](https://github.com/harshraj172/measuring-reliability-of-llms)**|\n", "2210.10045": "|**2022-10-18**|**SafeText: A Benchmark for Exploring Physical Safety in Language Models**|Sharon Levy et.al.|[2210.10045v1](http://arxiv.org/abs/2210.10045v1)|null|\n", "2210.09467": "|**2022-10-17**|**Adversarial and Safely Scaled Question Generation**|Sreehari Sankar et.al.|[2210.09467v1](http://arxiv.org/abs/2210.09467v1)|null|\n", "2210.09150": "|**2023-02-15**|**Prompting GPT-3 To Be Reliable**|Chenglei Si et.al.|[2210.09150v2](http://arxiv.org/abs/2210.09150v2)|**[link](https://github.com/noviscl/gpt3-reliability)**|\n", "2210.01478": "|**2022-10-27**|**When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment**|Zhijing Jin et.al.|[2210.01478v3](http://arxiv.org/abs/2210.01478v3)|**[link](https://github.com/feradauto/moralcot)**|\n", "2209.15259": "|**2023-05-09**|**On the Impossible Safety of Large AI Models**|El-Mahdi El-Mhamdi et.al.|[2209.15259v2](http://arxiv.org/abs/2209.15259v2)|null|\n", "2207.14157": "|**2022-07-25**|**A Hazard Analysis Framework for Code Synthesis Large Language Models**|Heidy Khlaaf et.al.|[2207.14157v1](http://arxiv.org/abs/2207.14157v1)|null|\n", "2205.09712": "|**2022-05-19**|**Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning**|Antonia Creswell et.al.|[2205.09712v1](http://arxiv.org/abs/2205.09712v1)|null|\n", "2203.11147": "|**2022-03-21**|**Teaching language models to support answers with verified quotes**|Jacob Menick et.al.|[2203.11147v1](http://arxiv.org/abs/2203.11147v1)|null|\n", "2109.07445": "|**2021-09-15**|**Challenges in Detoxifying Language Models**|Johannes Welbl et.al.|[2109.07445v1](http://arxiv.org/abs/2109.07445v1)|null|\n", "2108.11063": "|**2021-08-25**|**Viola: A Topic Agnostic Generate-and-Rank Dialogue System**|Hyundong Cho et.al.|[2108.11063v1](http://arxiv.org/abs/2108.11063v1)|null|\n", "2107.03374": "|**2021-07-14**|**Evaluating Large Language Models Trained on Code**|Mark Chen et.al.|[2107.03374v2](http://arxiv.org/abs/2107.03374v2)|**[link](https://github.com/openai/human-eval)**|\n"}, "LLM - Privacy": {"2311.14030": "|**2023-11-23**|**PrivateLoRA For Efficient Privacy Preserving LLM**|Yiming Wang et.al.|[2311.14030v1](http://arxiv.org/abs/2311.14030v1)|null|\n", "2311.13857": "|**2023-11-23**|**Challenges of Large Language Models for Mental Health Counseling**|Neo Christopher Chung et.al.|[2311.13857v1](http://arxiv.org/abs/2311.13857v1)|null|\n", "2311.13158": "|**2023-11-22**|**From Principles to Practice: An Accountability Metrics Catalogue for Managing AI Risks**|Boming Xia et.al.|[2311.13158v1](http://arxiv.org/abs/2311.13158v1)|null|\n", "2311.12955": "|**2023-11-21**|**Don't forget private retrieval: distributed private similarity search for large language models**|Guy Zyskind et.al.|[2311.12955v1](http://arxiv.org/abs/2311.12955v1)|null|\n", "2311.12287": "|**2023-11-21**|**Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications**|Samira Ghodratnama et.al.|[2311.12287v1](http://arxiv.org/abs/2311.12287v1)|null|\n", "2311.11161": "|**2023-11-18**|**Experts-in-the-Loop: Establishing an Effective Workflow in Crafting Privacy Q&A**|Zahra Kolagar et.al.|[2311.11161v1](http://arxiv.org/abs/2311.11161v1)|null|\n", "2311.10785": "|**2023-11-16**|**Text Sanitization Beyond Specific Domains: Zero-Shot Redaction & Substitution with Large Language Models**|Federico Albanese et.al.|[2311.10785v1](http://arxiv.org/abs/2311.10785v1)|null|\n", "2311.09447": "|**2023-11-15**|**How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities**|Lingbo Mo et.al.|[2311.09447v1](http://arxiv.org/abs/2311.09447v1)|**[link](https://github.com/osu-nlp-group/eval-llm-trust)**|\n", "2311.10766": "|**2023-11-15**|**Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values**|Jing Yao et.al.|[2311.10766v1](http://arxiv.org/abs/2311.10766v1)|**[link](https://github.com/valuecompass/valuecompass.github.io)**|\n", "2311.06805": "|**2023-11-12**|**Tunable Soft Prompts are Messengers in Federated Learning**|Chenhe Dong et.al.|[2311.06805v1](http://arxiv.org/abs/2311.06805v1)|**[link](https://github.com/alibaba/federatedscope)**|\n", "2311.09243": "|**2023-11-12**|**Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling**|Yujin Cho et.al.|[2311.09243v1](http://arxiv.org/abs/2311.09243v1)|null|\n", "2311.07601": "|**2023-11-11**|**Online Advertisements with LLMs: Opportunities and Challenges**|Soheil Feizi et.al.|[2311.07601v1](http://arxiv.org/abs/2311.07601v1)|null|\n", "2311.06062": "|**2023-11-10**|**Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration**|Wenjie Fu et.al.|[2311.06062v1](http://arxiv.org/abs/2311.06062v1)|null|\n", "2311.05863": "|**2023-11-10**|**Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service**|Yuanmin Tang et.al.|[2311.05863v1](http://arxiv.org/abs/2311.05863v1)|**[link](https://github.com/Pter61/vlpmarker)**|\n", "2311.06318": "|**2023-11-10**|**Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion**|Jinheon Baek et.al.|[2311.06318v1](http://arxiv.org/abs/2311.06318v1)|null|\n", "2311.07585": "|**2023-11-24**|**Input Reconstruction Attack against Vertical Federated Large Language Models**|Fei Zheng et.al.|[2311.07585v2](http://arxiv.org/abs/2311.07585v2)|null|\n", "2311.02775": "|**2023-11-13**|**ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**|Yann Hicke et.al.|[2311.02775v2](http://arxiv.org/abs/2311.02775v2)|null|\n", "2311.02192": "|**2023-11-03**|**Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models**|Jake Chanenson et.al.|[2311.02192v1](http://arxiv.org/abs/2311.02192v1)|null|\n", "2311.00984": "|**2023-11-02**|**Inclusiveness Matters: A Large-Scale Analysis of User Feedback**|Nowshin Nawar Arony et.al.|[2311.00984v1](http://arxiv.org/abs/2311.00984v1)|null|\n", "2311.00287": "|**2023-11-01**|**Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models**|Ran Xu et.al.|[2311.00287v1](http://arxiv.org/abs/2311.00287v1)|**[link](https://github.com/ritaranx/clingen)**|\n", "2310.20150": "|**2023-10-31**|**Unlearn What You Want to Forget: Efficient Unlearning for LLMs**|Jiaao Chen et.al.|[2310.20150v1](http://arxiv.org/abs/2310.20150v1)|null|\n", "2310.20138": "|**2023-10-31**|**DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models**|Xinwei Wu et.al.|[2310.20138v1](http://arxiv.org/abs/2310.20138v1)|null|\n", "2310.20111": "|**2023-10-31**|**Making Large Language Models Better Data Creators**|Dong-Ho Lee et.al.|[2310.20111v1](http://arxiv.org/abs/2310.20111v1)|**[link](https://github.com/microsoft/llm-data-creation)**|\n", "2310.19233": "|**2023-11-08**|**Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective**|Md Tahmid Rahman Laskar et.al.|[2310.19233v3](http://arxiv.org/abs/2310.19233v3)|null|\n", "2310.17884": "|**2023-10-27**|**Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory**|Niloofar Mireshghallah et.al.|[2310.17884v1](http://arxiv.org/abs/2310.17884v1)|null|\n", "2310.17752": "|**2023-10-26**|**PockEngine: Sparse and Efficient Fine-tuning in a Pocket**|Ligeng Zhu et.al.|[2310.17752v1](http://arxiv.org/abs/2310.17752v1)|null|\n", "2310.16960": "|**2023-10-25**|**Privately Aligning Language Models with Reinforcement Learning**|Fan Wu et.al.|[2310.16960v1](http://arxiv.org/abs/2310.16960v1)|null|\n", "2310.16789": "|**2023-11-03**|**Detecting Pretraining Data from Large Language Models**|Weijia Shi et.al.|[2310.16789v2](http://arxiv.org/abs/2310.16789v2)|null|\n", "2310.16340": "|**2023-10-25**|**RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models**|Zefan Wang et.al.|[2310.16340v1](http://arxiv.org/abs/2310.16340v1)|null|\n", "2310.16111": "|**2023-10-24**|**Locally Differentially Private Document Generation Using Zero Shot Prompting**|Saiteja Utpala et.al.|[2310.16111v1](http://arxiv.org/abs/2310.16111v1)|null|\n", "2310.18362": "|**2023-10-24**|**SoK: Memorization in General-Purpose Large Language Models**|Valentin Hartmann et.al.|[2310.18362v1](http://arxiv.org/abs/2310.18362v1)|null|\n", "2310.15477": "|**2023-10-24**|**CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model**|Kaiyan Zhang et.al.|[2310.15477v1](http://arxiv.org/abs/2310.15477v1)|null|\n", "2310.15469": "|**2023-10-24**|**The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks**|Xiaoyi Chen et.al.|[2310.15469v1](http://arxiv.org/abs/2310.15469v1)|null|\n", "2310.18355": "|**2023-10-23**|**Health Disparities through Generative AI Models: A Comparison Study Using A Domain Specific large language model**|Yohn Jairo Parra Bautista et.al.|[2310.18355v1](http://arxiv.org/abs/2310.18355v1)|null|\n", "2310.15007": "|**2023-10-23**|**Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models**|Matthieu Meeus et.al.|[2310.15007v1](http://arxiv.org/abs/2310.15007v1)|null|\n", "2310.14970": "|**2023-10-23**|**Towards LLM-driven Dialogue State Tracking**|Yujie Feng et.al.|[2310.14970v1](http://arxiv.org/abs/2310.14970v1)|**[link](https://github.com/woodscene/ldst)**|\n", "2310.14369": "|**2023-10-22**|**MoPe: Model Perturbation-based Privacy Attacks on Language Models**|Marvin Li et.al.|[2310.14369v1](http://arxiv.org/abs/2310.14369v1)|null|\n", "2310.13291": "|**2023-10-20**|**Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks**|Ruixiang Tang et.al.|[2310.13291v1](http://arxiv.org/abs/2310.13291v1)|null|\n", "2310.12746": "|**2023-10-19**|**TabuLa: Harnessing Language Models for Tabular Data Synthesis**|Zilong Zhao et.al.|[2310.12746v1](http://arxiv.org/abs/2310.12746v1)|**[link](https://github.com/zhao-zilong/tabula)**|\n", "2310.12523": "|**2023-10-19**|**Privacy Preserving Large Language Models: ChatGPT Case Study Based Vision and Framework**|Imdad Ullah et.al.|[2310.12523v1](http://arxiv.org/abs/2310.12523v1)|null|\n", "2310.12214": "|**2023-10-24**|**PrivInfer: Privacy-Preserving Inference for Black-box Large Language Model**|Meng Tong et.al.|[2310.12214v3](http://arxiv.org/abs/2310.12214v3)|null|\n", "2310.11397": "|**2023-10-17**|**Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning**|Rui Wen et.al.|[2310.11397v1](http://arxiv.org/abs/2310.11397v1)|null|\n", "2310.10383": "|**2023-10-16**|**Privacy in Large Language Models: Attacks, Defenses and Future Directions**|Haoran Li et.al.|[2310.10383v1](http://arxiv.org/abs/2310.10383v1)|null|\n", "2310.10049": "|**2023-10-16**|**FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models**|Tao Fan et.al.|[2310.10049v1](http://arxiv.org/abs/2310.10049v1)|**[link](https://github.com/FederatedAI/FATE-LLM)**|\n", "2310.09639": "|**2023-10-14**|**DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization**|Liang Zhang et.al.|[2310.09639v1](http://arxiv.org/abs/2310.09639v1)|null|\n", "2310.09266": "|**2023-10-13**|**User Inference Attacks on Large Language Models**|Nikhil Kandpal et.al.|[2310.09266v1](http://arxiv.org/abs/2310.09266v1)|null|\n", "2310.09130": "|**2023-10-13**|**Split-and-Denoise: Protect large language model inference with local differential privacy**|Peihua Mai et.al.|[2310.09130v1](http://arxiv.org/abs/2310.09130v1)|null|\n", "2310.07298": "|**2023-10-11**|**Beyond Memorization: Violating Privacy Via Inference with Large Language Models**|Robin Staab et.al.|[2310.07298v1](http://arxiv.org/abs/2310.07298v1)|null|\n", "2310.07282": "|**2023-10-12**|**An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT**|Shyni Sharaf et.al.|[2310.07282v2](http://arxiv.org/abs/2310.07282v2)|null|\n", "2310.06278": "|**2023-10-10**|**BC4LLM: Trusted Artificial Intelligence When Blockchain Meets Large Language Models**|Haoxiang Luo et.al.|[2310.06278v1](http://arxiv.org/abs/2310.06278v1)|null|\n", "2310.03104": "|**2023-10-04**|**DP-SGD for non-decomposable objective functions**|William Kong et.al.|[2310.03104v1](http://arxiv.org/abs/2310.03104v1)|null|\n", "2310.02469": "|**2023-10-03**|**Large Language Models Can Be Good Privacy Protection Learners**|Yijia Xiao et.al.|[2310.02469v1](http://arxiv.org/abs/2310.02469v1)|null|\n", "2310.02431": "|**2023-10-03**|**Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions**|Yufan Chen et.al.|[2310.02431v1](http://arxiv.org/abs/2310.02431v1)|**[link](https://github.com/purseclab/llm_security_privacy_advice)**|\n", "2310.01329": "|**2023-10-02**|**BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models**|Qingqing Cao et.al.|[2310.01329v1](http://arxiv.org/abs/2310.01329v1)|null|\n", "2310.01467": "|**2023-10-02**|**FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models**|Jingwei Sun et.al.|[2310.01467v1](http://arxiv.org/abs/2310.01467v1)|null|\n", "2310.01166": "|**2023-10-02**|**Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models**|Zhou Yang et.al.|[2310.01166v1](http://arxiv.org/abs/2310.01166v1)|null|\n", "2310.01152": "|**2023-10-16**|**Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives**|Sihao Hu et.al.|[2310.01152v2](http://arxiv.org/abs/2310.01152v2)|**[link](https://github.com/git-disl/gptlens)**|\n", "2310.00272": "|**2023-09-30**|**Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thoughts Prompting**|Baphumelele Masikisiki et.al.|[2310.00272v1](http://arxiv.org/abs/2310.00272v1)|null|\n", "2310.01434": "|**2023-09-29**|**Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile**|Samuel Carreira et.al.|[2310.01434v1](http://arxiv.org/abs/2310.01434v1)|null|\n", "2309.17157": "|**2023-11-14**|**LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud**|Mengke Zhang et.al.|[2309.17157v3](http://arxiv.org/abs/2309.17157v3)|null|\n", "2309.16739": "|**2023-09-28**|**Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities**|Zheng Lin et.al.|[2309.16739v1](http://arxiv.org/abs/2309.16739v1)|null|\n", "2309.14726": "|**2023-09-26**|**PLMM: Personal Large Models on Mobile Devices**|Yuanhao Gong et.al.|[2309.14726v1](http://arxiv.org/abs/2309.14726v1)|null|\n", "2309.14510": "|**2023-09-25**|**An Empathy-Based Sandbox Approach to Bridge Attitudes, Goals, Knowledge, and Behaviors in the Privacy Paradox**|Chaoran Chen et.al.|[2309.14510v1](http://arxiv.org/abs/2309.14510v1)|null|\n", "2309.11852": "|**2023-09-21**|**Knowledge Sanitization of Large Language Models**|Yoichi Ishibashi et.al.|[2309.11852v1](http://arxiv.org/abs/2309.11852v1)|null|\n", "2309.11765": "|**2023-09-21**|**Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation**|Xinyu Tang et.al.|[2309.11765v1](http://arxiv.org/abs/2309.11765v1)|**[link](https://github.com/microsoft/dp-few-shot-generation)**|\n", "2309.11653": "|**2023-09-20**|**\"It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents**|Zhiping Zhang et.al.|[2309.11653v1](http://arxiv.org/abs/2309.11653v1)|null|\n", "2309.10929": "|**2023-09-19**|**Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training**|Ruiqi Xu et.al.|[2309.10929v1](http://arxiv.org/abs/2309.10929v1)|**[link](https://github.com/ruiqixu37/BTTS_ECAI2023)**|\n", "2309.10254": "|**2023-09-19**|**LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins**|Umar Iqbal et.al.|[2309.10254v1](http://arxiv.org/abs/2309.10254v1)|**[link](https://github.com/llm-platform-security/chatgpt-plugin-eval)**|\n", "2309.10238": "|**2023-09-19**|**PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models**|Chenhao Tang et.al.|[2309.10238v1](http://arxiv.org/abs/2309.10238v1)|null|\n", "2309.09843": "|**2023-09-18**|**Instruction-Following Speech Recognition**|Cheng-I Jeff Lai et.al.|[2309.09843v1](http://arxiv.org/abs/2309.09843v1)|null|\n", "2309.08173": "|**2023-09-15**|**FedJudge: Federated Legal Large Language Model**|Linan Yue et.al.|[2309.08173v1](http://arxiv.org/abs/2309.08173v1)|**[link](https://github.com/yuelinan/fedjudge)**|\n", "2309.07254": "|**2023-10-26**|**Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement**|Chenghao Li et.al.|[2309.07254v2](http://arxiv.org/abs/2309.07254v2)|**[link](https://github.com/howardli0816/dual-fusion-diffusion)**|\n", "2309.08628": "|**2023-09-23**|**Recovering from Privacy-Preserving Masking with Large Language Models**|Arpita Vats et.al.|[2309.08628v2](http://arxiv.org/abs/2309.08628v2)|null|\n", "2309.04255": "|**2023-09-08**|**LLMCad: Fast and Scalable On-device Large Language Model Inference**|Daliang Xu et.al.|[2309.04255v1](http://arxiv.org/abs/2309.04255v1)|null|\n", "2309.04076": "|**2023-10-08**|**Towards Smaller, Faster, and Greener Language Models of Code**|Jieke Shi et.al.|[2309.04076v2](http://arxiv.org/abs/2309.04076v2)|null|\n", "2309.03748": "|**2023-09-07**|**Enhancing Pipeline-Based Conversational Agents with Large Language Models**|Mina Foosherian et.al.|[2309.03748v1](http://arxiv.org/abs/2309.03748v1)|null|\n", "2309.03057": "|**2023-09-06**|**Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection**|Yu Chen et.al.|[2309.03057v1](http://arxiv.org/abs/2309.03057v1)|**[link](https://github.com/alohachen/hide-and-seek)**|\n", "2311.06251": "|**2023-09-06**|**AI for Investment: A Platform Disruption**|Mohammad Rasouli et.al.|[2311.06251v1](http://arxiv.org/abs/2311.06251v1)|null|\n", "2309.03242": "|**2023-09-06**|**Automated Bioinformatics Analysis via AutoBA**|Juexiao Zhou et.al.|[2309.03242v1](http://arxiv.org/abs/2309.03242v1)|**[link](https://github.com/joshuachou2018/autoba)**|\n", "2309.01172": "|**2023-09-03**|**FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs**|Zhenheng Tang et.al.|[2309.01172v1](http://arxiv.org/abs/2309.01172v1)|null|\n", "2309.00964": "|**2023-09-13**|**eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models**|Minsik Cho et.al.|[2309.00964v2](http://arxiv.org/abs/2309.00964v2)|null|\n", "2309.00363": "|**2023-09-01**|**FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning**|Weirui Kuang et.al.|[2309.00363v1](http://arxiv.org/abs/2309.00363v1)|**[link](https://github.com/alibaba/federatedscope)**|\n", "2309.00237": "|**2023-09-06**|**Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes**|Sunjun Kweon et.al.|[2309.00237v2](http://arxiv.org/abs/2309.00237v2)|**[link](https://github.com/starmpcc/asclepius)**|\n", "2308.15727": "|**2023-11-05**|**Quantifying and Analyzing Entity-level Memorization in Large Language Models**|Zhenhong Zhou et.al.|[2308.15727v2](http://arxiv.org/abs/2308.15727v2)|null|\n", "2308.15126": "|**2023-10-10**|**Evaluation and Analysis of Hallucination in Large Vision-Language Models**|Junyang Wang et.al.|[2308.15126v3](http://arxiv.org/abs/2308.15126v3)|**[link](https://github.com/junyangwang0410/haelm)**|\n", "2308.14352": "|**2023-08-28**|**EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models**|Rongjie Yi et.al.|[2308.14352v1](http://arxiv.org/abs/2308.14352v1)|null|\n", "2308.13894": "|**2023-08-26**|**Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices**|Mengwei Xu et.al.|[2308.13894v1](http://arxiv.org/abs/2308.13894v1)|null|\n", "2308.11807": "|**2023-08-22**|**Towards an On-device Agent for Text Rewriting**|Yun Zhu et.al.|[2308.11807v1](http://arxiv.org/abs/2308.11807v1)|null|\n", "2308.11103": "|**2023-08-22**|**Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models**|Alex Nyffenegger et.al.|[2308.11103v1](http://arxiv.org/abs/2308.11103v1)|**[link](https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models)**|\n", "2308.09932": "|**2023-08-19**|**What Do Code Models Memorize? An Empirical Study on Large Language Models of Code**|Zhou Yang et.al.|[2308.09932v1](http://arxiv.org/abs/2308.09932v1)|null|\n", "2308.09376": "|**2023-08-18**|**Leveraging Large Language Models for DRL-Based Anti-Jamming Strategies in Zero Touch Networks**|Abubakar S. Ali et.al.|[2308.09376v1](http://arxiv.org/abs/2308.09376v1)|null|\n", "2308.07847": "|**2023-08-15**|**Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models**|Yugeng Liu et.al.|[2308.07847v1](http://arxiv.org/abs/2308.07847v1)|null|\n", "2308.13534": "|**2023-08-13**|**Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph**|Ahtsham Zafar et.al.|[2308.13534v1](http://arxiv.org/abs/2308.13534v1)|null|\n", "2308.06261": "|**2023-08-11**|**Enhancing Network Management Using Code Generated by Large Language Models**|Sathiya Kumaran Mani et.al.|[2308.06261v1](http://arxiv.org/abs/2308.06261v1)|**[link](https://github.com/microsoft/nemoeval)**|\n", "2308.06294": "|**2023-11-09**|**Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT**|Jingye Yang et.al.|[2308.06294v2](http://arxiv.org/abs/2308.06294v2)|**[link](https://github.com/wglab/phenogpt)**|\n", "2308.05596": "|**2023-08-10**|**You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content**|Xinlei He et.al.|[2308.05596v1](http://arxiv.org/abs/2308.05596v1)|**[link](https://github.com/xinleihe/toxic-prompt)**|\n", "2308.04913": "|**2023-08-09**|**LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following**|Kaize Shi et.al.|[2308.04913v1](http://arxiv.org/abs/2308.04913v1)|null|\n", "2308.03983": "|**2023-08-08**|**SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool**|Youyang Ng et.al.|[2308.03983v1](http://arxiv.org/abs/2308.03983v1)|**[link](https://github.com/rcgai/simplyretrieve)**|\n", "2307.16680": "|**2023-08-23**|**On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey**|Mingyuan Fan et.al.|[2307.16680v4](http://arxiv.org/abs/2307.16680v4)|null|\n", "2307.15838": "|**2023-07-28**|**Holistic Survey of Privacy and Fairness in Machine Learning**|Sina Shaham et.al.|[2307.15838v1](http://arxiv.org/abs/2307.15838v1)|null|\n", "2307.14192": "|**2023-07-26**|**Unveiling Security, Privacy, and Ethical Concerns of ChatGPT**|Xiaodong Wu et.al.|[2307.14192v1](http://arxiv.org/abs/2307.14192v1)|null|\n", "2307.13221": "|**2023-07-25**|**Multilevel Large Language Models for Everyone**|Yuanhao Gong et.al.|[2307.13221v1](http://arxiv.org/abs/2307.13221v1)|null|\n", "2307.12181": "|**2023-07-22**|**Security and Privacy Issues of Federated Learning**|Jahid Hasan et.al.|[2307.12181v1](http://arxiv.org/abs/2307.12181v1)|null|\n", "2307.11254": "|**2023-11-11**|**An In-Depth Evaluation of Federated Learning on Biomedical Natural Language Processing**|Le Peng et.al.|[2307.11254v2](http://arxiv.org/abs/2307.11254v2)|**[link](https://github.com/gaoxiangluo/llm-biomed-ner-er)**|\n", "2307.10476": "|**2023-07-19**|**What can we learn from Data Leakage and Unlearning for Law?**|Jaydeep Borkar et.al.|[2307.10476v1](http://arxiv.org/abs/2307.10476v1)|null|\n", "2307.08925": "|**2023-07-18**|**Federated Large Language Model: A Position Paper**|Chaochao Chen et.al.|[2307.08925v1](http://arxiv.org/abs/2307.08925v1)|null|\n", "2307.08674": "|**2023-08-07**|**TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT**|Liangyu Zha et.al.|[2307.08674v3](http://arxiv.org/abs/2307.08674v3)|null|\n", "2307.08152": "|**2023-07-16**|**The Potential and Pitfalls of using a Large Language Model such as ChatGPT or GPT-4 as a Clinical Assistant**|Jingqing Zhang et.al.|[2307.08152v1](http://arxiv.org/abs/2307.08152v1)|null|\n", "2307.04280": "|**2023-07-09**|**Shaping the Emerging Norms of Using Large Language Models in Social Computing Research**|Hong Shen et.al.|[2307.04280v1](http://arxiv.org/abs/2307.04280v1)|null|\n", "2307.03941": "|**2023-09-22**|**Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions**|Dawen Zhang et.al.|[2307.03941v3](http://arxiv.org/abs/2307.03941v3)|null|\n", "2307.03875": "|**2023-07-13**|**Large Language Models for Supply Chain Optimization**|Beibin Li et.al.|[2307.03875v2](http://arxiv.org/abs/2307.03875v2)|null|\n", "2307.02779": "|**2023-07-06**|**Large Language Models Empowered Autonomous Edge AI for Connected Intelligence**|Yifei Shen et.al.|[2307.02779v1](http://arxiv.org/abs/2307.02779v1)|null|\n", "2307.01881": "|**2023-07-04**|**ProPILE: Probing Privacy Leakage in Large Language Models**|Siwon Kim et.al.|[2307.01881v1](http://arxiv.org/abs/2307.01881v1)|null|\n", "2307.00470": "|**2023-07-20**|**PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation**|Le Xiao et.al.|[2307.00470v4](http://arxiv.org/abs/2307.00470v4)|null|\n", "2306.14504": "|**2023-06-26**|**ChatIDS: Explainable Cybersecurity Using Generative AI**|Victor J\u00fcttner et.al.|[2306.14504v1](http://arxiv.org/abs/2306.14504v1)|null|\n", "2306.11698": "|**2023-06-20**|**DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models**|Boxin Wang et.al.|[2306.11698v1](http://arxiv.org/abs/2306.11698v1)|null|\n", "2306.10765": "|**2023-06-19**|**Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest Cost**|Juexiao Zhou et.al.|[2306.10765v1](http://arxiv.org/abs/2306.10765v1)|**[link](https://github.com/joshuachou2018/medagi)**|\n", "2306.10070": "|**2023-10-17**|**Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health**|Shubo Tian et.al.|[2306.10070v2](http://arxiv.org/abs/2306.10070v2)|null|\n", "2306.09273": "|**2023-09-17**|**Your Room is not Private: Gradient Inversion Attack on Reinforcement Learning**|Miao Li et.al.|[2306.09273v2](http://arxiv.org/abs/2306.09273v2)|null|\n", "2306.08937": "|**2023-10-26**|**DocumentNet: Bridging the Data Gap in Document Pre-Training**|Lijun Yu et.al.|[2306.08937v3](http://arxiv.org/abs/2306.08937v3)|null|\n", "2306.08666": "|**2023-06-14**|**Radiology-GPT: A Large Language Model for Radiology**|Zhengliang Liu et.al.|[2306.08666v1](http://arxiv.org/abs/2306.08666v1)|null|\n", "2306.08223": "|**2023-06-14**|**Protecting User Privacy in Remote Conversational Systems: A Privacy-Preserving framework based on text sanitization**|Zhigang Kan et.al.|[2306.08223v1](http://arxiv.org/abs/2306.08223v1)|null|\n", "2306.05087": "|**2023-06-08**|**PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization**|Yidong Wang et.al.|[2306.05087v1](http://arxiv.org/abs/2306.05087v1)|**[link](https://github.com/weopenml/pandalm)**|\n", "2306.01684": "|**2023-06-02**|**Harnessing large-language models to generate private synthetic text**|Alexey Kurakin et.al.|[2306.01684v1](http://arxiv.org/abs/2306.01684v1)|null|\n", "2306.01242": "|**2023-06-02**|**Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators**|Zhizheng Zhang et.al.|[2306.01242v1](http://arxiv.org/abs/2306.01242v1)|null|\n", "2305.18396": "|**2023-10-23**|**LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers**|Xuanqi Liu et.al.|[2305.18396v2](http://arxiv.org/abs/2305.18396v2)|**[link](https://github.com/privatellm001/private-llm-inference)**|\n", "2305.18395": "|**2023-10-30**|**Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks**|Minki Kang et.al.|[2305.18395v2](http://arxiv.org/abs/2305.18395v2)|**[link](https://github.com/nardien/kard)**|\n", "2305.15594": "|**2023-05-24**|**Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models**|Haonan Duan et.al.|[2305.15594v1](http://arxiv.org/abs/2305.15594v1)|null|\n", "2305.15242": "|**2023-05-24**|**Machine Unlearning: its nature, scope, and importance for a \"delete culture\"**|Luciano Floridi et.al.|[2305.15242v1](http://arxiv.org/abs/2305.15242v1)|null|\n", "2305.14965": "|**2023-05-24**|**Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks**|Abhinav Rao et.al.|[2305.14965v1](http://arxiv.org/abs/2305.14965v1)|null|\n", "2305.14536": "|**2023-10-23**|**MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems**|Jakub Macina et.al.|[2305.14536v2](http://arxiv.org/abs/2305.14536v2)|**[link](https://github.com/eth-nlped/mathdial)**|\n", "2305.14292": "|**2023-10-27**|**WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia**|Sina J. Semnani et.al.|[2305.14292v2](http://arxiv.org/abs/2305.14292v2)|null|\n", "2305.12723": "|**2023-05-22**|**Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting**|Xinlu Zhang et.al.|[2305.12723v1](http://arxiv.org/abs/2305.12723v1)|**[link](https://github.com/xzhang97666/privacyboost-slm)**|\n", "2305.12707": "|**2023-05-22**|**Quantifying Association Capabilities of Large Language Models and Its Implications on Privacy Leakage**|Hanyin Shao et.al.|[2305.12707v1](http://arxiv.org/abs/2305.12707v1)|null|\n", "2305.12132": "|**2023-05-20**|**Can Public Large Language Models Help Private Cross-device Federated Learning?**|Boxin Wang et.al.|[2305.12132v1](http://arxiv.org/abs/2305.12132v1)|null|\n", "2305.11759": "|**2023-05-19**|**Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning**|Mustafa Safa Ozdayi et.al.|[2305.11759v1](http://arxiv.org/abs/2305.11759v1)|**[link](https://github.com/amazon-science/controlling-llm-memorization)**|\n", "2305.11418": "|**2023-05-19**|**Towards Human-AI Collaborative Urban Science Research Enabled by Pre-trained Large Language Models**|Jiayi Fu et.al.|[2305.11418v1](http://arxiv.org/abs/2305.11418v1)|null|\n", "2305.11414": "|**2023-11-08**|**Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models**|Sixing Yu et.al.|[2305.11414v2](http://arxiv.org/abs/2305.11414v2)|null|\n", "2306.05552": "|**2023-05-19**|**ChatGPT for Us: Preserving Data Privacy in ChatGPT via Dialogue Text Ambiguation to Expand Mental Health Care Delivery**|Anaelia Ovalle et.al.|[2306.05552v1](http://arxiv.org/abs/2306.05552v1)|null|\n", "2305.10646": "|**2023-05-18**|**Ethical ChatGPT: Concerns, Challenges, and Commandments**|Jianlong Zhou et.al.|[2305.10646v1](http://arxiv.org/abs/2305.10646v1)|null|\n", "2305.09620": "|**2023-11-26**|**AI-Augmented Surveys: Leveraging Large Language Models and Surveys for Opinion Prediction**|Junsol Kim et.al.|[2305.09620v2](http://arxiv.org/abs/2305.09620v2)|null|\n", "2305.09550": "|**2023-05-17**|**Life of PII -- A PII Obfuscation Transformer**|Ajinkya Deshmukh et.al.|[2305.09550v2](http://arxiv.org/abs/2305.09550v2)|null|\n", "2305.06212": "|**2023-05-10**|**Privacy-Preserving Prompt Tuning for Large Language Model Services**|Yansong Li et.al.|[2305.06212v1](http://arxiv.org/abs/2305.06212v1)|null|\n", "2305.05973": "|**2023-05-10**|**Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models**|Aldo Gael Carranza et.al.|[2305.05973v1](http://arxiv.org/abs/2305.05973v1)|null|\n", "2305.05644": "|**2023-05-09**|**Towards Building the Federated GPT: Federated Instruction Tuning**|Jianyi Zhang et.al.|[2305.05644v1](http://arxiv.org/abs/2305.05644v1)|**[link](https://github.com/jayzhang42/federatedgpt-shepherd)**|\n", "2305.04757": "|**2023-05-18**|**Augmented Large Language Models with Parametric Knowledge Guiding**|Ziyang Luo et.al.|[2305.04757v2](http://arxiv.org/abs/2305.04757v2)|null|\n", "2305.04701": "|**2023-05-08**|**Differentially Private Attention Computation**|Yeqi Gao et.al.|[2305.04701v1](http://arxiv.org/abs/2305.04701v1)|null|\n", "2305.01639": "|**2023-09-30**|**Privacy-Preserving In-Context Learning for Large Language Models**|Tong Wu et.al.|[2305.01639v2](http://arxiv.org/abs/2305.01639v2)|null|\n", "2305.01550": "|**2023-05-02**|**Mitigating Approximate Memorization in Language Models via Dissimilarity Learned Policy**|Aly M. Kassem et.al.|[2305.01550v1](http://arxiv.org/abs/2305.01550v1)|null|\n", "2305.01181": "|**2023-05-02**|**New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT**|Chenyang Lyu et.al.|[2305.01181v1](http://arxiv.org/abs/2305.01181v1)|null|\n", "2304.13188": "|**2023-04-25**|**TABLET: Learning From Instructions For Tabular Data**|Dylan Slack et.al.|[2304.13188v1](http://arxiv.org/abs/2304.13188v1)|null|\n", "2304.10691": "|**2023-06-08**|**SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual Large Language Model**|Juexiao Zhou et.al.|[2304.10691v2](http://arxiv.org/abs/2304.10691v2)|**[link](https://github.com/joshuachou2018/skingpt-4)**|\n", "2304.09399": "|**2023-09-01**|**Designing a realistic peer-like embodied conversational agent for supporting children's storytelling**|Zhixin Li et.al.|[2304.09399v3](http://arxiv.org/abs/2304.09399v3)|null|\n", "2304.08247": "|**2023-10-04**|**MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data**|Tianyu Han et.al.|[2304.08247v2](http://arxiv.org/abs/2304.08247v2)|null|\n", "2305.03123": "|**2023-04-13**|**ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review**|Sunder Ali Khowaja et.al.|[2305.03123v1](http://arxiv.org/abs/2305.03123v1)|null|\n", "2304.05197": "|**2023-11-01**|**Multi-step Jailbreaking Privacy Attacks on ChatGPT**|Haoran Li et.al.|[2304.05197v3](http://arxiv.org/abs/2304.05197v3)|**[link](https://github.com/hkust-knowcomp/llm-multistep-jailbreak)**|\n", "2304.03472": "|**2023-04-15**|**Does Prompt-Tuning Language Model Ensure Privacy?**|Shangyu Xie et.al.|[2304.03472v2](http://arxiv.org/abs/2304.03472v2)|null|\n", "2304.01002": "|**2023-10-09**|**Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?**|Adaku Uchendu et.al.|[2304.01002v3](http://arxiv.org/abs/2304.01002v3)|**[link](https://github.com/huashen218/llm-deepfake-human-study)**|\n", "2303.16028": "|**2023-03-28**|**Synthetically generated text for supervised text analysis**|Andrew Halterman et.al.|[2303.16028v1](http://arxiv.org/abs/2303.16028v1)|null|\n", "2303.14070": "|**2023-06-24**|**ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge**|Yunxiang Li et.al.|[2303.14070v5](http://arxiv.org/abs/2303.14070v5)|**[link](https://github.com/kent0n-li/chatdoctor)**|\n", "2303.13856": "|**2023-04-12**|**Unleashing ChatGPT on the Metaverse: Savior or Destroyer?**|Pengyuan Zhou et.al.|[2303.13856v2](http://arxiv.org/abs/2303.13856v2)|null|\n", "2303.16756": "|**2023-08-05**|**Large Language Models for Healthcare Data Augmentation: An Example on Patient-Trial Matching**|Jiayi Yuan et.al.|[2303.16756v2](http://arxiv.org/abs/2303.16756v2)|null|\n", "2304.03086": "|**2023-07-31**|**ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model**|Hanyao Huang et.al.|[2304.03086v2](http://arxiv.org/abs/2304.03086v2)|null|\n", "2303.12429": "|**2023-03-22**|**Man vs the machine: The Struggle for Effective Text Anonymisation in the Age of Large Language Models**|Constantinos Patsakis et.al.|[2303.12429v1](http://arxiv.org/abs/2303.12429v1)|null|\n", "2303.11032": "|**2023-03-20**|**DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4**|Zhengliang Liu et.al.|[2303.11032v1](http://arxiv.org/abs/2303.11032v1)|**[link](https://github.com/yhydhx/chatgpt-api)**|\n", "2303.13379": "|**2023-07-22**|**Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review**|Lixiang Yan et.al.|[2303.13379v2](http://arxiv.org/abs/2303.13379v2)|null|\n", "2303.09136": "|**2023-03-16**|**A Short Survey of Viewing Large Language Models in Legal Aspect**|Zhongxiang Sun et.al.|[2303.09136v1](http://arxiv.org/abs/2303.09136v1)|**[link](https://github.com/jeryi-sun/llm-and-law)**|\n", "2303.04360": "|**2023-04-10**|**Does Synthetic Data Generation of LLMs Help Clinical Text Mining?**|Ruixiang Tang et.al.|[2303.04360v2](http://arxiv.org/abs/2303.04360v2)|null|\n", "2302.13681": "|**2023-02-28**|**The (ab)use of Open Source Code to Train Large Language Models**|Ali Al-Kaswan et.al.|[2302.13681v2](http://arxiv.org/abs/2302.13681v2)|**[link](https://github.com/aise-tudelft/nlbse23_reading_list)**|\n", "2303.17511": "|**2023-02-25**|**On pitfalls (and advantages) of sophisticated large language models**|Anna Strasser et.al.|[2303.17511v1](http://arxiv.org/abs/2303.17511v1)|null|\n", "2302.09419": "|**2023-05-01**|**A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT**|Ce Zhou et.al.|[2302.09419v3](http://arxiv.org/abs/2302.09419v3)|null|\n", "2302.09042": "|**2023-02-23**|**Privately Customizing Prefinetuning to Better Match User Data in Federated Learning**|Charlie Hou et.al.|[2302.09042v2](http://arxiv.org/abs/2302.09042v2)|null|\n", "2302.07735": "|**2023-02-13**|**Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge**|Ali Al-Kaswan et.al.|[2302.07735v1](http://arxiv.org/abs/2302.07735v1)|null|\n", "2302.03269": "|**2023-02-17**|**PLACES: Prompting Language Models for Social Conversation Synthesis**|Maximillian Chen et.al.|[2302.03269v3](http://arxiv.org/abs/2302.03269v3)|**[link](https://github.com/alexa/places)**|\n", "2302.02094": "|**2023-02-12**|**Chat2VIS: Generating Data Visualisations via Natural Language using ChatGPT, Codex and GPT-3 Large Language Models**|Paula Maddigan et.al.|[2302.02094v2](http://arxiv.org/abs/2302.02094v2)|null|\n", "2212.08354": "|**2022-12-16**|**FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP Tasks**|Weilong Dong et.al.|[2212.08354v1](http://arxiv.org/abs/2212.08354v1)|null|\n", "2210.15042": "|**2023-03-20**|**Privately Fine-Tuning Large Language Models with Differential Privacy**|Rouzbeh Behnia et.al.|[2210.15042v3](http://arxiv.org/abs/2210.15042v3)|null|\n", "2210.14739": "|**2022-11-30**|**A Case for Business Process-Specific Foundation Models**|Yara Rizk et.al.|[2210.14739v2](http://arxiv.org/abs/2210.14739v2)|null|\n", "2207.10802": "|**2023-09-02**|**Combing for Credentials: Active Pattern Extraction from Smart Reply**|Bargav Jayaraman et.al.|[2207.10802v3](http://arxiv.org/abs/2207.10802v3)|null|\n", "2207.00160": "|**2022-10-26**|**When Does Differentially Private Learning Not Suffer in High Dimensions?**|Xuechen Li et.al.|[2207.00160v4](http://arxiv.org/abs/2207.00160v4)|**[link](https://github.com/lxuechen/private-transformers)**|\n", "2205.13621": "|**2022-09-08**|**Differentially Private Decoding in Large Language Models**|Jimit Majmudar et.al.|[2205.13621v2](http://arxiv.org/abs/2205.13621v2)|null|\n", "2205.12506": "|**2022-11-04**|**Memorization in NLP Fine-tuning Methods**|Fatemehsadat Mireshghallah et.al.|[2205.12506v2](http://arxiv.org/abs/2205.12506v2)|**[link](https://github.com/mireshghallah/ft-memorization)**|\n", "2205.01863": "|**2022-06-23**|**Provably Confidential Language Modelling**|Xuandong Zhao et.al.|[2205.01863v2](http://arxiv.org/abs/2205.01863v2)|**[link](https://github.com/xuandongzhao/crt)**|\n", "2205.10228": "|**2022-04-26**|**You Don't Know My Favorite Color: Preventing Dialogue Representations from Revealing Speakers' Private Personas**|Haoran Li et.al.|[2205.10228v1](http://arxiv.org/abs/2205.10228v1)|**[link](https://github.com/hkust-knowcomp/persona_leakage_and_defense_in_gpt-2)**|\n", "2204.09391": "|**2022-04-20**|**You Are What You Write: Preserving Privacy in the Era of Large Language Models**|Richard Plant et.al.|[2204.09391v1](http://arxiv.org/abs/2204.09391v1)|null|\n", "2204.07667": "|**2022-10-27**|**Just Fine-tune Twice: Selective Differential Privacy for Large Language Models**|Weiyan Shi et.al.|[2204.07667v3](http://arxiv.org/abs/2204.07667v3)|**[link](https://github.com/wyshi/sdp_transformers)**|\n", "2202.07646": "|**2023-03-06**|**Quantifying Memorization Across Neural Language Models**|Nicholas Carlini et.al.|[2202.07646v3](http://arxiv.org/abs/2202.07646v3)|null|\n", "2202.06539": "|**2022-12-20**|**Deduplicating Training Data Mitigates Privacy Risks in Language Models**|Nikhil Kandpal et.al.|[2202.06539v3](http://arxiv.org/abs/2202.06539v3)|null|\n", "2112.02125": "|**2022-08-15**|**Examining Zero-Shot Vulnerability Repair with Large Language Models**|Hammond Pearce et.al.|[2112.02125v3](http://arxiv.org/abs/2112.02125v3)|null|\n", "2110.05679": "|**2022-11-10**|**Large Language Models Can Be Strong Differentially Private Learners**|Xuechen Li et.al.|[2110.05679v6](http://arxiv.org/abs/2110.05679v6)|**[link](https://github.com/lxuechen/private-transformers)**|\n", "2102.00875": "|**2021-02-01**|**Scaling Federated Learning for Fine-tuning of Large Language Models**|Agrin Hilmkil et.al.|[2102.00875v1](http://arxiv.org/abs/2102.00875v1)|null|\n"}, "LLM - Evaluation": {"2311.16103": "|**2023-11-27**|**Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models**|Munan Ning et.al.|[2311.16103v1](http://arxiv.org/abs/2311.16103v1)|**[link](https://github.com/pku-yuangroup/video-bench)**|\n", "2311.16093": "|**2023-11-27**|**Have we built machines that think like people?**|Luca M. Schulze Buschoff et.al.|[2311.16093v1](http://arxiv.org/abs/2311.16093v1)|null|\n", "2311.16079": "|**2023-11-27**|**MEDITRON-70B: Scaling Medical Pretraining for Large Language Models**|Zeming Chen et.al.|[2311.16079v1](http://arxiv.org/abs/2311.16079v1)|**[link](https://github.com/epfllm/meditron)**|\n", "2311.16075": "|**2023-11-27**|**BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical Knowledge Graph Insights**|Fran\u00e7ois Remy et.al.|[2311.16075v1](http://arxiv.org/abs/2311.16075v1)|null|\n", "2311.15781": "|**2023-11-27**|**Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs**|Simone Conia et.al.|[2311.15781v1](http://arxiv.org/abs/2311.15781v1)|**[link](https://github.com/apple/ml-kge)**|\n", "2311.15766": "|**2023-11-27**|**Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges**|Nianwen Si et.al.|[2311.15766v1](http://arxiv.org/abs/2311.15766v1)|null|\n", "2311.15653": "|**2023-11-27**|**MoDS: Model-oriented Data Selection for Instruction Tuning**|Qianlong Du et.al.|[2311.15653v1](http://arxiv.org/abs/2311.15653v1)|null|\n", "2311.15566": "|**2023-11-27**|**SpotServe: Serving Generative Large Language Models on Preemptible Instances**|Xupeng Miao et.al.|[2311.15566v1](http://arxiv.org/abs/2311.15566v1)|**[link](https://github.com/hsword/spotserve)**|\n", "2311.15548": "|**2023-11-27**|**Deficiency of Large Language Models in Finance: An Empirical Examination of Hallucination**|Haoqiang Kang et.al.|[2311.15548v1](http://arxiv.org/abs/2311.15548v1)|null|\n", "2311.15544": "|**2023-11-27**|**The effect of source disclosure on evaluation of AI-generated messages: A two-part study**|Sue Lim et.al.|[2311.15544v1](http://arxiv.org/abs/2311.15544v1)|null|\n", "2311.15500": "|**2023-11-27**|**Function-constrained Program Synthesis**|Patrick Hajali et.al.|[2311.15500v1](http://arxiv.org/abs/2311.15500v1)|null|\n", "2311.15451": "|**2023-11-26**|**Uncertainty-aware Language Modeling for Selective Question Answering**|Qi Yang et.al.|[2311.15451v1](http://arxiv.org/abs/2311.15451v1)|null|\n", "2311.15425": "|**2023-11-26**|**Machine-Generated Text Detection using Deep Learning**|Raghav Gaggar et.al.|[2311.15425v1](http://arxiv.org/abs/2311.15425v1)|null|\n", "2311.15296": "|**2023-11-26**|**UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation**|Xun Liang et.al.|[2311.15296v1](http://arxiv.org/abs/2311.15296v1)|**[link](https://github.com/IAAR-Shanghai/UHGEval)**|\n", "2311.15271": "|**2023-11-26**|**Synthesizing mixed-integer linear programming models from natural language descriptions**|Qingyang Li et.al.|[2311.15271v1](http://arxiv.org/abs/2311.15271v1)|null|\n", "2311.15209": "|**2023-11-26**|**See and Think: Embodied Agent in Virtual Environment**|Zhonghan Zhao et.al.|[2311.15209v1](http://arxiv.org/abs/2311.15209v1)|null|\n", "2311.15106": "|**2023-11-25**|**Solving the Right Problem is Key for Translational NLP: A Case Study in UMLS Vocabulary Insertion**|Bernal Jimenez Gutierrez et.al.|[2311.15106v1](http://arxiv.org/abs/2311.15106v1)|**[link](https://github.com/osu-nlp-group/umls-vocabulary-insertion)**|\n", "2311.14966": "|**2023-11-25**|**Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains**|Chia-Chien Hung et.al.|[2311.14966v1](http://arxiv.org/abs/2311.14966v1)|null|\n", "2311.14903": "|**2023-11-25**|**Code Generation Based Grading: Evaluating an Auto-grading Mechanism for \"Explain-in-Plain-English\" Questions**|David H. Smith IV et.al.|[2311.14903v1](http://arxiv.org/abs/2311.14903v1)|null|\n", "2311.14656": "|**2023-11-24**|**Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs**|Jonathan Roberts et.al.|[2311.14656v1](http://arxiv.org/abs/2311.14656v1)|**[link](https://github.com/jonathan-roberts1/charting-new-territories)**|\n", "2311.14788": "|**2023-11-24**|**Evaluating Large Language Models through Gender and Racial Stereotypes**|Ananya Malik et.al.|[2311.14788v1](http://arxiv.org/abs/2311.14788v1)|null|\n", "2311.14786": "|**2023-11-24**|**GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian Behavior Prediction**|Jia Huang et.al.|[2311.14786v1](http://arxiv.org/abs/2311.14786v1)|null|\n", "2311.14580": "|**2023-11-24**|**Large Language Models as Automated Aligners for benchmarking Vision-Language Models**|Yuanfeng Ji et.al.|[2311.14580v1](http://arxiv.org/abs/2311.14580v1)|null|\n", "2311.14519": "|**2023-11-24**|**Benchmarking Large Language Models for Log Analysis, Security, and Interpretation**|Egil Karlsen et.al.|[2311.14519v1](http://arxiv.org/abs/2311.14519v1)|null|\n", "2311.14479": "|**2023-11-24**|**Controlled Text Generation via Language Model Arithmetic**|Jasper Dekoninck et.al.|[2311.14479v1](http://arxiv.org/abs/2311.14479v1)|**[link](https://github.com/eth-sri/language-model-arithmetic)**|\n", "2311.14126": "|**2023-11-23**|**Towards Auditing Large Language Models: Improving Text-based Stereotype Detection**|Wu Zekun et.al.|[2311.14126v1](http://arxiv.org/abs/2311.14126v1)|null|\n", "2311.14096": "|**2023-11-23**|**Auditing and Mitigating Cultural Bias in LLMs**|Yan Tao et.al.|[2311.14096v1](http://arxiv.org/abs/2311.14096v1)|null|\n", "2311.13951": "|**2023-11-23**|**MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V**|Wentao Ge et.al.|[2311.13951v1](http://arxiv.org/abs/2311.13951v1)|null|\n", "2311.13884": "|**2023-11-23**|**Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**|Bin Zhang et.al.|[2311.13884v1](http://arxiv.org/abs/2311.13884v1)|null|\n", "2311.13668": "|**2023-11-22**|**MAIRA-1: A specialised large multimodal model for radiology report generation**|Stephanie L. Hyland et.al.|[2311.13668v1](http://arxiv.org/abs/2311.13668v1)|null|\n", "2311.13577": "|**2023-11-22**|**Physical Reasoning and Object Planning for Household Embodied Agents**|Ayush Agrawal et.al.|[2311.13577v1](http://arxiv.org/abs/2311.13577v1)|**[link](https://github.com/com-phy-affordance/coat)**|\n", "2311.13627": "|**2023-11-22**|**Vamos: Versatile Action Models for Video Understanding**|Shijie Wang et.al.|[2311.13627v1](http://arxiv.org/abs/2311.13627v1)|null|\n", "2311.13373": "|**2023-11-27**|**Large Language Model is a Good Policy Teacher for Training Reinforcement Learning Agents**|Zihao Zhou et.al.|[2311.13373v2](http://arxiv.org/abs/2311.13373v2)|null|\n", "2311.13274": "|**2023-11-22**|**Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**|Daphne van Zandvoort et.al.|[2311.13274v1](http://arxiv.org/abs/2311.13274v1)|null|\n", "2311.14740": "|**2023-11-22**|**AutoKG: Efficient Automated Knowledge Graph Generation for Language Models**|Bohan Chen et.al.|[2311.14740v1](http://arxiv.org/abs/2311.14740v1)|null|\n", "2311.13240": "|**2023-11-22**|**On the Calibration of Large Language Models and Alignment**|Chiwei Zhu et.al.|[2311.13240v1](http://arxiv.org/abs/2311.13240v1)|null|\n", "2311.13230": "|**2023-11-22**|**Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus**|Tianhang Zhang et.al.|[2311.13230v1](http://arxiv.org/abs/2311.13230v1)|**[link](https://github.com/zthang/focus)**|\n", "2311.13184": "|**2023-11-22**|**AS-LLM: When Algorithm Selection Meets Large Language Model**|Xingyu Wu et.al.|[2311.13184v1](http://arxiv.org/abs/2311.13184v1)|null|\n", "2311.13165": "|**2023-11-22**|**Multimodal Large Language Models: A Survey**|Jiayang Wu et.al.|[2311.13165v1](http://arxiv.org/abs/2311.13165v1)|null|\n", "2311.13614": "|**2023-11-22**|**HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data**|Qifan Yu et.al.|[2311.13614v1](http://arxiv.org/abs/2311.13614v1)|**[link](https://github.com/yuqifan1117/hallucidoctor)**|\n", "2311.13148": "|**2023-11-22**|**Building the Future of Responsible AI: A Pattern-Oriented Reference Architecture for Designing Large Language Model based Agents**|Qinghua Lu et.al.|[2311.13148v1](http://arxiv.org/abs/2311.13148v1)|null|\n", "2311.13133": "|**2023-11-22**|**LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms**|Aditi Jha et.al.|[2311.13133v1](http://arxiv.org/abs/2311.13133v1)|null|\n", "2311.13095": "|**2023-11-22**|**Enhancing Logical Reasoning in Large Language Models to Facilitate Legal Applications**|Ha-Thanh Nguyen et.al.|[2311.13095v1](http://arxiv.org/abs/2311.13095v1)|null|\n", "2311.13057": "|**2023-11-26**|**The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing through Interactive Visualization**|Md Naimul Hoque et.al.|[2311.13057v2](http://arxiv.org/abs/2311.13057v2)|null|\n", "2311.13053": "|**2023-11-21**|**Beyond Text: Unveiling Multimodal Proficiency of Large Language Models with MultiAPI Benchmark**|Xiao Liu et.al.|[2311.13053v1](http://arxiv.org/abs/2311.13053v1)|**[link](https://github.com/haroldliuj/multiapi)**|\n", "2311.13051": "|**2023-11-21**|**Latent Lab: Large Language Models for Knowledge Exploration**|Kevin Dunnell et.al.|[2311.13051v1](http://arxiv.org/abs/2311.13051v1)|null|\n", "2311.14743": "|**2023-11-21**|**A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift**|Ben Pikus et.al.|[2311.14743v1](http://arxiv.org/abs/2311.14743v1)|null|\n", "2311.12908": "|**2023-11-21**|**Diffusion Model Alignment Using Direct Preference Optimization**|Bram Wallace et.al.|[2311.12908v1](http://arxiv.org/abs/2311.12908v1)|null|\n", "2311.12668": "|**2023-11-21**|**From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design**|Cyril Picard et.al.|[2311.12668v1](http://arxiv.org/abs/2311.12668v1)|null|\n", "2311.12574": "|**2023-11-21**|**IMGTB: A Framework for Machine-Generated Text Detection Benchmarking**|Michal Spiegel et.al.|[2311.12574v1](http://arxiv.org/abs/2311.12574v1)|null|\n", "2311.12538": "|**2023-11-22**|**In-Context Learning Functions with Varying Number of Minima**|David Oniani et.al.|[2311.12538v2](http://arxiv.org/abs/2311.12538v2)|**[link](https://github.com/pittnail/icl-minima)**|\n", "2311.12537": "|**2023-11-21**|**Oasis: Data Curation and Assessment System for Pretraining of Large Language Models**|Tong Zhou et.al.|[2311.12537v1](http://arxiv.org/abs/2311.12537v1)|**[link](https://github.com/tongzhou21/oasis)**|\n", "2311.12524": "|**2023-11-21**|**ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models**|Jiankai Tang et.al.|[2311.12524v1](http://arxiv.org/abs/2311.12524v1)|**[link](https://github.com/mcjacktang/llm-healthassistant)**|\n", "2311.12351": "|**2023-11-21**|**Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**|Yunpeng Huang et.al.|[2311.12351v1](http://arxiv.org/abs/2311.12351v1)|**[link](https://github.com/strivin0311/long-llms-learning)**|\n", "2311.12327": "|**2023-11-21**|**ViLaM: A Vision-Language Model with Enhanced Visual Grounding and Generalization Capability**|Xiaoyu Yang et.al.|[2311.12327v1](http://arxiv.org/abs/2311.12327v1)|**[link](https://github.com/anonymgiant/vilam)**|\n", "2311.12315": "|**2023-11-21**|**AcademicGPT: Empowering Academic Research**|Shufa Wei et.al.|[2311.12315v1](http://arxiv.org/abs/2311.12315v1)|null|\n", "2311.12289": "|**2023-11-21**|**ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for Interdisciplinary Science**|Sai Munikoti et.al.|[2311.12289v1](http://arxiv.org/abs/2311.12289v1)|null|\n", "2311.12233": "|**2023-11-20**|**Unifying Corroborative and Contributive Attributions in Large Language Models**|Theodora Worledge et.al.|[2311.12233v1](http://arxiv.org/abs/2311.12233v1)|null|\n", "2311.11865": "|**2023-11-20**|**VLM-Eval: A General Evaluation on Video Large Language Models**|Shuailin Li et.al.|[2311.11865v1](http://arxiv.org/abs/2311.11865v1)|null|\n", "2311.11861": "|**2023-11-20**|**Generating Valid and Natural Adversarial Examples with Large Language Models**|Zimu Wang et.al.|[2311.11861v1](http://arxiv.org/abs/2311.11861v1)|null|\n", "2311.11855": "|**2023-11-20**|**Evil Geniuses: Delving into the Safety of LLM-based Agents**|Yu Tian et.al.|[2311.11855v1](http://arxiv.org/abs/2311.11855v1)|**[link](https://github.com/t1ans1r/evil-geniuses)**|\n", "2311.11844": "|**2023-11-20**|**How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents**|Lorenzo Lupo et.al.|[2311.11844v1](http://arxiv.org/abs/2311.11844v1)|null|\n", "2311.11690": "|**2023-11-20**|**Refactoring Programs Using Large Language Models with Few-Shot Examples**|Atsushi Shirafuji et.al.|[2311.11690v1](http://arxiv.org/abs/2311.11690v1)|null|\n", "2311.11689": "|**2023-11-20**|**Causal Structure Learning Supervised by Large Language Model**|Taiyu Ban et.al.|[2311.11689v1](http://arxiv.org/abs/2311.11689v1)|**[link](https://github.com/tymadara/ils-csl)**|\n", "2311.11567": "|**2023-11-20**|**CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models**|Xiaotian Han et.al.|[2311.11567v1](http://arxiv.org/abs/2311.11567v1)|null|\n", "2311.11552": "|**2023-11-20**|**Exploring Prompting Large Language Models as Explainable Metrics**|Ghazaleh Mahmoudi et.al.|[2311.11552v1](http://arxiv.org/abs/2311.11552v1)|**[link](https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics)**|\n", "2311.11547": "|**2023-11-20**|**Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT**|Abdelkarim El-Hajjami et.al.|[2311.11547v1](http://arxiv.org/abs/2311.11547v1)|null|\n", "2311.11516": "|**2023-11-20**|**GPT in Data Science: A Practical Exploration of Model Selection**|Nathalia Nascimento et.al.|[2311.11516v1](http://arxiv.org/abs/2311.11516v1)|null|\n", "2311.12074": "|**2023-11-19**|**SecureBERT and LLAMA 2 Empowered Control Area Network Intrusion Detection and Classification**|Xuemei Li et.al.|[2311.12074v1](http://arxiv.org/abs/2311.12074v1)|null|\n", "2311.14722": "|**2023-11-19**|**Zero-Shot Question Answering over Financial Documents using Large Language Models**|Karmvir Singh Phogat et.al.|[2311.14722v1](http://arxiv.org/abs/2311.14722v1)|null|\n", "2311.11267": "|**2023-11-19**|**Rethinking Large Language Models in Mental Health Applications**|Shaoxiong Ji et.al.|[2311.11267v1](http://arxiv.org/abs/2311.11267v1)|null|\n", "2311.11255": "|**2023-11-19**|**M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models**|Atin Sakkeer Hussain et.al.|[2311.11255v1](http://arxiv.org/abs/2311.11255v1)|null|\n", "2311.11183": "|**2023-11-18**|**Deploying and Evaluating LLMs to Program Service Mobile Robots**|Zichao Hu et.al.|[2311.11183v1](http://arxiv.org/abs/2311.11183v1)|null|\n", "2311.11081": "|**2023-11-18**|**Can AI Serve as a Substitute for Human Subjects in Software Engineering Research?**|Marco A. Gerosa et.al.|[2311.11081v1](http://arxiv.org/abs/2311.11081v1)|null|\n", "2311.11077": "|**2023-11-18**|**Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**|Clifton Poth et.al.|[2311.11077v1](http://arxiv.org/abs/2311.11077v1)|null|\n", "2311.10947": "|**2023-11-18**|**RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**|Yuxuan Lei et.al.|[2311.10947v1](http://arxiv.org/abs/2311.10947v1)|null|\n", "2311.10813": "|**2023-11-21**|**A Language Agent for Autonomous Driving**|Jiageng Mao et.al.|[2311.10813v2](http://arxiv.org/abs/2311.10813v2)|**[link](https://github.com/usc-gvl/agent-driver)**|\n", "2311.10702": "|**2023-11-20**|**Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2**|Hamish Ivison et.al.|[2311.10702v2](http://arxiv.org/abs/2311.10702v2)|null|\n", "2311.10614": "|**2023-11-17**|**A Self-enhancement Approach for Domain-specific Chatbot Training via Knowledge Mining and Digest**|Ruohong Zhang et.al.|[2311.10614v1](http://arxiv.org/abs/2311.10614v1)|null|\n", "2311.10418": "|**2023-11-17**|**DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines**|Chenyu Jiang et.al.|[2311.10418v1](http://arxiv.org/abs/2311.10418v1)|**[link](https://github.com/chenyu-jiang/megatron-lm)**|\n", "2311.10388": "|**2023-11-17**|**Automatic Smart Contract Comment Generation via Large Language Models and In-Context Learning**|Junjie Zhao et.al.|[2311.10388v1](http://arxiv.org/abs/2311.10388v1)|**[link](https://github.com/jun-jie-zhao/sccllm)**|\n", "2311.10255": "|**2023-11-17**|**FREE: The Foundational Semantic Recognition for Modeling Environmental Ecosystems**|Shiyuan Luo et.al.|[2311.10255v1](http://arxiv.org/abs/2311.10255v1)|null|\n", "2311.10785": "|**2023-11-16**|**Text Sanitization Beyond Specific Domains: Zero-Shot Redaction & Substitution with Large Language Models**|Federico Albanese et.al.|[2311.10785v1](http://arxiv.org/abs/2311.10785v1)|null|\n", "2311.10054": "|**2023-11-16**|**Is \"A Helpful Assistant\" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts**|Mingqian Zheng et.al.|[2311.10054v1](http://arxiv.org/abs/2311.10054v1)|null|\n", "2311.09862": "|**2023-11-16**|**Which Modality should I use -- Text, Motif, or Image? : Understanding Graphs with Large Language Models**|Debarati Das et.al.|[2311.09862v1](http://arxiv.org/abs/2311.09862v1)|null|\n", "2311.09861": "|**2023-11-17**|**PsyBench: a balanced and in-depth Psychological Chinese Evaluation Benchmark for Foundation Models**|Junlei Zhang et.al.|[2311.09861v2](http://arxiv.org/abs/2311.09861v2)|null|\n", "2311.09835": "|**2023-11-16**|**ML-Bench: Large Language Models Leverage Open-source Libraries for Machine Learning Tasks**|Yuliang Liu et.al.|[2311.09835v1](http://arxiv.org/abs/2311.09835v1)|null|\n", "2311.09829": "|**2023-11-16**|**FollowEval: A Multi-Dimensional Benchmark for Assessing the Instruction-Following Capability of Large Language Models**|Yimin Jing et.al.|[2311.09829v1](http://arxiv.org/abs/2311.09829v1)|null|\n", "2311.10537": "|**2023-11-16**|**MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning**|Xiangru Tang et.al.|[2311.10537v1](http://arxiv.org/abs/2311.10537v1)|**[link](https://github.com/gersteinlab/medagents)**|\n", "2311.09816": "|**2023-11-16**|**Performance Trade-offs of Watermarking Large Language Models**|Anirudh Ajith et.al.|[2311.09816v1](http://arxiv.org/abs/2311.09816v1)|null|\n", "2311.09783": "|**2023-11-16**|**Investigating Data Contamination in Modern Benchmarks for Large Language Models**|Chunyuan Deng et.al.|[2311.09783v1](http://arxiv.org/abs/2311.09783v1)|null|\n", "2311.09763": "|**2023-11-16**|**Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations**|Wenjie Mo et.al.|[2311.09763v1](http://arxiv.org/abs/2311.09763v1)|null|\n", "2311.09741": "|**2023-11-16**|**What Constitutes a Faithful Summary? Preserving Author Perspectives in News Summarization**|Yuhan Liu et.al.|[2311.09741v1](http://arxiv.org/abs/2311.09741v1)|**[link](https://github.com/lyh6560new/p3sum)**|\n", "2311.09735": "|**2023-11-16**|**GEO: Generative Engine Optimization**|Pranjal Aggarwal et.al.|[2311.09735v1](http://arxiv.org/abs/2311.09735v1)|null|\n", "2311.09721": "|**2023-11-16**|**On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering**|Linyong Nan et.al.|[2311.09721v1](http://arxiv.org/abs/2311.09721v1)|null|\n", "2311.09707": "|**2023-11-16**|**GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding**|Andor Diera et.al.|[2311.09707v1](http://arxiv.org/abs/2311.09707v1)|null|\n", "2311.09702": "|**2023-11-16**|**Deceiving Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?**|Bangzheng Li et.al.|[2311.09702v1](http://arxiv.org/abs/2311.09702v1)|null|\n", "2311.09687": "|**2023-11-16**|**Inducing Political Bias Allows Language Models Anticipate Partisan Reactions to Controversies**|Zihao He et.al.|[2311.09687v1](http://arxiv.org/abs/2311.09687v1)|null|\n", "2311.09665": "|**2023-11-16**|**Evaluating LLM Agent Group Dynamics against Human Group Dynamics: A Case Study on Wisdom of Partisan Crowds**|Yun-Shiuan Chuang et.al.|[2311.09665v1](http://arxiv.org/abs/2311.09665v1)|null|\n", "2311.09651": "|**2023-11-16**|**\"It's not like Jarvis, but it's pretty close!\" -- Examining ChatGPT's Usage among Undergraduate Students in Computer Science**|Ishika Joshi et.al.|[2311.09651v1](http://arxiv.org/abs/2311.09651v1)|null|\n", "2311.09648": "|**2023-11-16**|**Event Causality Is Key to Computational Story Understanding**|Yidan Sun et.al.|[2311.09648v1](http://arxiv.org/abs/2311.09648v1)|null|\n", "2311.09635": "|**2023-11-16**|**Evaluating In-Context Learning of Libraries for Code Generation**|Arkil Patel et.al.|[2311.09635v1](http://arxiv.org/abs/2311.09635v1)|null|\n", "2311.09632": "|**2023-11-16**|**Online Continual Knowledge Learning for Language Models**|Yuhao Wu et.al.|[2311.09632v1](http://arxiv.org/abs/2311.09632v1)|null|\n", "2311.09603": "|**2023-11-16**|**SCORE: A framework for Self-Contradictory Reasoning Evaluation**|Ziyi Liu et.al.|[2311.09603v1](http://arxiv.org/abs/2311.09603v1)|null|\n", "2311.09602": "|**2023-11-16**|**Language Models (Mostly) Do Not Consider Emotion Triggers When Predicting Emotion**|Smriti Singh et.al.|[2311.09602v1](http://arxiv.org/abs/2311.09602v1)|null|\n", "2311.09564": "|**2023-11-16**|**LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks**|Mihir Parmar et.al.|[2311.09564v1](http://arxiv.org/abs/2311.09564v1)|**[link](https://github.com/mihir3009/longbox)**|\n", "2311.09562": "|**2023-11-16**|**A Reevaluation of Event Extraction: Past, Present, and Future Challenges**|Kuan-Hao Huang et.al.|[2311.09562v1](http://arxiv.org/abs/2311.09562v1)|**[link](https://github.com/ej0cl6/textee)**|\n", "2311.09558": "|**2023-11-16**|**Pachinko: Patching Interpretable QA Models through Natural Language Feedback**|Chaitanya Malaviya et.al.|[2311.09558v1](http://arxiv.org/abs/2311.09558v1)|**[link](https://github.com/chaitanyamalaviya/pachinko)**|\n", "2311.09552": "|**2023-11-16**|**Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition**|Tariq Alhindi et.al.|[2311.09552v1](http://arxiv.org/abs/2311.09552v1)|null|\n", "2311.09535": "|**2023-11-17**|**FunctionMarker: Watermarking Language Datasets via Knowledge Injection**|Shuai Li et.al.|[2311.09535v2](http://arxiv.org/abs/2311.09535v2)|null|\n", "2311.09517": "|**2023-11-16**|**GEE! Grammar Error Explanation with Large Language Models**|Yixiao Song et.al.|[2311.09517v1](http://arxiv.org/abs/2311.09517v1)|**[link](https://github.com/yixiao-song/gee-with-llms)**|\n", "2311.09513": "|**2023-11-16**|**Sequencing Matters: A Generate-Retrieve-Generate Model for Building Conversational Agents**|Quinn Patwardhan et.al.|[2311.09513v1](http://arxiv.org/abs/2311.09513v1)|null|\n", "2311.10775": "|**2023-11-15**|**ToolTalk: Evaluating Tool-Usage in a Conversational Setting**|Nicholas Farn et.al.|[2311.10775v1](http://arxiv.org/abs/2311.10775v1)|null|\n", "2311.10774": "|**2023-11-15**|**MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning**|Fuxiao Liu et.al.|[2311.10774v1](http://arxiv.org/abs/2311.10774v1)|**[link](https://github.com/fuxiaoliu/mmc)**|\n", "2311.09410": "|**2023-11-15**|**When Large Language Models contradict humans? Large Language Models' Sycophantic Behaviour**|Leonardo Ranaldi et.al.|[2311.09410v1](http://arxiv.org/abs/2311.09410v1)|null|\n", "2311.09358": "|**2023-11-15**|**Empirical evaluation of Uncertainty Quantification in Retrieval-Augmented Language Models for Science**|Sridevi Wagle et.al.|[2311.09358v1](http://arxiv.org/abs/2311.09358v1)|**[link](https://github.com/pnnl/expert2)**|\n", "2311.09335": "|**2023-11-15**|**Lighter, yet More Faithful: Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization**|George Chrysostomou et.al.|[2311.09335v1](http://arxiv.org/abs/2311.09335v1)|null|\n", "2311.09214": "|**2023-11-15**|**Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models**|Weize Liu et.al.|[2311.09214v1](http://arxiv.org/abs/2311.09214v1)|null|\n", "2311.09210": "|**2023-11-15**|**Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**|Wenhao Yu et.al.|[2311.09210v1](http://arxiv.org/abs/2311.09210v1)|null|\n", "2311.09206": "|**2023-11-15**|**TableLlama: Towards Open Large Generalist Models for Tables**|Tianshu Zhang et.al.|[2311.09206v1](http://arxiv.org/abs/2311.09206v1)|null|\n", "2311.09204": "|**2023-11-15**|**Fusion-Eval: Integrating Evaluators with LLMs**|Lei Shu et.al.|[2311.09204v1](http://arxiv.org/abs/2311.09204v1)|null|\n", "2311.09189": "|**2023-11-15**|**PsyEval: A Comprehensive Large Language Model Evaluation Benchmark for Mental Health**|Haoan Jin et.al.|[2311.09189v1](http://arxiv.org/abs/2311.09189v1)|null|\n", "2311.09184": "|**2023-11-15**|**Benchmarking Generation and Evaluation Capabilities of Large Language Models for Instruction Controllable Summarization**|Yixin Liu et.al.|[2311.09184v1](http://arxiv.org/abs/2311.09184v1)|**[link](https://github.com/yale-nlp/instrusum)**|\n", "2311.09154": "|**2023-11-15**|**CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models**|Wenhong Zhu et.al.|[2311.09154v1](http://arxiv.org/abs/2311.09154v1)|null|\n", "2311.09127": "|**2023-11-15**|**Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts**|Yuanwei Wu et.al.|[2311.09127v1](http://arxiv.org/abs/2311.09127v1)|null|\n", "2311.09101": "|**2023-11-15**|**Towards A Unified View of Answer Calibration for Multi-Step Reasoning**|Shumin Deng et.al.|[2311.09101v1](http://arxiv.org/abs/2311.09101v1)|null|\n", "2311.09090": "|**2023-11-15**|**Social Bias Probing: Fairness Benchmarking for Language Models**|Marta Marchiori Manerba et.al.|[2311.09090v1](http://arxiv.org/abs/2311.09090v1)|null|\n", "2311.09071": "|**2023-11-15**|**How Multilingual is Multilingual LLM?**|Fei Yuan et.al.|[2311.09071v1](http://arxiv.org/abs/2311.09071v1)|null|\n", "2311.09060": "|**2023-11-15**|**Do Localization Methods Actually Localize Memorized Data in LLMs?**|Ting-Yun Chang et.al.|[2311.09060v1](http://arxiv.org/abs/2311.09060v1)|null|\n", "2311.09053": "|**2023-11-15**|**Assessing Knowledge Editing in Language Models via Relation Perspective**|Yifan Wei et.al.|[2311.09053v1](http://arxiv.org/abs/2311.09053v1)|**[link](https://github.com/weiyifan1023/knowledge-edit-based-on-relation-perspective)**|\n", "2311.09050": "|**2023-11-15**|**Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts**|Yunshi Lan et.al.|[2311.09050v1](http://arxiv.org/abs/2311.09050v1)|**[link](https://github.com/ecnu-dase-nlp/rqp)**|\n", "2311.09048": "|**2023-11-15**|**GRASP: A novel benchmark for evaluating language GRounding And Situated Physics understanding in multimodal language models**|Serwan Jassim et.al.|[2311.09048v1](http://arxiv.org/abs/2311.09048v1)|null|\n", "2311.09033": "|**2023-11-15**|**MELA: Multilingual Evaluation of Linguistic Acceptability**|Ziyin Zhang et.al.|[2311.09033v1](http://arxiv.org/abs/2311.09033v1)|null|\n", "2311.09022": "|**2023-11-15**|**Exploring the Potential of Large Language Models in Computational Argumentation**|Guizhen Chen et.al.|[2311.09022v1](http://arxiv.org/abs/2311.09022v1)|**[link](https://github.com/damo-nlp-sg/llm-argumentation)**|\n", "2311.09020": "|**2023-11-15**|**Explaining Explanation: An Empirical Study on Explanation in Code Reviews**|Ratnadira Widyasari et.al.|[2311.09020v1](http://arxiv.org/abs/2311.09020v1)|null|\n", "2311.08981": "|**2023-11-15**|**Speculative Contrastive Decoding**|Hongyi Yuan et.al.|[2311.08981v1](http://arxiv.org/abs/2311.08981v1)|null|\n", "2311.08877": "|**2023-11-15**|**Llamas Know What GPTs Don't Show: Surrogate Models for Confidence Estimation**|Vaishnavi Shrivastava et.al.|[2311.08877v1](http://arxiv.org/abs/2311.08877v1)|null|\n", "2311.10766": "|**2023-11-15**|**Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values**|Jing Yao et.al.|[2311.10766v1](http://arxiv.org/abs/2311.10766v1)|**[link](https://github.com/valuecompass/valuecompass.github.io)**|\n", "2311.14711": "|**2023-11-15**|**Towards Publicly Accountable Frontier LLMs: Building an External Scrutiny Ecosystem under the ASPIRE Framework**|Markus Anderljung et.al.|[2311.14711v1](http://arxiv.org/abs/2311.14711v1)|null|\n", "2311.08838": "|**2023-11-15**|**Disinformation Capabilities of Large Language Models**|Ivan Vykopal et.al.|[2311.08838v1](http://arxiv.org/abs/2311.08838v1)|null|\n", "2311.08832": "|**2023-11-15**|**Exploring Links between Conversational Agent Design Challenges and Interdisciplinary Collaboration**|Malak Sadek et.al.|[2311.08832v1](http://arxiv.org/abs/2311.08832v1)|null|\n", "2311.08803": "|**2023-11-15**|**StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving**|Chang Gao et.al.|[2311.08803v1](http://arxiv.org/abs/2311.08803v1)|null|\n", "2311.08732": "|**2023-11-15**|**Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models**|Minze Chen et.al.|[2311.08732v1](http://arxiv.org/abs/2311.08732v1)|null|\n", "2311.08723": "|**2023-11-15**|**Token Prediction as Implicit Classification to Identify LLM-Generated Text**|Yutian Chen et.al.|[2311.08723v1](http://arxiv.org/abs/2311.08723v1)|**[link](https://github.com/markchenyutian/t5-sentinel-public)**|\n", "2311.08718": "|**2023-11-15**|**Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling**|Bairu Hou et.al.|[2311.08718v1](http://arxiv.org/abs/2311.08718v1)|null|\n", "2311.08711": "|**2023-11-15**|**PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning**|Zhihan Zhang et.al.|[2311.08711v1](http://arxiv.org/abs/2311.08711v1)|**[link](https://github.com/ytyz1307zzh/plug)**|\n", "2311.08704": "|**2023-11-15**|**Can Large Language Models Follow Concept Annotation Guidelines? A Case Study on Scientific and Financial Domains**|Marcio Fonseca et.al.|[2311.08704v1](http://arxiv.org/abs/2311.08704v1)|null|\n", "2311.08692": "|**2023-11-15**|**Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models**|Keming Lu et.al.|[2311.08692v1](http://arxiv.org/abs/2311.08692v1)|null|\n", "2311.08649": "|**2023-11-15**|**Autonomous Large Language Model Agents Enabling Intent-Driven Mobile GUI Testing**|Juyeon Yoon et.al.|[2311.08649v1](http://arxiv.org/abs/2311.08649v1)|null|\n", "2311.10763": "|**2023-11-15**|**Comparing Generalization in Learning with Limited Numbers of Exemplars: Transformer vs. RNN in Attractor Dynamics**|Rui Fukushima et.al.|[2311.10763v1](http://arxiv.org/abs/2311.10763v1)|null|\n", "2311.08614": "|**2023-11-15**|**XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making**|Zichen Chen et.al.|[2311.08614v1](http://arxiv.org/abs/2311.08614v1)|null|\n", "2311.08596": "|**2023-11-14**|**Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment**|Philippe Laban et.al.|[2311.08596v1](http://arxiv.org/abs/2311.08596v1)|null|\n", "2311.08592": "|**2023-11-14**|**AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications**|Bhaktipriya Radharapu et.al.|[2311.08592v1](http://arxiv.org/abs/2311.08592v1)|null|\n", "2311.08588": "|**2023-11-14**|**CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation**|Weixiang Yan et.al.|[2311.08588v1](http://arxiv.org/abs/2311.08588v1)|**[link](https://github.com/weixiangyan/codescope)**|\n", "2311.08576": "|**2023-11-14**|**Towards Evaluating AI Systems for Moral Status Using Self-Reports**|Ethan Perez et.al.|[2311.08576v1](http://arxiv.org/abs/2311.08576v1)|null|\n", "2311.08562": "|**2023-11-16**|**MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration**|Lin Xu et.al.|[2311.08562v2](http://arxiv.org/abs/2311.08562v2)|**[link](https://github.com/cathyxl/magic)**|\n", "2311.08526": "|**2023-11-14**|**GLiNER: Generalist Model for Named Entity Recognition using Bidirectional Transformer**|Urchade Zaratiana et.al.|[2311.08526v1](http://arxiv.org/abs/2311.08526v1)|**[link](https://github.com/urchade/gliner)**|\n", "2311.08472": "|**2023-11-14**|**Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models**|Carlos Aguirre et.al.|[2311.08472v1](http://arxiv.org/abs/2311.08472v1)|null|\n", "2311.08469": "|**2023-11-14**|**UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations**|Wenting Zhao et.al.|[2311.08469v1](http://arxiv.org/abs/2311.08469v1)|null|\n", "2311.08398": "|**2023-11-16**|**Are Large Language Models Temporally Grounded?**|Yifu Qiu et.al.|[2311.08398v2](http://arxiv.org/abs/2311.08398v2)|**[link](https://github.com/yfqiu-nlp/temporal-llms)**|\n", "2311.08390": "|**2023-11-14**|**On What Basis? Predicting Text Preference Via Structured Comparative Reasoning**|Jing Nathan Yan et.al.|[2311.08390v1](http://arxiv.org/abs/2311.08390v1)|null|\n", "2311.08389": "|**2023-11-14**|**TSST: A Benchmark and Evaluation Models for Text Speech-Style Transfer**|Huashan Sun et.al.|[2311.08389v1](http://arxiv.org/abs/2311.08389v1)|null|\n", "2311.08303": "|**2023-11-14**|**Extrinsically-Focused Evaluation of Omissions in Medical Summarization**|Elliot Schumacher et.al.|[2311.08303v1](http://arxiv.org/abs/2311.08303v1)|null|\n", "2311.08287": "|**2023-11-14**|**How Well Do Large Language Models Understand Syntax? An Evaluation by Asking Natural Language Questions**|Houquan Zhou et.al.|[2311.08287v1](http://arxiv.org/abs/2311.08287v1)|**[link](https://github.com/Jacob-Zhou/SynEval)**|\n", "2311.08106": "|**2023-11-14**|**Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language Models**|Yujin Kim et.al.|[2311.08106v1](http://arxiv.org/abs/2311.08106v1)|null|\n", "2311.08097": "|**2023-11-14**|**Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts**|Leonardo Ranaldi et.al.|[2311.08097v1](http://arxiv.org/abs/2311.08097v1)|null|\n", "2311.07957": "|**2023-11-14**|**Language Models are Better Bug Detector Through Code-Pair Classification**|Kamel Alrashedy et.al.|[2311.07957v1](http://arxiv.org/abs/2311.07957v1)|**[link](https://github.com/kamel773/code_pair_classification)**|\n", "2311.07945": "|**2023-11-14**|**First Step Advantage: Importance of Starting Right in Multi-Step Reasoning**|Kushal Jain et.al.|[2311.07945v1](http://arxiv.org/abs/2311.07945v1)|null|\n", "2311.07911": "|**2023-11-14**|**Instruction-Following Evaluation for Large Language Models**|Jeffrey Zhou et.al.|[2311.07911v1](http://arxiv.org/abs/2311.07911v1)|**[link](https://github.com/google-research/google-research)**|\n", "2311.07884": "|**2023-11-14**|**Fair Abstractive Summarization of Diverse Perspectives**|Yusen Zhang et.al.|[2311.07884v1](http://arxiv.org/abs/2311.07884v1)|**[link](https://github.com/psunlpgroup/fairsumm)**|\n", "2311.07878": "|**2023-11-18**|**Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset**|Zafaryab Rasool et.al.|[2311.07878v3](http://arxiv.org/abs/2311.07878v3)|null|\n", "2311.07838": "|**2023-11-14**|**LLatrieval: LLM-Verified Retrieval for Verifiable Generation**|Xiaonan Li et.al.|[2311.07838v1](http://arxiv.org/abs/2311.07838v1)|**[link](https://github.com/beastyz/llm-verified-retrieval)**|\n", "2311.07792": "|**2023-11-13**|**Western, Religious or Spiritual: An Evaluation of Moral Justification in Large Language Models**|Eyup Engin Kucuk et.al.|[2311.07792v1](http://arxiv.org/abs/2311.07792v1)|null|\n", "2311.07687": "|**2023-11-13**|**Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games**|Arjun Vaithilingam Sudhakar et.al.|[2311.07687v1](http://arxiv.org/abs/2311.07687v1)|null|\n", "2311.07575": "|**2023-11-13**|**SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large Language Models**|Ziyi Lin et.al.|[2311.07575v1](http://arxiv.org/abs/2311.07575v1)|**[link](https://github.com/alpha-vllm/llama2-accessory)**|\n", "2311.07556": "|**2023-11-13**|**Using Natural Language Explanations to Improve Robustness of In-context Learning for Natural Language Inference**|Xuanli He et.al.|[2311.07556v1](http://arxiv.org/abs/2311.07556v1)|null|\n", "2311.07532": "|**2023-11-13**|**It's Not Easy Being Wrong: Evaluating Process of Elimination Reasoning in Large Language Models**|Nishant Balepur et.al.|[2311.07532v1](http://arxiv.org/abs/2311.07532v1)|**[link](https://github.com/nbalepur/poe)**|\n", "2311.07509": "|**2023-11-13**|**A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases**|Juan Sequeda et.al.|[2311.07509v1](http://arxiv.org/abs/2311.07509v1)|null|\n", "2311.07470": "|**2023-11-13**|**Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer**|Haowen Pan et.al.|[2311.07470v1](http://arxiv.org/abs/2311.07470v1)|null|\n", "2311.07469": "|**2023-11-15**|**InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models**|Ken E. Friedl et.al.|[2311.07469v2](http://arxiv.org/abs/2311.07469v2)|null|\n", "2311.07466": "|**2023-11-13**|**On Measuring Faithfulness of Natural Language Explanations**|Letitia Parcalabescu et.al.|[2311.07466v1](http://arxiv.org/abs/2311.07466v1)|**[link](https://github.com/heidelberg-nlp/cc-shap)**|\n", "2311.07463": "|**2023-11-13**|**MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks**|Sanchit Ahuja et.al.|[2311.07463v1](http://arxiv.org/abs/2311.07463v1)|null|\n", "2311.07446": "|**2023-11-13**|**Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text**|Zhongfei Qing et.al.|[2311.07446v1](http://arxiv.org/abs/2311.07446v1)|null|\n", "2311.07445": "|**2023-11-13**|**Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue**|Junkai Zhou et.al.|[2311.07445v1](http://arxiv.org/abs/2311.07445v1)|null|\n", "2311.07397": "|**2023-11-13**|**An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation**|Junyang Wang et.al.|[2311.07397v1](http://arxiv.org/abs/2311.07397v1)|**[link](https://github.com/junyangwang0410/amber)**|\n", "2311.07383": "|**2023-11-13**|**LM-Polygraph: Uncertainty Estimation for Language Models**|Ekaterina Fadeeva et.al.|[2311.07383v1](http://arxiv.org/abs/2311.07383v1)|null|\n", "2311.07361": "|**2023-11-13**|**The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4**|Microsoft Research AI4Science et.al.|[2311.07361v1](http://arxiv.org/abs/2311.07361v1)|null|\n", "2311.07237": "|**2023-11-13**|**In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search**|Huihan Li et.al.|[2311.07237v1](http://arxiv.org/abs/2311.07237v1)|**[link](https://github.com/ink-usc/link)**|\n", "2311.07204": "|**2023-11-13**|**On Elastic Language Models**|Chen Zhang et.al.|[2311.07204v1](http://arxiv.org/abs/2311.07204v1)|null|\n", "2311.07194": "|**2023-11-16**|**Exploring the Dialogue Comprehension Ability of Large Language Models**|Shuaijie She et.al.|[2311.07194v2](http://arxiv.org/abs/2311.07194v2)|null|\n", "2311.07138": "|**2023-11-13**|**WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models**|Shangqing Tu et.al.|[2311.07138v1](http://arxiv.org/abs/2311.07138v1)|**[link](https://github.com/THU-KEG/WaterBench)**|\n", "2311.07032": "|**2023-11-13**|**ExpNote: Black-box Large Language Models are Better Task Solvers with Experience Notebook**|Wangtao Sun et.al.|[2311.07032v1](http://arxiv.org/abs/2311.07032v1)|**[link](https://github.com/forangel2014/expnote)**|\n", "2311.06979": "|**2023-11-12**|**Assessing the Interpretability of Programmatic Policies with Large Language Models**|Zahra Bashir et.al.|[2311.06979v1](http://arxiv.org/abs/2311.06979v1)|null|\n", "2311.06899": "|**2023-11-12**|**Flames: Benchmarking Value Alignment of Chinese Large Language Models**|Kexin Huang et.al.|[2311.06899v1](http://arxiv.org/abs/2311.06899v1)|null|\n", "2311.06838": "|**2023-11-12**|**GIELLM: Japanese General Information Extraction Large Language Model Utilizing Mutual Reinforcement Effect**|Chengguang Gan et.al.|[2311.06838v1](http://arxiv.org/abs/2311.06838v1)|null|\n", "2311.06791": "|**2023-11-12**|**InfMLLM: A Unified Framework for Visual-Language Tasks**|Qiang Zhou et.al.|[2311.06791v1](http://arxiv.org/abs/2311.06791v1)|**[link](https://github.com/mightyzau/infmllm)**|\n", "2311.09243": "|**2023-11-12**|**Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling**|Yujin Cho et.al.|[2311.09243v1](http://arxiv.org/abs/2311.09243v1)|null|\n", "2311.07618": "|**2023-11-12**|**Large Language Models' Understanding of Math: Source Criticism and Extrapolation**|Roozbeh Yousefzadeh et.al.|[2311.07618v1](http://arxiv.org/abs/2311.07618v1)|null|\n", "2311.06736": "|**2023-11-12**|**Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof Generation with Contrastive Stepwise Decoding**|Ying Su et.al.|[2311.06736v1](http://arxiv.org/abs/2311.06736v1)|null|\n", "2311.06697": "|**2023-11-12**|**Trusted Source Alignment in Large Language Models**|Vasilisa Bashlovkina et.al.|[2311.06697v1](http://arxiv.org/abs/2311.06697v1)|null|\n"}}