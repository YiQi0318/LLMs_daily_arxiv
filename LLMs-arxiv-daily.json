{"LLM - Explainability": {"2311.18702": "|**2023-11-30**|**CritiqueLLM: Scaling LLM-as-Critic for Effective and Explainable Evaluation of Large Language Model Generation**|Pei Ke et.al.|[2311.18702v1](http://arxiv.org/abs/2311.18702v1)|**[link](https://github.com/thu-coai/critiquellm)**|\n", "2311.18353": "|**2023-11-30**|**Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension**|Akira Kawabata et.al.|[2311.18353v1](http://arxiv.org/abs/2311.18353v1)|null|\n", "2311.18062": "|**2023-11-29**|**Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation**|Xijia Zhang et.al.|[2311.18062v1](http://arxiv.org/abs/2311.18062v1)|null|\n", "2311.17365": "|**2023-11-29**|**Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning**|Xiaoqian Wu et.al.|[2311.17365v1](http://arxiv.org/abs/2311.17365v1)|null|\n", "2311.17331": "|**2023-11-29**|**Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**|Zeqing Wang et.al.|[2311.17331v1](http://arxiv.org/abs/2311.17331v1)|null|\n", "2311.16017": "|**2023-11-27**|**Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models**|Stephen MacNeil et.al.|[2311.16017v1](http://arxiv.org/abs/2311.16017v1)|null|\n", "2311.15716": "|**2023-11-27**|**Justifiable Artificial Intelligence: Engineering Large Language Models for Legal Applications**|Sabine Wehnert et.al.|[2311.15716v1](http://arxiv.org/abs/2311.15716v1)|null|\n", "2311.15548": "|**2023-11-27**|**Deficiency of Large Language Models in Finance: An Empirical Examination of Hallucination**|Haoqiang Kang et.al.|[2311.15548v1](http://arxiv.org/abs/2311.15548v1)|null|\n", "2311.14903": "|**2023-11-25**|**Code Generation Based Grading: Evaluating an Auto-grading Mechanism for \"Explain-in-Plain-English\" Questions**|David H. Smith IV et.al.|[2311.14903v1](http://arxiv.org/abs/2311.14903v1)|null|\n", "2311.14126": "|**2023-11-23**|**Towards Auditing Large Language Models: Improving Text-based Stereotype Detection**|Wu Zekun et.al.|[2311.14126v1](http://arxiv.org/abs/2311.14126v1)|null|\n", "2311.14061": "|**2023-11-23**|**Towards Explainable Strategy Templates using NLP Transformers**|Pallavi Bagga et.al.|[2311.14061v1](http://arxiv.org/abs/2311.14061v1)|null|\n", "2311.13160": "|**2023-11-22**|**Large Language Models in Education: Vision and Opportunities**|Wensheng Gan et.al.|[2311.13160v1](http://arxiv.org/abs/2311.13160v1)|null|\n", "2311.12338": "|**2023-11-21**|**A Survey on Large Language Models for Personalized and Explainable Recommendations**|Junyi Chen et.al.|[2311.12338v1](http://arxiv.org/abs/2311.12338v1)|null|\n", "2311.12233": "|**2023-11-20**|**Unifying Corroborative and Contributive Attributions in Large Language Models**|Theodora Worledge et.al.|[2311.12233v1](http://arxiv.org/abs/2311.12233v1)|null|\n", "2311.11904": "|**2023-11-20**|**LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions**|Songhao Han et.al.|[2311.11904v1](http://arxiv.org/abs/2311.11904v1)|null|\n", "2311.11811": "|**2023-11-20**|**Large Language Models and Explainable Law: a Hybrid Methodology**|Marco Billi et.al.|[2311.11811v1](http://arxiv.org/abs/2311.11811v1)|null|\n", "2311.11552": "|**2023-11-20**|**Exploring Prompting Large Language Models as Explainable Metrics**|Ghazaleh Mahmoudi et.al.|[2311.11552v1](http://arxiv.org/abs/2311.11552v1)|**[link](https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics)**|\n", "2311.11334": "|**2023-11-19**|**Using Causal Threads to Explain Changes in a Dynamic System**|Robert B. Allen et.al.|[2311.11334v1](http://arxiv.org/abs/2311.11334v1)|null|\n", "2311.11267": "|**2023-11-19**|**Rethinking Large Language Models in Mental Health Applications**|Shaoxiong Ji et.al.|[2311.11267v1](http://arxiv.org/abs/2311.11267v1)|null|\n", "2311.10075": "|**2023-11-16**|**ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve Health Literacy and Communication in Pediatric Populations and Beyond**|Kanhai S. Amin et.al.|[2311.10075v1](http://arxiv.org/abs/2311.10075v1)|null|\n", "2311.10054": "|**2023-11-16**|**Is \"A Helpful Assistant\" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts**|Mingqian Zheng et.al.|[2311.10054v1](http://arxiv.org/abs/2311.10054v1)|null|\n", "2311.16169": "|**2023-11-16**|**Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities**|Avishree Khare et.al.|[2311.16169v1](http://arxiv.org/abs/2311.16169v1)|null|\n", "2311.09020": "|**2023-11-15**|**Explaining Explanation: An Empirical Study on Explanation in Code Reviews**|Ratnadira Widyasari et.al.|[2311.09020v1](http://arxiv.org/abs/2311.09020v1)|null|\n", "2311.09006": "|**2023-11-15**|**Data Similarity is Not Enough to Explain Language Model Performance**|Gregory Yauney et.al.|[2311.09006v1](http://arxiv.org/abs/2311.09006v1)|**[link](https://github.com/gyauney/data-similarity-is-not-enough)**|\n", "2311.08614": "|**2023-11-15**|**XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making**|Zichen Chen et.al.|[2311.08614v1](http://arxiv.org/abs/2311.08614v1)|null|\n", "2311.08469": "|**2023-11-14**|**UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations**|Wenting Zhao et.al.|[2311.08469v1](http://arxiv.org/abs/2311.08469v1)|null|\n", "2311.08398": "|**2023-11-16**|**Are Large Language Models Temporally Grounded?**|Yifu Qiu et.al.|[2311.08398v2](http://arxiv.org/abs/2311.08398v2)|**[link](https://github.com/yfqiu-nlp/temporal-llms)**|\n", "2311.07811": "|**2023-11-13**|**In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax**|Aaron Mueller et.al.|[2311.07811v1](http://arxiv.org/abs/2311.07811v1)|**[link](https://github.com/aaronmueller/syntax-icl)**|\n", "2311.07466": "|**2023-11-13**|**On Measuring Faithfulness of Natural Language Explanations**|Letitia Parcalabescu et.al.|[2311.07466v1](http://arxiv.org/abs/2311.07466v1)|**[link](https://github.com/heidelberg-nlp/cc-shap)**|\n", "2311.06985": "|**2023-11-12**|**SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves**|Jiachen Zhao et.al.|[2311.06985v1](http://arxiv.org/abs/2311.06985v1)|null|\n", "2311.06383": "|**2023-11-10**|**Distilling Large Language Models using Skill-Occupation Graph Context for HR-Related Tasks**|Pouya Pezeshkpour et.al.|[2311.06383v1](http://arxiv.org/abs/2311.06383v1)|**[link](https://github.com/megagonlabs/rjdb)**|\n", "2311.14703": "|**2023-11-10**|**ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management**|Angela Zhang et.al.|[2311.14703v1](http://arxiv.org/abs/2311.14703v1)|null|\n", "2311.05019": "|**2023-11-08**|**DEMASQ: Unmasking the ChatGPT Wordsmith**|Kavita Kumari et.al.|[2311.05019v1](http://arxiv.org/abs/2311.05019v1)|null|\n", "2311.04047": "|**2023-11-07**|**Extracting human interpretable structure-property relationships in chemistry using XAI and large language models**|Geemi P. Wellawatte et.al.|[2311.04047v1](http://arxiv.org/abs/2311.04047v1)|**[link](https://github.com/geemi725/xpertai)**|\n", "2311.03754": "|**2023-11-07**|**Which is better? Exploring Prompting Strategy For LLM-based Metrics**|Joonghoon Kim et.al.|[2311.03754v1](http://arxiv.org/abs/2311.03754v1)|**[link](https://github.com/SeoroMin/Prompt4LLM-Eval)**|\n", "2311.03734": "|**2023-11-07**|**Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning**|Ruosen Li et.al.|[2311.03734v1](http://arxiv.org/abs/2311.03734v1)|**[link](https://github.com/bcdnlp/structure-qa)**|\n", "2311.02433": "|**2023-11-04**|**Can ChatGPT support software verification?**|Christian Jan\u00dfen et.al.|[2311.02433v1](http://arxiv.org/abs/2311.02433v1)|null|\n", "2311.01732": "|**2023-11-12**|**Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models**|Sean Xie et.al.|[2311.01732v2](http://arxiv.org/abs/2311.01732v2)|**[link](https://github.com/yx131/proto-lm)**|\n", "2311.04911": "|**2023-11-01**|**From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems**|Samyar Janatian et.al.|[2311.04911v1](http://arxiv.org/abs/2311.04911v1)|**[link](https://github.com/samyarj/jcapg-jurix2023)**|\n", "2311.00671": "|**2023-11-01**|**Emotion Detection for Misinformation: A Review**|Zhiwei Liu et.al.|[2311.00671v1](http://arxiv.org/abs/2311.00671v1)|null|\n", "2311.00321": "|**2023-11-22**|**HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning**|Yongjin Yang et.al.|[2311.00321v2](http://arxiv.org/abs/2311.00321v2)|**[link](https://github.com/joonkeekim/hare-hate-speech)**|\n", "2311.00206": "|**2023-11-01**|**ChatGPT-Powered Hierarchical Comparisons for Image Classification**|Zhiyuan Ren et.al.|[2311.00206v1](http://arxiv.org/abs/2311.00206v1)|null|\n", "2310.20689": "|**2023-11-14**|**Learning From Mistakes Makes LLM Better Reasoner**|Shengnan An et.al.|[2310.20689v2](http://arxiv.org/abs/2310.20689v2)|**[link](https://github.com/microsoft/lema)**|\n", "2310.20320": "|**2023-10-31**|**Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests**|Max J. van Duijn et.al.|[2310.20320v1](http://arxiv.org/abs/2310.20320v1)|null|\n", "2310.19792": "|**2023-10-30**|**The Eval4NLP 2023 Shared Task on Prompting Large Language Models as Explainable Metrics**|Christoph Leiter et.al.|[2310.19792v1](http://arxiv.org/abs/2310.19792v1)|**[link](https://github.com/eval4nlp/sharedtask2023)**|\n", "2310.19658": "|**2023-10-30**|**Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection**|Noah Ziems et.al.|[2310.19658v1](http://arxiv.org/abs/2310.19658v1)|null|\n", "2310.18813": "|**2023-10-28**|**The Synergy of Speculative Decoding and Batching in Serving Large Language Models**|Qidong Su et.al.|[2310.18813v1](http://arxiv.org/abs/2310.18813v1)|null|\n", "2310.17217": "|**2023-10-26**|**Beyond MLE: Convex Learning for Text Generation**|Chenze Shao et.al.|[2310.17217v1](http://arxiv.org/abs/2310.17217v1)|null|\n", "2310.18233": "|**2023-11-01**|**Will releasing the weights of future large language models grant widespread access to pandemic agents?**|Anjali Gopal et.al.|[2310.18233v2](http://arxiv.org/abs/2310.18233v2)|null|\n", "2310.16436": "|**2023-10-26**|**DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models**|Ge Zheng et.al.|[2310.16436v2](http://arxiv.org/abs/2310.16436v2)|null|\n", "2310.16421": "|**2023-10-25**|**Graph Agent: Explicit Reasoning Agent for Graphs**|Qinyong Wang et.al.|[2310.16421v1](http://arxiv.org/abs/2310.16421v1)|null|\n", "2310.15455": "|**2023-10-24**|**UI Layout Generation with LLMs Guided by UI Grammar**|Yuwen Lu et.al.|[2310.15455v1](http://arxiv.org/abs/2310.15455v1)|null|\n", "2310.14389": "|**2023-10-22**|**Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models**|Hongli Zhan et.al.|[2310.14389v1](http://arxiv.org/abs/2310.14389v1)|**[link](https://github.com/honglizhan/covidet-appraisals-public)**|\n", "2310.14325": "|**2023-10-22**|**Towards Harmful Erotic Content Detection through Coreference-Driven Contextual Analysis**|Inez Okulska et.al.|[2310.14325v1](http://arxiv.org/abs/2310.14325v1)|null|\n", "2310.14025": "|**2023-10-21**|**Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation**|Anastasia Kritharoula et.al.|[2310.14025v1](http://arxiv.org/abs/2310.14025v1)|**[link](https://github.com/anastasiakrith/multimodal-retrieval-for-vwsd)**|\n", "2310.13850": "|**2023-10-20**|**Ecologically Valid Explanations for Label Variation in NLI**|Nan-Jiang Jiang et.al.|[2310.13850v1](http://arxiv.org/abs/2310.13850v1)|**[link](https://github.com/njjiang/livenli)**|\n", "2310.13571": "|**2023-10-30**|**Why Can Large Language Models Generate Correct Chain-of-Thoughts?**|Rasul Tutunov et.al.|[2310.13571v2](http://arxiv.org/abs/2310.13571v2)|null|\n", "2310.13549": "|**2023-10-20**|**The Perils & Promises of Fact-checking with Large Language Models**|Dorian Quelle et.al.|[2310.13549v1](http://arxiv.org/abs/2310.13549v1)|null|\n", "2310.13506": "|**2023-10-20**|**Explaining Interactions Between Text Spans**|Sagnik Ray Choudhury et.al.|[2310.13506v1](http://arxiv.org/abs/2310.13506v1)|**[link](https://github.com/copenlu/spanex)**|\n", "2310.12973": "|**2023-10-19**|**Frozen Transformers in Language Models Are Effective Visual Encoder Layers**|Ziqi Pang et.al.|[2310.12973v1](http://arxiv.org/abs/2310.12973v1)|**[link](https://github.com/ziqipang/lm4visualencoding)**|\n", "2310.12860": "|**2023-10-28**|**Probing LLMs for hate speech detection: strengths and vulnerabilities**|Sarthak Roy et.al.|[2310.12860v2](http://arxiv.org/abs/2310.12860v2)|null|\n", "2310.12558": "|**2023-10-19**|**Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong**|Chenglei Si et.al.|[2310.12558v1](http://arxiv.org/abs/2310.12558v1)|null|\n", "2310.11207": "|**2023-10-17**|**Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations**|Shiyuan Huang et.al.|[2310.11207v1](http://arxiv.org/abs/2310.11207v1)|null|\n", "2310.10418": "|**2023-11-11**|**Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms**|Seungju Han et.al.|[2310.10418v2](http://arxiv.org/abs/2310.10418v2)|**[link](https://github.com/wade3han/normlens)**|\n", "2310.09754": "|**2023-10-15**|**EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification**|Huanhuan Ma et.al.|[2310.09754v1](http://arxiv.org/abs/2310.09754v1)|**[link](https://github.com/dependentsign/EX-FEVER)**|\n", "2310.08797": "|**2023-10-13**|**A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models**|Takuma Udagawa et.al.|[2310.08797v1](http://arxiv.org/abs/2310.08797v1)|null|\n", "2310.08744": "|**2023-10-12**|**Circuit Component Reuse Across Tasks in Transformer Language Models**|Jack Merullo et.al.|[2310.08744v1](http://arxiv.org/abs/2310.08744v1)|null|\n", "2310.08123": "|**2023-10-12**|**Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification**|Chia-Yu Hung et.al.|[2310.08123v1](http://arxiv.org/abs/2310.08123v1)|null|\n", "2310.07984": "|**2023-10-12**|**Large Language Models for Scientific Synthesis, Inference and Explanation**|Yizhen Zheng et.al.|[2310.07984v1](http://arxiv.org/abs/2310.07984v1)|**[link](https://github.com/zyzisastudyreallyhardguy/llm4sd)**|\n", "2310.07820": "|**2023-10-11**|**Large Language Models Are Zero-Shot Time Series Forecasters**|Nate Gruver et.al.|[2310.07820v1](http://arxiv.org/abs/2310.07820v1)|null|\n", "2310.06680": "|**2023-10-10**|**Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach**|Zhenlan Ji et.al.|[2310.06680v1](http://arxiv.org/abs/2310.06680v1)|null|\n", "2310.06257": "|**2023-10-10**|**SCAR: Power Side-Channel Analysis at RTL-Level**|Amisha Srivastava et.al.|[2310.06257v1](http://arxiv.org/abs/2310.06257v1)|null|\n", "2310.06200": "|**2023-10-11**|**The Importance of Prompt Tuning for Automated Neuron Explanations**|Justin Lee et.al.|[2310.06200v2](http://arxiv.org/abs/2310.06200v2)|null|\n", "2310.05884": "|**2023-10-09**|**A Meta-Learning Perspective on Transformers for Causal Language Modeling**|Xinbo Wu et.al.|[2310.05884v1](http://arxiv.org/abs/2310.05884v1)|null|\n", "2310.05797": "|**2023-10-10**|**Are Large Language Models Post Hoc Explainers?**|Nicholas Kroeger et.al.|[2310.05797v2](http://arxiv.org/abs/2310.05797v2)|**[link](https://github.com/AI4LIFE-GROUP/LLM_Explainer)**|\n", "2310.05657": "|**2023-10-09**|**A Closer Look into Automatic Evaluation Using Large Language Models**|Cheng-Han Chiang et.al.|[2310.05657v1](http://arxiv.org/abs/2310.05657v1)|**[link](https://github.com/d223302/a-closer-look-to-llm-evaluation)**|\n", "2310.05452": "|**2023-10-09**|**Explaining the Complex Task Reasoning of Large Language Models with Template-Content Structure**|Haotong Yang et.al.|[2310.05452v1](http://arxiv.org/abs/2310.05452v1)|null|\n", "2310.05253": "|**2023-10-20**|**Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models**|Haoran Wang et.al.|[2310.05253v2](http://arxiv.org/abs/2310.05253v2)|**[link](https://github.com/wang2226/folk)**|\n", "2310.05209": "|**2023-10-08**|**Scaling Laws of RoPE-based Extrapolation**|Xiaoran Liu et.al.|[2310.05209v1](http://arxiv.org/abs/2310.05209v1)|null|\n", "2310.05046": "|**2023-10-08**|**Harnessing the Power of ChatGPT in Fake News: An In-Depth Exploration in Generation, Detection and Explanation**|Yue Huang et.al.|[2310.05046v1](http://arxiv.org/abs/2310.05046v1)|null|\n", "2310.05029": "|**2023-10-08**|**Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading**|Howard Chen et.al.|[2310.05029v1](http://arxiv.org/abs/2310.05029v1)|null|\n", "2310.04949": "|**2023-10-08**|**Domain Knowledge Graph Construction Via A Simple Checker**|Yueling Zeng et.al.|[2310.04949v1](http://arxiv.org/abs/2310.04949v1)|null|\n", "2310.04793": "|**2023-11-11**|**FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets**|Neng Wang et.al.|[2310.04793v2](http://arxiv.org/abs/2310.04793v2)|**[link](https://github.com/ai4finance-foundation/fingpt)**|\n", "2310.02439": "|**2023-10-03**|**Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions**|Naiming Liu et.al.|[2310.02439v1](http://arxiv.org/abs/2310.02439v1)|null|\n", "2310.01957": "|**2023-10-13**|**Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving**|Long Chen et.al.|[2310.01957v2](http://arxiv.org/abs/2310.01957v2)|**[link](https://github.com/wayveai/driving-with-llms)**|\n", "2310.01870": "|**2023-11-28**|**DeepDecipher: Accessing and Investigating Neuron Activation in Large Language Models**|Albert Garde et.al.|[2310.01870v2](http://arxiv.org/abs/2310.01870v2)|**[link](https://github.com/apartresearch/deepdecipher)**|\n", "2310.01132": "|**2023-10-02**|**Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback**|Jacob Whitehill et.al.|[2310.01132v1](http://arxiv.org/abs/2310.01132v1)|null|\n", "2310.01074": "|**2023-10-08**|**Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models**|Chenhan Yuan et.al.|[2310.01074v2](http://arxiv.org/abs/2310.01074v2)|**[link](https://github.com/chenhan97/timellama)**|\n", "2310.00647": "|**2023-10-01**|**Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning**|Mustafa Shukor et.al.|[2310.00647v1](http://arxiv.org/abs/2310.00647v1)|**[link](https://github.com/mshukor/EvALign-ICL)**|\n", "2310.00603": "|**2023-11-22**|**Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals**|Yair Gat et.al.|[2310.00603v2](http://arxiv.org/abs/2310.00603v2)|null|\n", "2310.01441": "|**2023-09-30**|**UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities**|Hejia Geng et.al.|[2310.01441v1](http://arxiv.org/abs/2310.01441v1)|null|\n", "2309.17057": "|**2023-09-29**|**Tell Me a Story! Narrative-Driven XAI with Large Language Models**|David Martens et.al.|[2309.17057v1](http://arxiv.org/abs/2309.17057v1)|**[link](https://github.com/admantwerp/xaistories)**|\n", "2309.16146": "|**2023-09-28**|**T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems**|Ming Wang et.al.|[2309.16146v1](http://arxiv.org/abs/2309.16146v1)|**[link](https://github.com/neu-datamining/t-col)**|\n", "2309.16090": "|**2023-09-28**|**TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration**|Hongru Wang et.al.|[2309.16090v1](http://arxiv.org/abs/2309.16090v1)|null|\n", "2309.16021": "|**2023-09-27**|**HuntGPT: Integrating Machine Learning-Based Anomaly Detection and Explainable AI with Large Language Models (LLMs)**|Tarek Ali et.al.|[2309.16021v1](http://arxiv.org/abs/2309.16021v1)|null|\n", "2309.15729": "|**2023-09-27**|**MindGPT: Interpreting What You See with Non-invasive Brain Recordings**|Jiaxuan Chen et.al.|[2309.15729v1](http://arxiv.org/abs/2309.15729v1)|**[link](https://github.com/jxuanc/mindgpt)**|\n", "2311.01463": "|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|\n", "2309.13340": "|**2023-09-23**|**LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain Black-box Text Classifiers?**|Amrita Bhattacharjee et.al.|[2309.13340v1](http://arxiv.org/abs/2309.13340v1)|null|\n", "2309.11805": "|**2023-09-21**|**JobRecoGPT -- Explainable job recommendations using LLMs**|Preetam Ghosh et.al.|[2309.11805v1](http://arxiv.org/abs/2309.11805v1)|null|\n", "2309.11439": "|**2023-09-20**|**Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction**|Masahiro Kaneko et.al.|[2309.11439v1](http://arxiv.org/abs/2309.11439v1)|**[link](https://github.com/kanekomasahiro/gec-explanation)**|\n"}, "LLM - Interpretability": {"2311.18836": "|**2023-11-30**|**PoseGPT: Chatting about 3D Human Pose**|Yao Feng et.al.|[2311.18836v1](http://arxiv.org/abs/2311.18836v1)|null|\n", "2311.18775": "|**2023-11-30**|**CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation**|Zineng Tang et.al.|[2311.18775v1](http://arxiv.org/abs/2311.18775v1)|null|\n", "2311.18743": "|**2023-11-30**|**AlignBench: Benchmarking Chinese Alignment of Large Language Models**|Xiao Liu et.al.|[2311.18743v1](http://arxiv.org/abs/2311.18743v1)|**[link](https://github.com/thudm/alignbench)**|\n", "2311.18307": "|**2023-11-30**|**Categorical Traffic Transformer: Interpretable and Diverse Behavior Prediction with Tokenized Latent**|Yuxiao Chen et.al.|[2311.18307v1](http://arxiv.org/abs/2311.18307v1)|null|\n", "2311.18034": "|**2023-11-29**|**Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings**|Andrea W Wen-Yi et.al.|[2311.18034v1](http://arxiv.org/abs/2311.18034v1)|**[link](https://github.com/andreawwenyi/hyperpolyglot)**|\n", "2311.17647": "|**2023-11-29**|**VIM: Probing Multimodal Large Language Models for Visual Embedded Instruction Following**|Yujie Lu et.al.|[2311.17647v1](http://arxiv.org/abs/2311.17647v1)|null|\n", "2311.17351": "|**2023-11-29**|**Exploring Large Language Models for Human Mobility Prediction under Public Events**|Yuebing Liang et.al.|[2311.17351v1](http://arxiv.org/abs/2311.17351v1)|null|\n", "2311.17331": "|**2023-11-29**|**Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**|Zeqing Wang et.al.|[2311.17331v1](http://arxiv.org/abs/2311.17331v1)|null|\n", "2311.17937": "|**2023-11-28**|**Unlocking Spatial Comprehension in Text-to-Image Diffusion Models**|Mohammad Mahdi Derakhshani et.al.|[2311.17937v1](http://arxiv.org/abs/2311.17937v1)|null|\n", "2311.17002": "|**2023-11-30**|**Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following**|Yutong Feng et.al.|[2311.17002v2](http://arxiv.org/abs/2311.17002v2)|null|\n", "2311.17126": "|**2023-11-28**|**Reason out Your Layout: Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis**|Xiaohui Chen et.al.|[2311.17126v1](http://arxiv.org/abs/2311.17126v1)|null|\n", "2311.16509": "|**2023-11-28**|**StyleCap: Automatic Speaking-Style Captioning from Speech Based on Speech and Language Self-supervised Learning Models**|Kazuki Yamauchi et.al.|[2311.16509v1](http://arxiv.org/abs/2311.16509v1)|null|\n", "2311.16093": "|**2023-11-27**|**Have we built machines that think like people?**|Luca M. Schulze Buschoff et.al.|[2311.16093v1](http://arxiv.org/abs/2311.16093v1)|**[link](https://github.com/lsbuschoff/multimodal)**|\n", "2311.16017": "|**2023-11-27**|**Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models**|Stephen MacNeil et.al.|[2311.16017v1](http://arxiv.org/abs/2311.16017v1)|null|\n", "2311.15983": "|**2023-11-27**|**Sparsify-then-Classify: From Internal Neurons of Large Language Models To Efficient Text Classifiers**|Yilun Liu et.al.|[2311.15983v1](http://arxiv.org/abs/2311.15983v1)|**[link](https://github.com/difanj0713/sparsify-then-classify)**|\n", "2311.16483": "|**2023-11-27**|**ChartLlama: A Multimodal LLM for Chart Understanding and Generation**|Yucheng Han et.al.|[2311.16483v1](http://arxiv.org/abs/2311.16483v1)|null|\n", "2311.16500": "|**2023-11-27**|**LLMGA: Multimodal Large Language Model based Generation Assistant**|Bin Xia et.al.|[2311.16500v1](http://arxiv.org/abs/2311.16500v1)|null|\n", "2311.15585": "|**2023-11-27**|**Dawning of a New Era in Gravitational Wave Data Analysis: Unveiling Cosmic Mysteries via Artificial Intelligence -- A Systematic Review**|Tianyu Zhao et.al.|[2311.15585v1](http://arxiv.org/abs/2311.15585v1)|null|\n", "2311.15209": "|**2023-11-26**|**See and Think: Embodied Agent in Virtual Environment**|Zhonghan Zhao et.al.|[2311.15209v1](http://arxiv.org/abs/2311.15209v1)|null|\n", "2311.15131": "|**2023-11-25**|**Localizing Lying in Llama: Understanding Instructed Dishonesty on True-False Questions Through Prompting, Probing, and Patching**|James Campbell et.al.|[2311.15131v1](http://arxiv.org/abs/2311.15131v1)|null|\n", "2311.14519": "|**2023-11-24**|**Benchmarking Large Language Models for Log Analysis, Security, and Interpretation**|Egil Karlsen et.al.|[2311.14519v1](http://arxiv.org/abs/2311.14519v1)|null|\n", "2311.14115": "|**2023-11-23**|**A density estimation perspective on learning from pairwise human preferences**|Vincent Dumoulin et.al.|[2311.14115v1](http://arxiv.org/abs/2311.14115v1)|null|\n", "2311.14061": "|**2023-11-23**|**Towards Explainable Strategy Templates using NLP Transformers**|Pallavi Bagga et.al.|[2311.14061v1](http://arxiv.org/abs/2311.14061v1)|null|\n", "2311.13857": "|**2023-11-23**|**Challenges of Large Language Models for Mental Health Counseling**|Neo Christopher Chung et.al.|[2311.13857v1](http://arxiv.org/abs/2311.13857v1)|null|\n", "2311.13743": "|**2023-11-23**|**FinMe: A Performance-Enhanced Large Language Model Trading Agent with Layered Memory and Character Design**|Yangyang Yu et.al.|[2311.13743v1](http://arxiv.org/abs/2311.13743v1)|**[link](https://github.com/pipiku915/FinMem-LLM-StockTrading/blob/main/README.md)**|\n", "2311.13549": "|**2023-11-22**|**ADriver-I: A General World Model for Autonomous Driving**|Fan Jia et.al.|[2311.13549v1](http://arxiv.org/abs/2311.13549v1)|null|\n", "2311.13627": "|**2023-11-22**|**Vamos: Versatile Action Models for Video Understanding**|Shijie Wang et.al.|[2311.13627v1](http://arxiv.org/abs/2311.13627v1)|null|\n", "2311.13194": "|**2023-11-22**|**Towards Improving Document Understanding: An Exploration on Text-Grounding via MLLMs**|Yonghui Wang et.al.|[2311.13194v1](http://arxiv.org/abs/2311.13194v1)|null|\n", "2311.13063": "|**2023-11-25**|**From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models**|Zachary Englhardt et.al.|[2311.13063v2](http://arxiv.org/abs/2311.13063v2)|null|\n", "2311.12524": "|**2023-11-21**|**ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models**|Jiankai Tang et.al.|[2311.12524v1](http://arxiv.org/abs/2311.12524v1)|**[link](https://github.com/mcjacktang/llm-healthassistant)**|\n", "2311.12287": "|**2023-11-21**|**Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications**|Samira Ghodratnama et.al.|[2311.12287v1](http://arxiv.org/abs/2311.12287v1)|null|\n", "2311.11797": "|**2023-11-20**|**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**|Zhuosheng Zhang et.al.|[2311.11797v1](http://arxiv.org/abs/2311.11797v1)|**[link](https://github.com/zoeyyao27/cot-igniting-agent)**|\n", "2311.11628": "|**2023-11-20**|**Incorporating LLM Priors into Tabular Learners**|Max Zhu et.al.|[2311.11628v1](http://arxiv.org/abs/2311.11628v1)|null|\n", "2311.11516": "|**2023-11-20**|**GPT in Data Science: A Practical Exploration of Model Selection**|Nathalia Nascimento et.al.|[2311.11516v1](http://arxiv.org/abs/2311.11516v1)|null|\n", "2311.11482": "|**2023-11-20**|**Meta Prompting for AGI Systems**|Yifan Zhang et.al.|[2311.11482v1](http://arxiv.org/abs/2311.11482v1)|**[link](https://github.com/meta-prompting/meta-prompting)**|\n", "2311.14722": "|**2023-11-19**|**Zero-Shot Question Answering over Financial Documents using Large Language Models**|Karmvir Singh Phogat et.al.|[2311.14722v1](http://arxiv.org/abs/2311.14722v1)|null|\n", "2311.11267": "|**2023-11-19**|**Rethinking Large Language Models in Mental Health Applications**|Shaoxiong Ji et.al.|[2311.11267v1](http://arxiv.org/abs/2311.11267v1)|null|\n", "2311.11012": "|**2023-11-18**|**Bit Cipher -- A Simple yet Powerful Word Representation System that Integrates Efficiently with Language Models**|Haoran Zhao et.al.|[2311.11012v1](http://arxiv.org/abs/2311.11012v1)|null|\n", "2311.10947": "|**2023-11-18**|**RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**|Yuxuan Lei et.al.|[2311.10947v1](http://arxiv.org/abs/2311.10947v1)|null|\n", "2311.10905": "|**2023-11-17**|**Flexible Model Interpretability through Natural Language Model Editing**|Karel D'Oosterlinck et.al.|[2311.10905v1](http://arxiv.org/abs/2311.10905v1)|null|\n", "2311.10813": "|**2023-11-27**|**A Language Agent for Autonomous Driving**|Jiageng Mao et.al.|[2311.10813v3](http://arxiv.org/abs/2311.10813v3)|**[link](https://github.com/usc-gvl/agent-driver)**|\n", "2311.10537": "|**2023-11-16**|**MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning**|Xiangru Tang et.al.|[2311.10537v1](http://arxiv.org/abs/2311.10537v1)|**[link](https://github.com/gersteinlab/medagents)**|\n", "2311.09796": "|**2023-11-16**|**Interpreting User Requests in the Context of Natural Language Standing Instructions**|Nikita Moghe et.al.|[2311.09796v1](http://arxiv.org/abs/2311.09796v1)|null|\n", "2311.09721": "|**2023-11-16**|**On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering**|Linyong Nan et.al.|[2311.09721v1](http://arxiv.org/abs/2311.09721v1)|null|\n", "2311.09635": "|**2023-11-16**|**Evaluating In-Context Learning of Libraries for Code Generation**|Arkil Patel et.al.|[2311.09635v1](http://arxiv.org/abs/2311.09635v1)|null|\n", "2311.09612": "|**2023-11-16**|**Efficient End-to-End Visual Document Understanding with Rationale Distillation**|Wang Zhu et.al.|[2311.09612v1](http://arxiv.org/abs/2311.09612v1)|null|\n", "2311.09558": "|**2023-11-16**|**Pachinko: Patching Interpretable QA Models through Natural Language Feedback**|Chaitanya Malaviya et.al.|[2311.09558v1](http://arxiv.org/abs/2311.09558v1)|**[link](https://github.com/chaitanyamalaviya/pachinko)**|\n", "2311.10774": "|**2023-11-15**|**MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning**|Fuxiao Liu et.al.|[2311.10774v1](http://arxiv.org/abs/2311.10774v1)|**[link](https://github.com/fuxiaoliu/mmc)**|\n", "2311.09206": "|**2023-11-15**|**TableLlama: Towards Open Large Generalist Models for Tables**|Tianshu Zhang et.al.|[2311.09206v1](http://arxiv.org/abs/2311.09206v1)|null|\n", "2311.09033": "|**2023-11-15**|**MELA: Multilingual Evaluation of Linguistic Acceptability**|Ziyin Zhang et.al.|[2311.09033v1](http://arxiv.org/abs/2311.09033v1)|null|\n", "2311.08968": "|**2023-11-15**|**Identifying Linear Relational Concepts in Large Language Models**|David Chanin et.al.|[2311.08968v1](http://arxiv.org/abs/2311.08968v1)|null|\n", "2311.08957": "|**2023-11-15**|**I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots**|Giulio Antonio Abbo et.al.|[2311.08957v1](http://arxiv.org/abs/2311.08957v1)|null|\n", "2311.08896": "|**2023-11-15**|**HELLaMA: LLaMA-based Table to Text Generation by Highlighting the Important Evidence**|Junyi Bian et.al.|[2311.08896v1](http://arxiv.org/abs/2311.08896v1)|null|\n", "2311.08723": "|**2023-11-15**|**Token Prediction as Implicit Classification to Identify LLM-Generated Text**|Yutian Chen et.al.|[2311.08723v1](http://arxiv.org/abs/2311.08723v1)|**[link](https://github.com/markchenyutian/t5-sentinel-public)**|\n", "2311.08718": "|**2023-11-15**|**Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling**|Bairu Hou et.al.|[2311.08718v1](http://arxiv.org/abs/2311.08718v1)|null|\n", "2311.08614": "|**2023-11-15**|**XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making**|Zichen Chen et.al.|[2311.08614v1](http://arxiv.org/abs/2311.08614v1)|null|\n", "2311.08605": "|**2023-11-15**|**Navigating the Ocean of Biases: Political Bias Attribution in Language Models via Causal Structures**|David F. Jenny et.al.|[2311.08605v1](http://arxiv.org/abs/2311.08605v1)|**[link](https://github.com/david-jenny/llm-political-study)**|\n", "2311.08576": "|**2023-11-14**|**Towards Evaluating AI Systems for Moral Status Using Self-Reports**|Ethan Perez et.al.|[2311.08576v1](http://arxiv.org/abs/2311.08576v1)|null|\n", "2311.08535": "|**2023-11-14**|**Taxonomy, Semantic Data Schema, and Schema Alignment for Open Data in Urban Building Energy Modeling**|Liang Zhang et.al.|[2311.08535v1](http://arxiv.org/abs/2311.08535v1)|null|\n", "2311.08364": "|**2023-11-14**|**Plum: Prompt Learning using Metaheuristic**|Rui Pan et.al.|[2311.08364v1](http://arxiv.org/abs/2311.08364v1)|**[link](https://github.com/research4pan/plum)**|\n", "2311.08206": "|**2023-11-14**|**Human-Centric Autonomous Systems With LLMs for User Command Reasoning**|Yi Yang et.al.|[2311.08206v1](http://arxiv.org/abs/2311.08206v1)|**[link](https://github.com/kth-rpl/drivecmd_llm)**|\n", "2311.07532": "|**2023-11-13**|**It's Not Easy Being Wrong: Evaluating Process of Elimination Reasoning in Large Language Models**|Nishant Balepur et.al.|[2311.07532v1](http://arxiv.org/abs/2311.07532v1)|**[link](https://github.com/nbalepur/poe)**|\n", "2311.07470": "|**2023-11-13**|**Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer**|Haowen Pan et.al.|[2311.07470v1](http://arxiv.org/abs/2311.07470v1)|null|\n", "2311.07466": "|**2023-11-13**|**On Measuring Faithfulness of Natural Language Explanations**|Letitia Parcalabescu et.al.|[2311.07466v1](http://arxiv.org/abs/2311.07466v1)|**[link](https://github.com/heidelberg-nlp/cc-shap)**|\n", "2311.07314": "|**2023-11-13**|**Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models**|Junpeng Li et.al.|[2311.07314v1](http://arxiv.org/abs/2311.07314v1)|null|\n", "2311.06979": "|**2023-11-12**|**Assessing the Interpretability of Programmatic Policies with Large Language Models**|Zahra Bashir et.al.|[2311.06979v1](http://arxiv.org/abs/2311.06979v1)|null|\n", "2311.06957": "|**2023-11-12**|**Simulating Public Administration Crisis: A Novel Generative Agent-Based Simulation System to Lower Technology Barriers in Social Science Research**|Bushi Xiao et.al.|[2311.06957v1](http://arxiv.org/abs/2311.06957v1)|null|\n", "2311.07605": "|**2023-11-11**|**Conceptual Model Interpreter for Large Language Models**|Felix H\u00e4rer et.al.|[2311.07605v1](http://arxiv.org/abs/2311.07605v1)|**[link](https://github.com/fhaer/llm-cmi)**|\n", "2311.06390": "|**2023-11-10**|**ChatGPT in the context of precision agriculture data analytics**|Ilyas Potamitis et.al.|[2311.06390v1](http://arxiv.org/abs/2311.06390v1)|**[link](https://github.com/potamitis123/chatgpt-in-the-context-of-precision-agriculture-data-analytics)**|\n", "2311.05754": "|**2023-11-09**|**Deep Natural Language Feature Learning for Interpretable Prediction**|Felipe Urrutia et.al.|[2311.05754v1](http://arxiv.org/abs/2311.05754v1)|**[link](https://github.com/furrutiav/nllf-emnlp-2023)**|\n", "2311.05297": "|**2023-11-09**|**Do personality tests generalize to Large Language Models?**|Florian E. Dorner et.al.|[2311.05297v1](http://arxiv.org/abs/2311.05297v1)|null|\n", "2311.09241": "|**2023-11-09**|**Chain of Images for Intuitively Reasoning**|Fanxu Meng et.al.|[2311.09241v1](http://arxiv.org/abs/2311.09241v1)|**[link](https://github.com/graphpku/coi)**|\n", "2311.04886": "|**2023-11-08**|**SEMQA: Semi-Extractive Multi-Source Question Answering**|Tal Schuster et.al.|[2311.04886v1](http://arxiv.org/abs/2311.04886v1)|**[link](https://github.com/google-research-datasets/quotesum)**|\n", "2311.04348": "|**2023-11-07**|**Evaluating the Effectiveness of Retrieval-Augmented Large Language Models in Scientific Document Reasoning**|Sai Munikoti et.al.|[2311.04348v1](http://arxiv.org/abs/2311.04348v1)|null|\n", "2311.04205": "|**2023-11-07**|**Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves**|Yihe Deng et.al.|[2311.04205v1](http://arxiv.org/abs/2311.04205v1)|**[link](https://github.com/uclaml/Rephrase-and-Respond)**|\n", "2311.04166": "|**2023-11-07**|**Perturbed examples reveal invariances shared by language models**|Ruchit Rawal et.al.|[2311.04166v1](http://arxiv.org/abs/2311.04166v1)|null|\n", "2311.04047": "|**2023-11-07**|**Extracting human interpretable structure-property relationships in chemistry using XAI and large language models**|Geemi P. Wellawatte et.al.|[2311.04047v1](http://arxiv.org/abs/2311.04047v1)|**[link](https://github.com/geemi725/xpertai)**|\n", "2311.03799": "|**2023-11-07**|**Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models**|Yichao Cao et.al.|[2311.03799v1](http://arxiv.org/abs/2311.03799v1)|**[link](https://github.com/caoyichao/unihoi)**|\n", "2311.03734": "|**2023-11-07**|**Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning**|Ruosen Li et.al.|[2311.03734v1](http://arxiv.org/abs/2311.03734v1)|**[link](https://github.com/bcdnlp/structure-qa)**|\n", "2311.03658": "|**2023-11-07**|**The Linear Representation Hypothesis and the Geometry of Large Language Models**|Kiho Park et.al.|[2311.03658v1](http://arxiv.org/abs/2311.03658v1)|**[link](https://github.com/kihopark/linear_rep_geometry)**|\n", "2311.03033": "|**2023-11-06**|**Beyond Words: A Mathematical Framework for Interpreting Large Language Models**|Javier Gonz\u00e1lez et.al.|[2311.03033v1](http://arxiv.org/abs/2311.03033v1)|null|\n", "2311.02807": "|**2023-11-06**|**QualEval: Qualitative Evaluation for Model Improvement**|Vishvak Murahari et.al.|[2311.02807v1](http://arxiv.org/abs/2311.02807v1)|**[link](https://github.com/vmurahari3/qualeval)**|\n", "2311.01964": "|**2023-11-03**|**Don't Make Your LLM an Evaluation Benchmark Cheater**|Kun Zhou et.al.|[2311.01964v1](http://arxiv.org/abs/2311.01964v1)|null|\n", "2311.01825": "|**2023-11-06**|**Large Language Models to the Rescue: Reducing the Complexity in Scientific Workflow Development Using ChatGPT**|Mario S\u00e4nger et.al.|[2311.01825v2](http://arxiv.org/abs/2311.01825v2)|null|\n", "2311.01732": "|**2023-11-12**|**Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models**|Sean Xie et.al.|[2311.01732v2](http://arxiv.org/abs/2311.01732v2)|**[link](https://github.com/yx131/proto-lm)**|\n", "2311.01449": "|**2023-11-02**|**TopicGPT: A Prompt-based Topic Modeling Framework**|Chau Minh Pham et.al.|[2311.01449v1](http://arxiv.org/abs/2311.01449v1)|**[link](https://github.com/chtmp223/topicgpt)**|\n", "2311.01403": "|**2023-11-02**|**REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots**|Andrea Tagliabue et.al.|[2311.01403v1](http://arxiv.org/abs/2311.01403v1)|null|\n", "2311.01150": "|**2023-11-02**|**Revisiting the Knowledge Injection Frameworks**|Peng Fu et.al.|[2311.01150v1](http://arxiv.org/abs/2311.01150v1)|null|\n", "2311.01011": "|**2023-11-02**|**Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game**|Sam Toyer et.al.|[2311.01011v1](http://arxiv.org/abs/2311.01011v1)|null|\n", "2311.00967": "|**2023-11-02**|**Vision-Language Interpreter for Robot Task Planning**|Keisuke Shirai et.al.|[2311.00967v1](http://arxiv.org/abs/2311.00967v1)|**[link](https://github.com/omron-sinicx/vilain)**|\n", "2311.04915": "|**2023-11-02**|**Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models**|Yoon Kyung Lee et.al.|[2311.04915v1](http://arxiv.org/abs/2311.04915v1)|null|\n", "2311.00926": "|**2023-11-02**|**M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place**|Wentao Yuan et.al.|[2311.00926v1](http://arxiv.org/abs/2311.00926v1)|null|\n", "2311.00671": "|**2023-11-01**|**Emotion Detection for Misinformation: A Review**|Zhiwei Liu et.al.|[2311.00671v1](http://arxiv.org/abs/2311.00671v1)|null|\n", "2311.00618": "|**2023-11-01**|**De-Diffusion Makes Text a Strong Cross-Modal Interface**|Chen Wei et.al.|[2311.00618v1](http://arxiv.org/abs/2311.00618v1)|null|\n", "2311.00237": "|**2023-11-01**|**The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilities**|Yuxiang Zhou et.al.|[2311.00237v1](http://arxiv.org/abs/2311.00237v1)|null|\n", "2311.00223": "|**2023-11-01**|**Is GPT Powerful Enough to Analyze the Emotions of Memes?**|Jingjing Wang et.al.|[2311.00223v1](http://arxiv.org/abs/2311.00223v1)|null|\n", "2310.20487": "|**2023-10-31**|**Large Language Model Can Interpret Latent Space of Sequential Recommender**|Zhengyi Yang et.al.|[2310.20487v1](http://arxiv.org/abs/2310.20487v1)|**[link](https://github.com/yangzhengyi98/recinterpreter)**|\n", "2310.20440": "|**2023-10-31**|**The SourceData-NLP dataset: integrating curation into scientific publishing for training large language models**|Jorge Abreu-Vicente et.al.|[2310.20440v1](http://arxiv.org/abs/2310.20440v1)|**[link](https://github.com/source-data/soda-data)**|\n", "2310.19998": "|**2023-10-30**|**Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design**|Markus J. Buehler et.al.|[2310.19998v1](http://arxiv.org/abs/2310.19998v1)|null|\n", "2310.19915": "|**2023-10-30**|**GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors Using Protein Language Models**|Seongwon Kim et.al.|[2310.19915v1](http://arxiv.org/abs/2310.19915v1)|null|\n"}, "LLM - Safety": {"2311.18062": "|**2023-11-29**|**Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation**|Xijia Zhang et.al.|[2311.18062v1](http://arxiv.org/abs/2311.18062v1)|null|\n", "2311.17686": "|**2023-11-29**|**AviationGPT: A Large Language Model for the Aviation Domain**|Liya Wang et.al.|[2311.17686v1](http://arxiv.org/abs/2311.17686v1)|null|\n", "2311.17600": "|**2023-11-29**|**Query-Relevant Images Jailbreak Large Multi-Modal Models**|Xin Liu et.al.|[2311.17600v1](http://arxiv.org/abs/2311.17600v1)|null|\n", "2311.17391": "|**2023-11-29**|**Unveiling the Implicit Toxicity in Large Language Models**|Jiaxin Wen et.al.|[2311.17391v1](http://arxiv.org/abs/2311.17391v1)|**[link](https://github.com/thu-coai/implicit-toxicity)**|\n", "2311.15936": "|**2023-11-30**|**Towards Responsible Governance of Biological Design Tools**|Richard Moulange et.al.|[2311.15936v3](http://arxiv.org/abs/2311.15936v3)|null|\n", "2311.15180": "|**2023-11-26**|**Benchmarking Large Language Model Volatility**|Boyang Yu et.al.|[2311.15180v1](http://arxiv.org/abs/2311.15180v1)|null|\n", "2311.14966": "|**2023-11-25**|**Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains**|Chia-Chien Hung et.al.|[2311.14966v1](http://arxiv.org/abs/2311.14966v1)|null|\n", "2311.16511": "|**2023-11-25**|**GPT4Video: A Unified Multimodal Large Language Model for lnstruction-Followed Understanding and Safety-Aware Generation**|Zhanyu Wang et.al.|[2311.16511v1](http://arxiv.org/abs/2311.16511v1)|null|\n", "2311.13577": "|**2023-11-22**|**Physical Reasoning and Object Planning for Household Embodied Agents**|Ayush Agrawal et.al.|[2311.13577v1](http://arxiv.org/abs/2311.13577v1)|**[link](https://github.com/com-phy-affordance/coat)**|\n", "2311.12893": "|**2023-11-21**|**A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs**|Jiageng Zhong et.al.|[2311.12893v1](http://arxiv.org/abs/2311.12893v1)|null|\n", "2311.11855": "|**2023-11-20**|**Evil Geniuses: Delving into the Safety of LLM-based Agents**|Yu Tian et.al.|[2311.11855v1](http://arxiv.org/abs/2311.11855v1)|**[link](https://github.com/t1ans1r/evil-geniuses)**|\n", "2311.11797": "|**2023-11-20**|**Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**|Zhuosheng Zhang et.al.|[2311.11797v1](http://arxiv.org/abs/2311.11797v1)|**[link](https://github.com/zoeyyao27/cot-igniting-agent)**|\n", "2311.11415": "|**2023-11-19**|**A Security Risk Taxonomy for Large Language Models**|Erik Derner et.al.|[2311.11415v1](http://arxiv.org/abs/2311.11415v1)|null|\n", "2311.09827": "|**2023-11-16**|**Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking**|Nan Xu et.al.|[2311.09827v1](http://arxiv.org/abs/2311.09827v1)|null|\n", "2311.14712": "|**2023-11-16**|**Multiagent Simulators for Social Networks**|Aditya Surve et.al.|[2311.14712v1](http://arxiv.org/abs/2311.14712v1)|null|\n", "2311.09641": "|**2023-11-16**|**On the Exploitability of Reinforcement Learning with Human Feedback for Large Language Models**|Jiongxiao Wang et.al.|[2311.09641v1](http://arxiv.org/abs/2311.09641v1)|null|\n", "2311.09585": "|**2023-11-16**|**LifeTox: Unveiling Implicit Toxicity in Life Advice**|Minbeom Kim et.al.|[2311.09585v1](http://arxiv.org/abs/2311.09585v1)|null|\n", "2311.09447": "|**2023-11-15**|**How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities**|Lingbo Mo et.al.|[2311.09447v1](http://arxiv.org/abs/2311.09447v1)|**[link](https://github.com/osu-nlp-group/eval-llm-trust)**|\n", "2311.09433": "|**2023-11-24**|**Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment**|Haoran Wang et.al.|[2311.09433v2](http://arxiv.org/abs/2311.09433v2)|**[link](https://github.com/wang2226/backdoor-activation-attack)**|\n", "2311.09358": "|**2023-11-15**|**Empirical evaluation of Uncertainty Quantification in Retrieval-Augmented Language Models for Science**|Sridevi Wagle et.al.|[2311.09358v1](http://arxiv.org/abs/2311.09358v1)|**[link](https://github.com/pnnl/expert2)**|\n", "2311.09335": "|**2023-11-15**|**Lighter, yet More Faithful: Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization**|George Chrysostomou et.al.|[2311.09335v1](http://arxiv.org/abs/2311.09335v1)|null|\n", "2311.09096": "|**2023-11-15**|**Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization**|Zhexin Zhang et.al.|[2311.09096v1](http://arxiv.org/abs/2311.09096v1)|**[link](https://github.com/thu-coai/jailbreakdefense_goalpriority)**|\n", "2311.08838": "|**2023-11-15**|**Disinformation Capabilities of Large Language Models**|Ivan Vykopal et.al.|[2311.08838v1](http://arxiv.org/abs/2311.08838v1)|null|\n", "2311.08592": "|**2023-11-29**|**AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications**|Bhaktipriya Radharapu et.al.|[2311.08592v2](http://arxiv.org/abs/2311.08592v2)|**[link](https://github.com/google-research-datasets/aart-ai-safety-dataset)**|\n", "2311.08370": "|**2023-11-14**|**SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models**|Bertie Vidgen et.al.|[2311.08370v1](http://arxiv.org/abs/2311.08370v1)|null|\n", "2311.08303": "|**2023-11-14**|**Extrinsically-Focused Evaluation of Omissions in Medical Summarization**|Elliot Schumacher et.al.|[2311.08303v1](http://arxiv.org/abs/2311.08303v1)|null|\n", "2311.08298": "|**2023-11-14**|**A Survey of Language Model Confidence Estimation and Calibration**|Jiahui Geng et.al.|[2311.08298v1](http://arxiv.org/abs/2311.08298v1)|null|\n", "2311.07689": "|**2023-11-13**|**MART: Improving LLM Safety with Multi-round Automatic Red-Teaming**|Suyu Ge et.al.|[2311.07689v1](http://arxiv.org/abs/2311.07689v1)|null|\n", "2311.07469": "|**2023-11-15**|**InCA: Rethinking In-Car Conversational System Assessment Leveraging Large Language Models**|Ken E. Friedl et.al.|[2311.07469v2](http://arxiv.org/abs/2311.07469v2)|null|\n", "2311.07377": "|**2023-11-13**|**Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach**|Xi Zheng et.al.|[2311.07377v1](http://arxiv.org/abs/2311.07377v1)|null|\n", "2311.06899": "|**2023-11-12**|**Flames: Benchmarking Value Alignment of Chinese Large Language Models**|Kexin Huang et.al.|[2311.06899v1](http://arxiv.org/abs/2311.06899v1)|null|\n", "2311.06668": "|**2023-11-16**|**In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**|Sheng Liu et.al.|[2311.06668v2](http://arxiv.org/abs/2311.06668v2)|**[link](https://github.com/shengliu66/icv)**|\n", "2311.06622": "|**2023-11-23**|**TrainerAgent: Customizable and Efficient Model Training through LLM-Powered Multi-Agent System**|Haoyuan Li et.al.|[2311.06622v2](http://arxiv.org/abs/2311.06622v2)|null|\n", "2311.05915": "|**2023-11-14**|**Fake Alignment: Are LLMs Really Aligned Well?**|Yixu Wang et.al.|[2311.05915v2](http://arxiv.org/abs/2311.05915v2)|null|\n", "2311.05608": "|**2023-11-09**|**FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts**|Yichen Gong et.al.|[2311.05608v1](http://arxiv.org/abs/2311.05608v1)|**[link](https://github.com/thuccslab/figstep)**|\n", "2311.04124": "|**2023-11-07**|**Unveiling Safety Vulnerabilities of Large Language Models**|George Kour et.al.|[2311.04124v1](http://arxiv.org/abs/2311.04124v1)|null|\n", "2311.03191": "|**2023-11-06**|**DeepInception: Hypnotize Large Language Model to Be Jailbreaker**|Xuan Li et.al.|[2311.03191v1](http://arxiv.org/abs/2311.03191v1)|**[link](https://github.com/tmlr-group/deepinception)**|\n", "2311.02147": "|**2023-11-03**|**The Alignment Problem in Context**|Rapha\u00ebl Milli\u00e8re et.al.|[2311.02147v1](http://arxiv.org/abs/2311.02147v1)|null|\n", "2311.01918": "|**2023-11-03**|**Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review**|Mingze Yuan et.al.|[2311.01918v1](http://arxiv.org/abs/2311.01918v1)|**[link](https://github.com/mingze-yuan/awesome-llm-healthcare)**|\n", "2311.04921": "|**2023-11-03**|**Successor Features for Efficient Multisubject Controlled Text Generation**|Meng Cao et.al.|[2311.04921v1](http://arxiv.org/abs/2311.04921v1)|null|\n", "2311.02105": "|**2023-11-02**|**Making Harmful Behaviors Unlearnable for Large Language Models**|Xin Zhou et.al.|[2311.02105v1](http://arxiv.org/abs/2311.02105v1)|null|\n", "2311.01025": "|**2023-11-02**|**Incorporating Language-Driven Appearance Knowledge Units with Visual Cues in Pedestrian Detection**|Sungjune Park et.al.|[2311.01025v1](http://arxiv.org/abs/2311.01025v1)|null|\n", "2311.00321": "|**2023-11-22**|**HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning**|Yongjin Yang et.al.|[2311.00321v2](http://arxiv.org/abs/2311.00321v2)|**[link](https://github.com/joonkeekim/hare-hate-speech)**|\n", "2311.00172": "|**2023-10-31**|**Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield**|Jinhwa Kim et.al.|[2311.00172v1](http://arxiv.org/abs/2311.00172v1)|null|\n", "2311.00168": "|**2023-10-31**|**The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from Human Feedback**|Nathan Lambert et.al.|[2311.00168v1](http://arxiv.org/abs/2311.00168v1)|null|\n", "2311.00117": "|**2023-10-31**|**BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B**|Pranav Gade et.al.|[2311.00117v1](http://arxiv.org/abs/2311.00117v1)|null|\n", "2310.20624": "|**2023-10-31**|**LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B**|Simon Lermen et.al.|[2310.20624v1](http://arxiv.org/abs/2310.20624v1)|null|\n", "2310.19736": "|**2023-11-25**|**Evaluating Large Language Models: A Comprehensive Survey**|Zishan Guo et.al.|[2310.19736v3](http://arxiv.org/abs/2310.19736v3)|**[link](https://github.com/tjunlp-lab/awesome-llms-evaluation-papers)**|\n", "2310.19626": "|**2023-10-30**|**Transformation vs Tradition: Artificial General Intelligence (AGI) for Arts and Humanities**|Zhengliang Liu et.al.|[2310.19626v1](http://arxiv.org/abs/2310.19626v1)|null|\n", "2310.18130": "|**2023-11-07**|**DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues**|David Q. Sun et.al.|[2310.18130v2](http://arxiv.org/abs/2310.18130v2)|**[link](https://github.com/zidixiu/delphi)**|\n", "2310.16959": "|**2023-10-25**|**Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning**|Ananth Balashankar et.al.|[2310.16959v1](http://arxiv.org/abs/2310.16959v1)|null|\n", "2310.16763": "|**2023-10-25**|**SuperHF: Supervised Iterative Learning from Human Feedback**|Gabriel Mukobi et.al.|[2310.16763v1](http://arxiv.org/abs/2310.16763v1)|**[link](https://github.com/openfeedback/superhf)**|\n", "2310.15851": "|**2023-10-24**|**Self-Guard: Empower the LLM to Safeguard Itself**|Zezhong Wang et.al.|[2310.15851v1](http://arxiv.org/abs/2310.15851v1)|null|\n", "2310.15140": "|**2023-10-23**|**AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models**|Sicheng Zhu et.al.|[2310.15140v1](http://arxiv.org/abs/2310.15140v1)|null|\n", "2310.14414": "|**2023-10-22**|**Vision Language Models in Autonomous Driving and Intelligent Transportation Systems**|Xingcheng Zhou et.al.|[2310.14414v1](http://arxiv.org/abs/2310.14414v1)|**[link](https://github.com/ge25nab/Awesome-VLM-AD-ITS)**|\n", "2310.14303": "|**2023-11-13**|**Language Model Unalignment: Parametric Red-Teaming to Expose Hidden Harms and Biases**|Rishabh Bhardwaj et.al.|[2310.14303v2](http://arxiv.org/abs/2310.14303v2)|null|\n", "2310.13345": "|**2023-10-20**|**An LLM can Fool Itself: A Prompt-Based Adversarial Attack**|Xilie Xu et.al.|[2310.13345v1](http://arxiv.org/abs/2310.13345v1)|null|\n", "2310.13132": "|**2023-10-23**|**Better to Ask in English: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries**|Yiqiao Jin et.al.|[2310.13132v2](http://arxiv.org/abs/2310.13132v2)|**[link](https://github.com/claws-lab/XLingEval)**|\n", "2310.12931": "|**2023-10-19**|**Eureka: Human-Level Reward Design via Coding Large Language Models**|Yecheng Jason Ma et.al.|[2310.12931v1](http://arxiv.org/abs/2310.12931v1)|**[link](https://github.com/eureka-research/Eureka)**|\n", "2310.12803": "|**2023-10-19**|**Causal-structure Driven Augmentations for Text OOD Generalization**|Amir Feder et.al.|[2310.12803v1](http://arxiv.org/abs/2310.12803v1)|null|\n", "2310.12773": "|**2023-10-19**|**Safe RLHF: Safe Reinforcement Learning from Human Feedback**|Josef Dai et.al.|[2310.12773v1](http://arxiv.org/abs/2310.12773v1)|**[link](https://github.com/pku-alignment/safe-rlhf)**|\n", "2310.12505": "|**2023-10-19**|**Attack Prompt Generation for Red Teaming and Defending Large Language Models**|Boyi Deng et.al.|[2310.12505v1](http://arxiv.org/abs/2310.12505v1)|**[link](https://github.com/aatrox103/sap)**|\n", "2310.10844": "|**2023-10-16**|**Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks**|Erfan Shayegani et.al.|[2310.10844v1](http://arxiv.org/abs/2310.10844v1)|null|\n", "2310.10477": "|**2023-10-20**|**Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis**|Kai Chen et.al.|[2310.10477v2](http://arxiv.org/abs/2310.10477v2)|null|\n", "2310.10383": "|**2023-10-16**|**Privacy in Large Language Models: Attacks, Defenses and Future Directions**|Haoran Li et.al.|[2310.10383v1](http://arxiv.org/abs/2310.10383v1)|null|\n", "2310.10077": "|**2023-10-16**|**Prompt Packer: Deceiving LLMs through Compositional Instruction with Hidden Attacks**|Shuyu Jiang et.al.|[2310.10077v1](http://arxiv.org/abs/2310.10077v1)|null|\n", "2310.09624": "|**2023-11-11**|**ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models**|Alex Mei et.al.|[2310.09624v2](http://arxiv.org/abs/2310.09624v2)|**[link](https://github.com/alexmeigz/assert)**|\n", "2310.08419": "|**2023-10-13**|**Jailbreaking Black Box Large Language Models in Twenty Queries**|Patrick Chao et.al.|[2310.08419v2](http://arxiv.org/abs/2310.08419v2)|**[link](https://github.com/patrickrchao/jailbreakingllms)**|\n", "2310.08034": "|**2023-10-12**|**Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles**|Can Cui et.al.|[2310.08034v1](http://arxiv.org/abs/2310.08034v1)|null|\n", "2310.07944": "|**2023-10-11**|**AutoRepo: A general framework for multi-modal LLM-based automated construction reporting**|Hongxu Pu et.al.|[2310.07944v1](http://arxiv.org/abs/2310.07944v1)|null|\n", "2310.06987": "|**2023-10-10**|**Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation**|Yangsibo Huang et.al.|[2310.06987v1](http://arxiv.org/abs/2310.06987v1)|**[link](https://github.com/princeton-sysml/jailbreak_llm)**|\n", "2310.06762": "|**2023-10-10**|**TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models**|Xiao Wang et.al.|[2310.06762v1](http://arxiv.org/abs/2310.06762v1)|**[link](https://github.com/beyonderxx/trace)**|\n", "2310.06474": "|**2023-10-10**|**Multilingual Jailbreak Challenges in Large Language Models**|Yue Deng et.al.|[2310.06474v1](http://arxiv.org/abs/2310.06474v1)|**[link](https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs)**|\n", "2310.06387": "|**2023-10-10**|**Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations**|Zeming Wei et.al.|[2310.06387v1](http://arxiv.org/abs/2310.06387v1)|null|\n", "2310.06200": "|**2023-10-11**|**The Importance of Prompt Tuning for Automated Neuron Explanations**|Justin Lee et.al.|[2310.06200v2](http://arxiv.org/abs/2310.06200v2)|null|\n", "2310.05818": "|**2023-10-09**|**SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese**|Liang Xu et.al.|[2310.05818v1](http://arxiv.org/abs/2310.05818v1)|null|\n", "2310.05553": "|**2023-10-09**|**Regulation and NLP (RegNLP): Taming Large Language Models**|Catalina Goanta et.al.|[2310.05553v1](http://arxiv.org/abs/2310.05553v1)|null|\n", "2310.03693": "|**2023-10-05**|**Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!**|Xiangyu Qi et.al.|[2310.03693v1](http://arxiv.org/abs/2310.03693v1)|**[link](https://github.com/llm-tuning-safety/llms-finetuning-safety)**|\n", "2310.03026": "|**2023-10-13**|**LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving**|Hao Sha et.al.|[2310.03026v2](http://arxiv.org/abs/2310.03026v2)|null|\n", "2310.02949": "|**2023-10-04**|**Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models**|Xianjun Yang et.al.|[2310.02949v1](http://arxiv.org/abs/2310.02949v1)|null|\n", "2310.02446": "|**2023-10-03**|**Low-Resource Languages Jailbreak GPT-4**|Zheng-Xin Yong et.al.|[2310.02446v1](http://arxiv.org/abs/2310.02446v1)|null|\n", "2310.01708": "|**2023-10-03**|**Deciphering Diagnoses: How Large Language Models Explanations Influence Clinical Decision Making**|D. Umerenkov et.al.|[2310.01708v1](http://arxiv.org/abs/2310.01708v1)|null|\n", "2310.01581": "|**2023-10-02**|**On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?**|Hangfan Zhang et.al.|[2310.01581v1](http://arxiv.org/abs/2310.01581v1)|null|\n", "2310.01405": "|**2023-10-10**|**Representation Engineering: A Top-Down Approach to AI Transparency**|Andy Zou et.al.|[2310.01405v3](http://arxiv.org/abs/2310.01405v3)|**[link](https://github.com/andyzoujm/representation-engineering)**|\n", "2310.01386": "|**2023-10-02**|**Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench**|Jen-tse Huang et.al.|[2310.01386v1](http://arxiv.org/abs/2310.01386v1)|**[link](https://github.com/cuhk-arise/psychobench)**|\n", "2310.01320": "|**2023-10-24**|**Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation**|Shenzhi Wang et.al.|[2310.01320v3](http://arxiv.org/abs/2310.01320v3)|null|\n", "2310.00905": "|**2023-10-02**|**All Languages Matter: On the Multilingual Safety of Large Language Models**|Wenxuan Wang et.al.|[2310.00905v1](http://arxiv.org/abs/2310.00905v1)|**[link](https://github.com/jarviswang94/multilingual_safety_benchmark)**|\n", "2310.00603": "|**2023-11-22**|**Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals**|Yair Gat et.al.|[2310.00603v2](http://arxiv.org/abs/2310.00603v2)|null|\n", "2309.16436": "|**2023-09-28**|**Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving**|Sumit Kumar Jha et.al.|[2309.16436v1](http://arxiv.org/abs/2309.16436v1)|null|\n", "2309.16240": "|**2023-09-28**|**Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints**|Chaoqi Wang et.al.|[2309.16240v1](http://arxiv.org/abs/2309.16240v1)|null|\n", "2309.14504": "|**2023-09-25**|**People's Perceptions Toward Bias and Related Concepts in Large Language Models: A Systematic Review**|Lu Wang et.al.|[2309.14504v1](http://arxiv.org/abs/2309.14504v1)|null|\n", "2309.14122": "|**2023-09-25**|**SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via Substitution**|Zhongjie Ba et.al.|[2309.14122v1](http://arxiv.org/abs/2309.14122v1)|**[link](https://github.com/zjm1900/surrogateprompt)**|\n", "2309.13788": "|**2023-09-25**|**Can LLM-Generated Misinformation Be Detected?**|Canyu Chen et.al.|[2309.13788v1](http://arxiv.org/abs/2309.13788v1)|null|\n", "2309.12941": "|**2023-09-22**|**Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models**|Zezhong Chen et.al.|[2309.12941v1](http://arxiv.org/abs/2309.12941v1)|null|\n", "2309.11998": "|**2023-09-30**|**LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset**|Lianmin Zheng et.al.|[2309.11998v3](http://arxiv.org/abs/2309.11998v3)|**[link](https://github.com/lm-sys/fastchat)**|\n", "2309.11830": "|**2023-09-21**|**A Chinese Prompt Attack Dataset for LLMs with Evil Content**|Chengyuan Liu et.al.|[2309.11830v1](http://arxiv.org/abs/2309.11830v1)|null|\n", "2309.11751": "|**2023-10-14**|**How Robust is Google's Bard to Adversarial Image Attacks?**|Yinpeng Dong et.al.|[2309.11751v2](http://arxiv.org/abs/2309.11751v2)|**[link](https://github.com/thu-ml/attack-bard)**|\n", "2309.10346": "|**2023-09-19**|**Explaining Agent Behavior with Large Language Models**|Xijia Zhang et.al.|[2309.10346v1](http://arxiv.org/abs/2309.10346v1)|null|\n", "2309.10254": "|**2023-09-19**|**LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins**|Umar Iqbal et.al.|[2309.10254v1](http://arxiv.org/abs/2309.10254v1)|**[link](https://github.com/llm-platform-security/chatgpt-plugin-eval)**|\n", "2309.10253": "|**2023-10-04**|**GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts**|Jiahao Yu et.al.|[2309.10253v2](http://arxiv.org/abs/2309.10253v2)|**[link](https://github.com/sherdencooper/gptfuzz)**|\n"}, "LLM - Privacy": {"2311.18345": "|**2023-11-30**|**Situating the social issues of image generation models in the model life cycle: a sociotechnical approach**|Amelia Katirai et.al.|[2311.18345v1](http://arxiv.org/abs/2311.18345v1)|null|\n", "2311.16429": "|**2023-11-28**|**The Transformative Influence of Large Language Models on Software Development**|Sajed Jalil et.al.|[2311.16429v1](http://arxiv.org/abs/2311.16429v1)|null|\n", "2311.14030": "|**2023-11-23**|**PrivateLoRA For Efficient Privacy Preserving LLM**|Yiming Wang et.al.|[2311.14030v1](http://arxiv.org/abs/2311.14030v1)|null|\n", "2311.13857": "|**2023-11-23**|**Challenges of Large Language Models for Mental Health Counseling**|Neo Christopher Chung et.al.|[2311.13857v1](http://arxiv.org/abs/2311.13857v1)|null|\n", "2311.13158": "|**2023-11-22**|**From Principles to Practice: An Accountability Metrics Catalogue for Managing AI Risks**|Boming Xia et.al.|[2311.13158v1](http://arxiv.org/abs/2311.13158v1)|null|\n", "2311.12955": "|**2023-11-21**|**Don't forget private retrieval: distributed private similarity search for large language models**|Guy Zyskind et.al.|[2311.12955v1](http://arxiv.org/abs/2311.12955v1)|null|\n", "2311.12287": "|**2023-11-21**|**Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications**|Samira Ghodratnama et.al.|[2311.12287v1](http://arxiv.org/abs/2311.12287v1)|null|\n", "2311.11161": "|**2023-11-18**|**Experts-in-the-Loop: Establishing an Effective Workflow in Crafting Privacy Q&A**|Zahra Kolagar et.al.|[2311.11161v1](http://arxiv.org/abs/2311.11161v1)|null|\n", "2311.10785": "|**2023-11-16**|**Text Sanitization Beyond Specific Domains: Zero-Shot Redaction & Substitution with Large Language Models**|Federico Albanese et.al.|[2311.10785v1](http://arxiv.org/abs/2311.10785v1)|null|\n", "2311.09447": "|**2023-11-15**|**How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities**|Lingbo Mo et.al.|[2311.09447v1](http://arxiv.org/abs/2311.09447v1)|**[link](https://github.com/osu-nlp-group/eval-llm-trust)**|\n", "2311.10766": "|**2023-11-15**|**Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values**|Jing Yao et.al.|[2311.10766v1](http://arxiv.org/abs/2311.10766v1)|**[link](https://github.com/valuecompass/valuecompass.github.io)**|\n", "2311.06805": "|**2023-11-12**|**Tunable Soft Prompts are Messengers in Federated Learning**|Chenhe Dong et.al.|[2311.06805v1](http://arxiv.org/abs/2311.06805v1)|**[link](https://github.com/alibaba/federatedscope)**|\n", "2311.09243": "|**2023-11-12**|**Evaluating the Efficacy of Interactive Language Therapy Based on LLM for High-Functioning Autistic Adolescent Psychological Counseling**|Yujin Cho et.al.|[2311.09243v1](http://arxiv.org/abs/2311.09243v1)|null|\n", "2311.07601": "|**2023-11-11**|**Online Advertisements with LLMs: Opportunities and Challenges**|Soheil Feizi et.al.|[2311.07601v1](http://arxiv.org/abs/2311.07601v1)|null|\n", "2311.06062": "|**2023-11-10**|**Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration**|Wenjie Fu et.al.|[2311.06062v1](http://arxiv.org/abs/2311.06062v1)|null|\n", "2311.05863": "|**2023-11-10**|**Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service**|Yuanmin Tang et.al.|[2311.05863v1](http://arxiv.org/abs/2311.05863v1)|**[link](https://github.com/Pter61/vlpmarker)**|\n", "2311.06318": "|**2023-11-10**|**Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion**|Jinheon Baek et.al.|[2311.06318v1](http://arxiv.org/abs/2311.06318v1)|null|\n", "2311.16153": "|**2023-11-29**|**Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications**|Fengqing Jiang et.al.|[2311.16153v2](http://arxiv.org/abs/2311.16153v2)|null|\n", "2311.07585": "|**2023-11-24**|**Input Reconstruction Attack against Vertical Federated Large Language Models**|Fei Zheng et.al.|[2311.07585v2](http://arxiv.org/abs/2311.07585v2)|null|\n", "2311.02775": "|**2023-11-13**|**ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**|Yann Hicke et.al.|[2311.02775v2](http://arxiv.org/abs/2311.02775v2)|null|\n", "2311.02192": "|**2023-11-03**|**Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models**|Jake Chanenson et.al.|[2311.02192v1](http://arxiv.org/abs/2311.02192v1)|null|\n", "2311.00984": "|**2023-11-02**|**Inclusiveness Matters: A Large-Scale Analysis of User Feedback**|Nowshin Nawar Arony et.al.|[2311.00984v1](http://arxiv.org/abs/2311.00984v1)|null|\n", "2311.00287": "|**2023-11-01**|**Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models**|Ran Xu et.al.|[2311.00287v1](http://arxiv.org/abs/2311.00287v1)|**[link](https://github.com/ritaranx/clingen)**|\n", "2310.20150": "|**2023-10-31**|**Unlearn What You Want to Forget: Efficient Unlearning for LLMs**|Jiaao Chen et.al.|[2310.20150v1](http://arxiv.org/abs/2310.20150v1)|null|\n", "2310.20138": "|**2023-10-31**|**DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models**|Xinwei Wu et.al.|[2310.20138v1](http://arxiv.org/abs/2310.20138v1)|null|\n", "2310.20111": "|**2023-10-31**|**Making Large Language Models Better Data Creators**|Dong-Ho Lee et.al.|[2310.20111v1](http://arxiv.org/abs/2310.20111v1)|**[link](https://github.com/microsoft/llm-data-creation)**|\n", "2310.19233": "|**2023-11-08**|**Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective**|Md Tahmid Rahman Laskar et.al.|[2310.19233v3](http://arxiv.org/abs/2310.19233v3)|null|\n", "2310.17884": "|**2023-10-27**|**Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory**|Niloofar Mireshghallah et.al.|[2310.17884v1](http://arxiv.org/abs/2310.17884v1)|null|\n", "2310.17752": "|**2023-10-26**|**PockEngine: Sparse and Efficient Fine-tuning in a Pocket**|Ligeng Zhu et.al.|[2310.17752v1](http://arxiv.org/abs/2310.17752v1)|null|\n", "2310.16960": "|**2023-10-25**|**Privately Aligning Language Models with Reinforcement Learning**|Fan Wu et.al.|[2310.16960v1](http://arxiv.org/abs/2310.16960v1)|null|\n", "2310.16789": "|**2023-11-03**|**Detecting Pretraining Data from Large Language Models**|Weijia Shi et.al.|[2310.16789v2](http://arxiv.org/abs/2310.16789v2)|null|\n", "2310.16340": "|**2023-10-25**|**RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models**|Zefan Wang et.al.|[2310.16340v1](http://arxiv.org/abs/2310.16340v1)|null|\n", "2310.16111": "|**2023-11-30**|**Locally Differentially Private Document Generation Using Zero Shot Prompting**|Saiteja Utpala et.al.|[2310.16111v2](http://arxiv.org/abs/2310.16111v2)|**[link](https://github.com/saitejautpala/dp_prompt)**|\n", "2310.18362": "|**2023-10-24**|**SoK: Memorization in General-Purpose Large Language Models**|Valentin Hartmann et.al.|[2310.18362v1](http://arxiv.org/abs/2310.18362v1)|null|\n", "2310.15477": "|**2023-10-24**|**CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model**|Kaiyan Zhang et.al.|[2310.15477v1](http://arxiv.org/abs/2310.15477v1)|null|\n", "2310.15469": "|**2023-10-24**|**The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks**|Xiaoyi Chen et.al.|[2310.15469v1](http://arxiv.org/abs/2310.15469v1)|null|\n", "2310.18355": "|**2023-10-23**|**Health Disparities through Generative AI Models: A Comparison Study Using A Domain Specific large language model**|Yohn Jairo Parra Bautista et.al.|[2310.18355v1](http://arxiv.org/abs/2310.18355v1)|null|\n", "2310.15007": "|**2023-10-23**|**Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models**|Matthieu Meeus et.al.|[2310.15007v1](http://arxiv.org/abs/2310.15007v1)|null|\n", "2310.14970": "|**2023-10-23**|**Towards LLM-driven Dialogue State Tracking**|Yujie Feng et.al.|[2310.14970v1](http://arxiv.org/abs/2310.14970v1)|**[link](https://github.com/woodscene/ldst)**|\n", "2310.14369": "|**2023-10-22**|**MoPe: Model Perturbation-based Privacy Attacks on Language Models**|Marvin Li et.al.|[2310.14369v1](http://arxiv.org/abs/2310.14369v1)|null|\n", "2310.13291": "|**2023-10-20**|**Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks**|Ruixiang Tang et.al.|[2310.13291v1](http://arxiv.org/abs/2310.13291v1)|null|\n", "2310.12746": "|**2023-10-19**|**TabuLa: Harnessing Language Models for Tabular Data Synthesis**|Zilong Zhao et.al.|[2310.12746v1](http://arxiv.org/abs/2310.12746v1)|**[link](https://github.com/zhao-zilong/tabula)**|\n", "2310.12523": "|**2023-10-19**|**Privacy Preserving Large Language Models: ChatGPT Case Study Based Vision and Framework**|Imdad Ullah et.al.|[2310.12523v1](http://arxiv.org/abs/2310.12523v1)|null|\n", "2310.12214": "|**2023-10-24**|**PrivInfer: Privacy-Preserving Inference for Black-box Large Language Model**|Meng Tong et.al.|[2310.12214v3](http://arxiv.org/abs/2310.12214v3)|null|\n", "2310.11397": "|**2023-10-17**|**Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning, LoRA, and In-Context Learning**|Rui Wen et.al.|[2310.11397v1](http://arxiv.org/abs/2310.11397v1)|null|\n", "2310.10383": "|**2023-10-16**|**Privacy in Large Language Models: Attacks, Defenses and Future Directions**|Haoran Li et.al.|[2310.10383v1](http://arxiv.org/abs/2310.10383v1)|null|\n", "2310.10049": "|**2023-10-16**|**FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models**|Tao Fan et.al.|[2310.10049v1](http://arxiv.org/abs/2310.10049v1)|**[link](https://github.com/FederatedAI/FATE-LLM)**|\n", "2310.09639": "|**2023-10-14**|**DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization**|Liang Zhang et.al.|[2310.09639v1](http://arxiv.org/abs/2310.09639v1)|null|\n", "2310.09266": "|**2023-10-13**|**User Inference Attacks on Large Language Models**|Nikhil Kandpal et.al.|[2310.09266v1](http://arxiv.org/abs/2310.09266v1)|null|\n", "2310.09130": "|**2023-10-13**|**Split-and-Denoise: Protect large language model inference with local differential privacy**|Peihua Mai et.al.|[2310.09130v1](http://arxiv.org/abs/2310.09130v1)|null|\n", "2310.07298": "|**2023-10-11**|**Beyond Memorization: Violating Privacy Via Inference with Large Language Models**|Robin Staab et.al.|[2310.07298v1](http://arxiv.org/abs/2310.07298v1)|null|\n", "2310.07282": "|**2023-10-12**|**An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT**|Shyni Sharaf et.al.|[2310.07282v2](http://arxiv.org/abs/2310.07282v2)|null|\n", "2310.06278": "|**2023-10-10**|**BC4LLM: Trusted Artificial Intelligence When Blockchain Meets Large Language Models**|Haoxiang Luo et.al.|[2310.06278v1](http://arxiv.org/abs/2310.06278v1)|null|\n", "2310.03104": "|**2023-10-04**|**DP-SGD for non-decomposable objective functions**|William Kong et.al.|[2310.03104v1](http://arxiv.org/abs/2310.03104v1)|null|\n", "2310.02469": "|**2023-10-03**|**Large Language Models Can Be Good Privacy Protection Learners**|Yijia Xiao et.al.|[2310.02469v1](http://arxiv.org/abs/2310.02469v1)|null|\n", "2310.02431": "|**2023-10-03**|**Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions**|Yufan Chen et.al.|[2310.02431v1](http://arxiv.org/abs/2310.02431v1)|**[link](https://github.com/purseclab/llm_security_privacy_advice)**|\n", "2310.01329": "|**2023-10-02**|**BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models**|Qingqing Cao et.al.|[2310.01329v1](http://arxiv.org/abs/2310.01329v1)|null|\n", "2310.01467": "|**2023-10-02**|**FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models**|Jingwei Sun et.al.|[2310.01467v1](http://arxiv.org/abs/2310.01467v1)|null|\n", "2310.01166": "|**2023-10-02**|**Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models**|Zhou Yang et.al.|[2310.01166v1](http://arxiv.org/abs/2310.01166v1)|null|\n", "2310.01152": "|**2023-10-16**|**Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives**|Sihao Hu et.al.|[2310.01152v2](http://arxiv.org/abs/2310.01152v2)|**[link](https://github.com/git-disl/gptlens)**|\n", "2310.00272": "|**2023-09-30**|**Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thoughts Prompting**|Baphumelele Masikisiki et.al.|[2310.00272v1](http://arxiv.org/abs/2310.00272v1)|null|\n", "2310.01434": "|**2023-09-29**|**Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile**|Samuel Carreira et.al.|[2310.01434v1](http://arxiv.org/abs/2310.01434v1)|null|\n", "2309.17157": "|**2023-11-14**|**LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud**|Mengke Zhang et.al.|[2309.17157v3](http://arxiv.org/abs/2309.17157v3)|null|\n", "2309.16739": "|**2023-09-28**|**Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities**|Zheng Lin et.al.|[2309.16739v1](http://arxiv.org/abs/2309.16739v1)|null|\n", "2309.14726": "|**2023-09-26**|**PLMM: Personal Large Models on Mobile Devices**|Yuanhao Gong et.al.|[2309.14726v1](http://arxiv.org/abs/2309.14726v1)|null|\n", "2309.14510": "|**2023-09-25**|**An Empathy-Based Sandbox Approach to Bridge Attitudes, Goals, Knowledge, and Behaviors in the Privacy Paradox**|Chaoran Chen et.al.|[2309.14510v1](http://arxiv.org/abs/2309.14510v1)|null|\n", "2309.11852": "|**2023-09-21**|**Knowledge Sanitization of Large Language Models**|Yoichi Ishibashi et.al.|[2309.11852v1](http://arxiv.org/abs/2309.11852v1)|null|\n", "2309.11765": "|**2023-09-21**|**Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation**|Xinyu Tang et.al.|[2309.11765v1](http://arxiv.org/abs/2309.11765v1)|**[link](https://github.com/microsoft/dp-few-shot-generation)**|\n", "2309.11653": "|**2023-09-20**|**\"It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents**|Zhiping Zhang et.al.|[2309.11653v1](http://arxiv.org/abs/2309.11653v1)|null|\n", "2309.10929": "|**2023-09-19**|**Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training**|Ruiqi Xu et.al.|[2309.10929v1](http://arxiv.org/abs/2309.10929v1)|**[link](https://github.com/ruiqixu37/BTTS_ECAI2023)**|\n", "2309.10254": "|**2023-09-19**|**LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins**|Umar Iqbal et.al.|[2309.10254v1](http://arxiv.org/abs/2309.10254v1)|**[link](https://github.com/llm-platform-security/chatgpt-plugin-eval)**|\n", "2309.10238": "|**2023-09-19**|**PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models**|Chenhao Tang et.al.|[2309.10238v1](http://arxiv.org/abs/2309.10238v1)|null|\n", "2309.09843": "|**2023-09-18**|**Instruction-Following Speech Recognition**|Cheng-I Jeff Lai et.al.|[2309.09843v1](http://arxiv.org/abs/2309.09843v1)|null|\n", "2309.08173": "|**2023-09-15**|**FedJudge: Federated Legal Large Language Model**|Linan Yue et.al.|[2309.08173v1](http://arxiv.org/abs/2309.08173v1)|**[link](https://github.com/yuelinan/fedjudge)**|\n", "2309.07254": "|**2023-10-26**|**Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement**|Chenghao Li et.al.|[2309.07254v2](http://arxiv.org/abs/2309.07254v2)|**[link](https://github.com/howardli0816/dual-fusion-diffusion)**|\n", "2309.08628": "|**2023-09-23**|**Recovering from Privacy-Preserving Masking with Large Language Models**|Arpita Vats et.al.|[2309.08628v2](http://arxiv.org/abs/2309.08628v2)|null|\n", "2309.04255": "|**2023-09-08**|**LLMCad: Fast and Scalable On-device Large Language Model Inference**|Daliang Xu et.al.|[2309.04255v1](http://arxiv.org/abs/2309.04255v1)|null|\n", "2309.04076": "|**2023-10-08**|**Towards Smaller, Faster, and Greener Language Models of Code**|Jieke Shi et.al.|[2309.04076v2](http://arxiv.org/abs/2309.04076v2)|null|\n", "2309.03748": "|**2023-09-07**|**Enhancing Pipeline-Based Conversational Agents with Large Language Models**|Mina Foosherian et.al.|[2309.03748v1](http://arxiv.org/abs/2309.03748v1)|null|\n", "2309.03057": "|**2023-09-06**|**Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection**|Yu Chen et.al.|[2309.03057v1](http://arxiv.org/abs/2309.03057v1)|**[link](https://github.com/alohachen/hide-and-seek)**|\n", "2311.06251": "|**2023-09-06**|**AI for Investment: A Platform Disruption**|Mohammad Rasouli et.al.|[2311.06251v1](http://arxiv.org/abs/2311.06251v1)|null|\n", "2309.03242": "|**2023-09-06**|**Automated Bioinformatics Analysis via AutoBA**|Juexiao Zhou et.al.|[2309.03242v1](http://arxiv.org/abs/2309.03242v1)|**[link](https://github.com/joshuachou2018/autoba)**|\n", "2309.01172": "|**2023-09-03**|**FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs**|Zhenheng Tang et.al.|[2309.01172v1](http://arxiv.org/abs/2309.01172v1)|null|\n", "2309.00964": "|**2023-09-13**|**eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models**|Minsik Cho et.al.|[2309.00964v2](http://arxiv.org/abs/2309.00964v2)|null|\n", "2309.00363": "|**2023-09-01**|**FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning**|Weirui Kuang et.al.|[2309.00363v1](http://arxiv.org/abs/2309.00363v1)|**[link](https://github.com/alibaba/federatedscope)**|\n", "2309.00237": "|**2023-09-06**|**Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes**|Sunjun Kweon et.al.|[2309.00237v2](http://arxiv.org/abs/2309.00237v2)|**[link](https://github.com/starmpcc/asclepius)**|\n", "2308.15727": "|**2023-11-05**|**Quantifying and Analyzing Entity-level Memorization in Large Language Models**|Zhenhong Zhou et.al.|[2308.15727v2](http://arxiv.org/abs/2308.15727v2)|null|\n", "2308.15126": "|**2023-10-10**|**Evaluation and Analysis of Hallucination in Large Vision-Language Models**|Junyang Wang et.al.|[2308.15126v3](http://arxiv.org/abs/2308.15126v3)|**[link](https://github.com/junyangwang0410/haelm)**|\n", "2308.14352": "|**2023-08-28**|**EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models**|Rongjie Yi et.al.|[2308.14352v1](http://arxiv.org/abs/2308.14352v1)|null|\n", "2308.13894": "|**2023-08-26**|**Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices**|Mengwei Xu et.al.|[2308.13894v1](http://arxiv.org/abs/2308.13894v1)|null|\n", "2308.11807": "|**2023-08-22**|**Towards an On-device Agent for Text Rewriting**|Yun Zhu et.al.|[2308.11807v1](http://arxiv.org/abs/2308.11807v1)|null|\n", "2308.11103": "|**2023-08-22**|**Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models**|Alex Nyffenegger et.al.|[2308.11103v1](http://arxiv.org/abs/2308.11103v1)|**[link](https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models)**|\n", "2308.09932": "|**2023-08-19**|**What Do Code Models Memorize? An Empirical Study on Large Language Models of Code**|Zhou Yang et.al.|[2308.09932v1](http://arxiv.org/abs/2308.09932v1)|null|\n", "2308.09376": "|**2023-08-18**|**Leveraging Large Language Models for DRL-Based Anti-Jamming Strategies in Zero Touch Networks**|Abubakar S. Ali et.al.|[2308.09376v1](http://arxiv.org/abs/2308.09376v1)|null|\n", "2308.07847": "|**2023-08-15**|**Robustness Over Time: Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of Large Language Models**|Yugeng Liu et.al.|[2308.07847v1](http://arxiv.org/abs/2308.07847v1)|null|\n", "2308.13534": "|**2023-08-13**|**Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph**|Ahtsham Zafar et.al.|[2308.13534v1](http://arxiv.org/abs/2308.13534v1)|null|\n", "2308.06261": "|**2023-08-11**|**Enhancing Network Management Using Code Generated by Large Language Models**|Sathiya Kumaran Mani et.al.|[2308.06261v1](http://arxiv.org/abs/2308.06261v1)|**[link](https://github.com/microsoft/nemoeval)**|\n", "2308.06294": "|**2023-11-09**|**Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT**|Jingye Yang et.al.|[2308.06294v2](http://arxiv.org/abs/2308.06294v2)|**[link](https://github.com/wglab/phenogpt)**|\n", "2308.05596": "|**2023-08-10**|**You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content**|Xinlei He et.al.|[2308.05596v1](http://arxiv.org/abs/2308.05596v1)|**[link](https://github.com/xinleihe/toxic-prompt)**|\n", "2308.04913": "|**2023-08-09**|**LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following**|Kaize Shi et.al.|[2308.04913v1](http://arxiv.org/abs/2308.04913v1)|null|\n"}, "LLM - Reliability": {"2311.18743": "|**2023-11-30**|**AlignBench: Benchmarking Chinese Alignment of Large Language Models**|Xiao Liu et.al.|[2311.18743v1](http://arxiv.org/abs/2311.18743v1)|**[link](https://github.com/thudm/alignbench)**|\n", "2311.18232": "|**2023-11-30**|**LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models**|Marwa Abdulhai et.al.|[2311.18232v1](http://arxiv.org/abs/2311.18232v1)|null|\n", "2311.18063": "|**2023-11-29**|**TurkishBERTweet: Fast and Reliable Large Language Model for Social Media Analysis**|Ali Najafi et.al.|[2311.18063v1](http://arxiv.org/abs/2311.18063v1)|null|\n", "2311.18054": "|**2023-11-29**|**I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text**|Kaan Efe Kele\u015f et.al.|[2311.18054v1](http://arxiv.org/abs/2311.18054v1)|null|\n", "2311.17371": "|**2023-11-29**|**Are we going MAD? Benchmarking Multi-Agent Debate between Language Models for Medical Q&A**|Andries Smit et.al.|[2311.17371v1](http://arxiv.org/abs/2311.17371v1)|null|\n", "2311.17355": "|**2023-11-29**|**Are Large Language Models Good Fact Checkers: A Preliminary Study**|Han Cao et.al.|[2311.17355v1](http://arxiv.org/abs/2311.17355v1)|null|\n", "2311.17295": "|**2023-11-29**|**Elo Uncovered: Robustness and Best Practices in Language Model Evaluation**|Meriem Boubdir et.al.|[2311.17295v1](http://arxiv.org/abs/2311.17295v1)|null|\n", "2311.16974": "|**2023-11-28**|**COLE: A Hierarchical Generation Framework for Graphic Design**|Peidong Jia et.al.|[2311.16974v1](http://arxiv.org/abs/2311.16974v1)|null|\n", "2311.16842": "|**2023-11-28**|**RELIC: Investigating Large Language Model Responses using Self-Consistency**|Furui Cheng et.al.|[2311.16842v1](http://arxiv.org/abs/2311.16842v1)|null|\n", "2311.16542": "|**2023-11-28**|**Agents meet OKR: An Object and Key Results Driven Agent System with Hierarchical Self-Collaboration and Self-Evaluation**|Yi Zheng et.al.|[2311.16542v1](http://arxiv.org/abs/2311.16542v1)|null|\n", "2311.16208": "|**2023-11-27**|**InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery**|He Cao et.al.|[2311.16208v1](http://arxiv.org/abs/2311.16208v1)|null|\n", "2311.15566": "|**2023-11-27**|**SpotServe: Serving Generative Large Language Models on Preemptible Instances**|Xupeng Miao et.al.|[2311.15566v1](http://arxiv.org/abs/2311.15566v1)|**[link](https://github.com/hsword/spotserve)**|\n", "2311.15296": "|**2023-11-26**|**UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation**|Xun Liang et.al.|[2311.15296v1](http://arxiv.org/abs/2311.15296v1)|**[link](https://github.com/IAAR-Shanghai/UHGEval)**|\n", "2311.14966": "|**2023-11-25**|**Walking a Tightrope -- Evaluating Large Language Models in High-Risk Domains**|Chia-Chien Hung et.al.|[2311.14966v1](http://arxiv.org/abs/2311.14966v1)|null|\n", "2311.14876": "|**2023-11-24**|**Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles**|Sonali Singh et.al.|[2311.14876v1](http://arxiv.org/abs/2311.14876v1)|null|\n", "2311.14324": "|**2023-11-24**|**Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs**|Shengyin Sun et.al.|[2311.14324v1](http://arxiv.org/abs/2311.14324v1)|null|\n", "2311.13857": "|**2023-11-23**|**Challenges of Large Language Models for Mental Health Counseling**|Neo Christopher Chung et.al.|[2311.13857v1](http://arxiv.org/abs/2311.13857v1)|null|\n", "2311.13314": "|**2023-11-22**|**Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-based Retrofitting**|Xinyan Guan et.al.|[2311.13314v1](http://arxiv.org/abs/2311.13314v1)|null|\n", "2311.13240": "|**2023-11-22**|**On the Calibration of Large Language Models and Alignment**|Chiwei Zhu et.al.|[2311.13240v1](http://arxiv.org/abs/2311.13240v1)|null|\n", "2311.12707": "|**2023-11-21**|**Keeping Users Engaged During Repeated Administration of the Same Questionnaire: Using Large Language Models to Reliably Diversify Questions**|Hye Sun Yun et.al.|[2311.12707v1](http://arxiv.org/abs/2311.12707v1)|null|\n", "2311.12524": "|**2023-11-21**|**ALPHA: AnomaLous Physiological Health Assessment Using Large Language Models**|Jiankai Tang et.al.|[2311.12524v1](http://arxiv.org/abs/2311.12524v1)|**[link](https://github.com/mcjacktang/llm-healthassistant)**|\n", "2311.12893": "|**2023-11-21**|**A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs**|Jiageng Zhong et.al.|[2311.12893v1](http://arxiv.org/abs/2311.12893v1)|null|\n", "2311.11516": "|**2023-11-20**|**GPT in Data Science: A Practical Exploration of Model Selection**|Nathalia Nascimento et.al.|[2311.11516v1](http://arxiv.org/abs/2311.11516v1)|null|\n", "2311.11267": "|**2023-11-19**|**Rethinking Large Language Models in Mental Health Applications**|Shaoxiong Ji et.al.|[2311.11267v1](http://arxiv.org/abs/2311.11267v1)|null|\n", "2311.11135": "|**2023-11-18**|**A Principled Framework for Knowledge-enhanced Large Language Model**|Saizhuo Wang et.al.|[2311.11135v1](http://arxiv.org/abs/2311.11135v1)|null|\n", "2311.10961": "|**2023-11-18**|**Journey of Hallucination-minimized Generative AI Solutions for Financial Decision Makers**|Sohini Roychowdhury et.al.|[2311.10961v1](http://arxiv.org/abs/2311.10961v1)|null|\n", "2311.10947": "|**2023-11-18**|**RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**|Yuxuan Lei et.al.|[2311.10947v1](http://arxiv.org/abs/2311.10947v1)|null|\n", "2311.16169": "|**2023-11-16**|**Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities**|Avishree Khare et.al.|[2311.16169v1](http://arxiv.org/abs/2311.16169v1)|null|\n", "2311.09829": "|**2023-11-16**|**FollowEval: A Multi-Dimensional Benchmark for Assessing the Instruction-Following Capability of Large Language Models**|Yimin Jing et.al.|[2311.09829v1](http://arxiv.org/abs/2311.09829v1)|null|\n", "2311.09758": "|**2023-11-16**|**OrchestraLLM: Efficient Orchestration of Language Models for Dialogue State Tracking**|Chia-Hsuan Lee et.al.|[2311.09758v1](http://arxiv.org/abs/2311.09758v1)|null|\n", "2311.09731": "|**2023-11-16**|**Prudent Silence or Foolish Babble? Examining Large Language Models' Responses to the Unknown**|Genglin Liu et.al.|[2311.09731v1](http://arxiv.org/abs/2311.09731v1)|null|\n", "2311.09721": "|**2023-11-16**|**On Evaluating the Integration of Reasoning and Action in LLM Agents with Database Question Answering**|Linyong Nan et.al.|[2311.09721v1](http://arxiv.org/abs/2311.09721v1)|null|\n", "2311.09718": "|**2023-11-16**|**You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments**|Bangzhao Shu et.al.|[2311.09718v1](http://arxiv.org/abs/2311.09718v1)|**[link](https://github.com/orange0629/llm-personas)**|\n", "2311.09693": "|**2023-11-16**|**BLT: Can Large Language Models Handle Basic Legal Text?**|Andrew Blair-Stanek et.al.|[2311.09693v1](http://arxiv.org/abs/2311.09693v1)|**[link](https://github.com/blairstanek/blt)**|\n", "2311.09648": "|**2023-11-16**|**Event Causality Is Key to Computational Story Understanding**|Yidan Sun et.al.|[2311.09648v1](http://arxiv.org/abs/2311.09648v1)|null|\n", "2311.09603": "|**2023-11-16**|**SCORE: A framework for Self-Contradictory Reasoning Evaluation**|Ziyi Liu et.al.|[2311.09603v1](http://arxiv.org/abs/2311.09603v1)|null|\n", "2311.09562": "|**2023-11-16**|**A Reevaluation of Event Extraction: Past, Present, and Future Challenges**|Kuan-Hao Huang et.al.|[2311.09562v1](http://arxiv.org/abs/2311.09562v1)|**[link](https://github.com/ej0cl6/textee)**|\n", "2311.09410": "|**2023-11-15**|**When Large Language Models contradict humans? Large Language Models' Sycophantic Behaviour**|Leonardo Ranaldi et.al.|[2311.09410v1](http://arxiv.org/abs/2311.09410v1)|null|\n", "2311.09358": "|**2023-11-15**|**Empirical evaluation of Uncertainty Quantification in Retrieval-Augmented Language Models for Science**|Sridevi Wagle et.al.|[2311.09358v1](http://arxiv.org/abs/2311.09358v1)|**[link](https://github.com/pnnl/expert2)**|\n", "2311.09335": "|**2023-11-15**|**Lighter, yet More Faithful: Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization**|George Chrysostomou et.al.|[2311.09335v1](http://arxiv.org/abs/2311.09335v1)|null|\n", "2311.09210": "|**2023-11-15**|**Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**|Wenhao Yu et.al.|[2311.09210v1](http://arxiv.org/abs/2311.09210v1)|null|\n", "2311.09069": "|**2023-11-15**|**How Well Do Large Language Models Truly Ground?**|Hyunji Lee et.al.|[2311.09069v1](http://arxiv.org/abs/2311.09069v1)|**[link](https://github.com/kaistai/how-well-do-llms-truly-ground)**|\n", "2311.08921": "|**2023-11-15**|**Self-Improving for Zero-Shot Named Entity Recognition with Large Language Models**|Tingyu Xie et.al.|[2311.08921v1](http://arxiv.org/abs/2311.08921v1)|null|\n", "2311.08732": "|**2023-11-15**|**Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models**|Minze Chen et.al.|[2311.08732v1](http://arxiv.org/abs/2311.08732v1)|null|\n", "2311.08718": "|**2023-11-15**|**Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling**|Bairu Hou et.al.|[2311.08718v1](http://arxiv.org/abs/2311.08718v1)|null|\n", "2311.08614": "|**2023-11-15**|**XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making**|Zichen Chen et.al.|[2311.08614v1](http://arxiv.org/abs/2311.08614v1)|null|\n", "2311.08576": "|**2023-11-14**|**Towards Evaluating AI Systems for Moral Status Using Self-Reports**|Ethan Perez et.al.|[2311.08576v1](http://arxiv.org/abs/2311.08576v1)|null|\n", "2311.08348": "|**2023-11-14**|**MC^2: A Multilingual Corpus of Minority Languages in China**|Chen Zhang et.al.|[2311.08348v1](http://arxiv.org/abs/2311.08348v1)|**[link](https://github.com/luciusssss/mc2_corpus)**|\n", "2311.08298": "|**2023-11-14**|**A Survey of Language Model Confidence Estimation and Calibration**|Jiahui Geng et.al.|[2311.08298v1](http://arxiv.org/abs/2311.08298v1)|null|\n", "2311.08166": "|**2023-11-14**|**MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge**|Bo Ni et.al.|[2311.08166v1](http://arxiv.org/abs/2311.08166v1)|null|\n", "2311.08117": "|**2023-11-14**|**Insights into Classifying and Mitigating LLMs' Hallucinations**|Alessandro Bruno et.al.|[2311.08117v1](http://arxiv.org/abs/2311.08117v1)|null|\n", "2311.07878": "|**2023-11-18**|**Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset**|Zafaryab Rasool et.al.|[2311.07878v3](http://arxiv.org/abs/2311.07878v3)|null|\n", "2311.07491": "|**2023-11-13**|**A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models**|Hejing Cao et.al.|[2311.07491v1](http://arxiv.org/abs/2311.07491v1)|**[link](https://github.com/alkaidpku/dq-toolqa)**|\n", "2311.06985": "|**2023-11-12**|**SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions by Themselves**|Jiachen Zhao et.al.|[2311.06985v1](http://arxiv.org/abs/2311.06985v1)|null|\n", "2311.06979": "|**2023-11-12**|**Assessing the Interpretability of Programmatic Policies with Large Language Models**|Zahra Bashir et.al.|[2311.06979v1](http://arxiv.org/abs/2311.06979v1)|null|\n", "2311.06697": "|**2023-11-12**|**Trusted Source Alignment in Large Language Models**|Vasilisa Bashlovkina et.al.|[2311.06697v1](http://arxiv.org/abs/2311.06697v1)|null|\n", "2311.06503": "|**2023-11-11**|**Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering**|Yichi Zhang et.al.|[2311.06503v1](http://arxiv.org/abs/2311.06503v1)|**[link](https://github.com/zjukg/knowpat)**|\n", "2311.07601": "|**2023-11-11**|**Online Advertisements with LLMs: Opportunities and Challenges**|Soheil Feizi et.al.|[2311.07601v1](http://arxiv.org/abs/2311.07601v1)|null|\n", "2311.06062": "|**2023-11-10**|**Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration**|Wenjie Fu et.al.|[2311.06062v1](http://arxiv.org/abs/2311.06062v1)|null|\n", "2311.05769": "|**2023-11-09**|**Chatbots Are Not Reliable Text Annotators**|Ross Deans Kristensen-McLachlan et.al.|[2311.05769v1](http://arxiv.org/abs/2311.05769v1)|**[link](https://github.com/centre-for-humanities-computing/llm-tweet-classification)**|\n", "2311.16162": "|**2023-11-09**|**Leveraging Artificial Intelligence Technology for Mapping Research to Sustainable Development Goals: A Case Study**|Hui Yin et.al.|[2311.16162v1](http://arxiv.org/abs/2311.16162v1)|null|\n", "2311.05232": "|**2023-11-09**|**A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions**|Lei Huang et.al.|[2311.05232v1](http://arxiv.org/abs/2311.05232v1)|**[link](https://github.com/luckyyysta/awesome-llm-hallucination)**|\n", "2311.04694": "|**2023-11-08**|**Evaluating Generative Ad Hoc Information Retrieval**|Lukas Gienapp et.al.|[2311.04694v1](http://arxiv.org/abs/2311.04694v1)|null|\n", "2311.04124": "|**2023-11-07**|**Unveiling Safety Vulnerabilities of Large Language Models**|George Kour et.al.|[2311.04124v1](http://arxiv.org/abs/2311.04124v1)|null|\n", "2311.03754": "|**2023-11-07**|**Which is better? Exploring Prompting Strategy For LLM-based Metrics**|Joonghoon Kim et.al.|[2311.03754v1](http://arxiv.org/abs/2311.03754v1)|**[link](https://github.com/SeoroMin/Prompt4LLM-Eval)**|\n", "2311.03731": "|**2023-11-07**|**A Survey of Large Language Models Attribution**|Dongfang Li et.al.|[2311.03731v1](http://arxiv.org/abs/2311.03731v1)|**[link](https://github.com/hitsz-tmg/awesome-llm-attributions)**|\n", "2311.03533": "|**2023-11-06**|**Quantifying Uncertainty in Natural Language Explanations of Large Language Models**|Sree Harsha Tanneru et.al.|[2311.03533v1](http://arxiv.org/abs/2311.03533v1)|null|\n", "2311.03033": "|**2023-11-06**|**Beyond Words: A Mathematical Framework for Interpreting Large Language Models**|Javier Gonz\u00e1lez et.al.|[2311.03033v1](http://arxiv.org/abs/2311.03033v1)|null|\n", "2311.04235": "|**2023-11-06**|**Can LLMs Follow Simple Rules?**|Norman Mu et.al.|[2311.04235v1](http://arxiv.org/abs/2311.04235v1)|**[link](https://github.com/normster/llm_rules)**|\n", "2311.02692": "|**2023-11-05**|**ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models**|Zhelun Shi et.al.|[2311.02692v1](http://arxiv.org/abs/2311.02692v1)|**[link](https://github.com/openlamm/lamm)**|\n", "2311.02147": "|**2023-11-03**|**The Alignment Problem in Context**|Rapha\u00ebl Milli\u00e8re et.al.|[2311.02147v1](http://arxiv.org/abs/2311.02147v1)|null|\n", "2311.02049": "|**2023-11-03**|**Post Turing: Mapping the landscape of LLM Evaluation**|Alexey Tikhonov et.al.|[2311.02049v1](http://arxiv.org/abs/2311.02049v1)|null|\n", "2311.01918": "|**2023-11-03**|**Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review**|Mingze Yuan et.al.|[2311.01918v1](http://arxiv.org/abs/2311.01918v1)|**[link](https://github.com/mingze-yuan/awesome-llm-healthcare)**|\n", "2311.01266": "|**2023-11-02**|**Let's Discover More API Relations: A Large Language Model-based AI Chain for Unsupervised API Relation Inference**|Qing Huang et.al.|[2311.01266v1](http://arxiv.org/abs/2311.01266v1)|null|\n", "2311.01041": "|**2023-11-02**|**Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism**|Lang Cao et.al.|[2311.01041v1](http://arxiv.org/abs/2311.01041v1)|null|\n", "2311.00681": "|**2023-11-01**|**Are Large Language Models Reliable Judges? A Study on the Factuality Evaluation Capabilities of LLMs**|Xue-Yong Fu et.al.|[2311.00681v1](http://arxiv.org/abs/2311.00681v1)|null|\n", "2311.00423": "|**2023-11-29**|**LLMRec: Large Language Models with Graph Augmentation for Recommendation**|Wei Wei et.al.|[2311.00423v5](http://arxiv.org/abs/2311.00423v5)|**[link](https://github.com/hkuds/llmrec)**|\n", "2311.00172": "|**2023-10-31**|**Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield**|Jinhwa Kim et.al.|[2311.00172v1](http://arxiv.org/abs/2311.00172v1)|null|\n", "2310.19740": "|**2023-10-30**|**Collaborative Evaluation: Exploring the Synergy of Large Language Models and Humans for Open-ended Generation Evaluation**|Qintong Li et.al.|[2310.19740v1](http://arxiv.org/abs/2310.19740v1)|**[link](https://github.com/qtli/coeval)**|\n", "2310.19596": "|**2023-10-31**|**LLMaAA: Making Large Language Models as Active Annotators**|Ruoyu Zhang et.al.|[2310.19596v2](http://arxiv.org/abs/2310.19596v2)|null|\n", "2310.19347": "|**2023-11-14**|**Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs**|Huawen Feng et.al.|[2310.19347v3](http://arxiv.org/abs/2310.19347v3)|null|\n", "2310.17918": "|**2023-10-27**|**Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method**|Yukun Zhao et.al.|[2310.17918v1](http://arxiv.org/abs/2310.17918v1)|null|\n", "2310.17876": "|**2023-10-30**|**TarGEN: Targeted Data Generation with Large Language Models**|Himanshu Gupta et.al.|[2310.17876v2](http://arxiv.org/abs/2310.17876v2)|**[link](https://github.com/kevinscaria/targen)**|\n", "2310.17793": "|**2023-10-26**|**\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation**|Allyson Ettinger et.al.|[2310.17793v1](http://arxiv.org/abs/2310.17793v1)|null|\n", "2310.17623": "|**2023-11-24**|**Proving Test Set Contamination in Black Box Language Models**|Yonatan Oren et.al.|[2310.17623v2](http://arxiv.org/abs/2310.17623v2)|**[link](https://github.com/tatsu-lab/test_set_contamination)**|\n", "2310.17589": "|**2023-10-26**|**An Open Source Data Contamination Report for Llama Series Models**|Yucheng Li et.al.|[2310.17589v1](http://arxiv.org/abs/2310.17589v1)|**[link](https://github.com/liyucheng09/contamination_detector)**|\n", "2310.18373": "|**2023-10-26**|**Can LLMs Grade Short-answer Reading Comprehension Questions : Foundational Literacy Assessment in LMICs**|Owen Henkel et.al.|[2310.18373v1](http://arxiv.org/abs/2310.18373v1)|null|\n", "2310.17526": "|**2023-10-27**|**Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages**|Qusai Khraisha et.al.|[2310.17526v2](http://arxiv.org/abs/2310.17526v2)|null|\n", "2310.15372": "|**2023-10-23**|**EpiK-Eval: Evaluation for Language Models as Epistemic Models**|Gabriele Prato et.al.|[2310.15372v1](http://arxiv.org/abs/2310.15372v1)|null|\n", "2310.15147": "|**2023-10-23**|**S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models**|Fangyu Lei et.al.|[2310.15147v1](http://arxiv.org/abs/2310.15147v1)|**[link](https://github.com/lfy79001/sqleval)**|\n", "2310.15117": "|**2023-10-23**|**Causal Inference Using LLM-Guided Discovery**|Aniket Vashishtha et.al.|[2310.15117v1](http://arxiv.org/abs/2310.15117v1)|null|\n", "2310.15100": "|**2023-10-23**|**LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis**|Shih-Chieh Dai et.al.|[2310.15100v1](http://arxiv.org/abs/2310.15100v1)|**[link](https://github.com/sjdai/llm-thematic-analysis)**|\n", "2310.14021": "|**2023-10-21**|**Survey of Vector Database Management Systems**|James Jie Pan et.al.|[2310.14021v1](http://arxiv.org/abs/2310.14021v1)|null|\n", "2310.13800": "|**2023-10-20**|**Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks**|Andrea Sottana et.al.|[2310.13800v1](http://arxiv.org/abs/2310.13800v1)|**[link](https://github.com/protagolabs/seq2seq_llm_evaluation)**|\n", "2310.13206": "|**2023-10-20**|**Primacy Effect of ChatGPT**|Yiwei Wang et.al.|[2310.13206v1](http://arxiv.org/abs/2310.13206v1)|null|\n", "2310.12963": "|**2023-11-15**|**AutoMix: Automatically Mixing Language Models**|Aman Madaan et.al.|[2310.12963v2](http://arxiv.org/abs/2310.12963v2)|**[link](https://github.com/automix-llm/automix)**|\n", "2310.12945": "|**2023-10-19**|**3D-GPT: Procedural 3D Modeling with Large Language Models**|Chunyi Sun et.al.|[2310.12945v1](http://arxiv.org/abs/2310.12945v1)|null|\n", "2310.12670": "|**2023-10-19**|**Reliable and Efficient In-Memory Fault Tolerance of Large Language Model Pretraining**|Yuxin Wang et.al.|[2310.12670v1](http://arxiv.org/abs/2310.12670v1)|null|\n", "2310.12558": "|**2023-10-19**|**Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong**|Chenglei Si et.al.|[2310.12558v1](http://arxiv.org/abs/2310.12558v1)|null|\n", "2310.13028": "|**2023-10-19**|**Reliable Academic Conference Question Answering: A Study Based on Large Language Model**|Zhiwei Huang et.al.|[2310.13028v1](http://arxiv.org/abs/2310.13028v1)|null|\n"}}